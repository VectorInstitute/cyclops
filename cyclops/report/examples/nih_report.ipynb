{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-concept",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import inspect\n",
    "import re\n",
    "from functools import partial\n",
    "from io import BytesIO\n",
    "\n",
    "import jinja2\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import torch\n",
    "from datasets.combine import concatenate_datasets  # noqa: E402\n",
    "from monai.transforms import AddChanneld, Compose, Lambdad, Resized, ToDeviced\n",
    "from pybtex.database import parse_string\n",
    "from pybtex.plugin import find_plugin\n",
    "from pydantic import BaseModel\n",
    "from pydantic.main import ModelMetaclass\n",
    "from torchxrayvision.models import DenseNet\n",
    "\n",
    "from cyclops.data.loader import load_nihcxr\n",
    "from cyclops.data.slicer import filter_value  # noqa: E402\n",
    "from cyclops.data.slicer import SliceSpec\n",
    "from cyclops.data.utils import apply_transforms\n",
    "from cyclops.evaluate import evaluator\n",
    "from cyclops.evaluate.fairness import evaluate_fairness  # noqa: E402\n",
    "from cyclops.evaluate.metrics.factory import create_metric\n",
    "from cyclops.monitor import ClinicalShiftApplicator, Detector, Reductor, TSTester\n",
    "from cyclops.monitor.plotter import plot_drift_experiment\n",
    "from cyclops.monitor.utils import get_device\n",
    "from cyclops.report.model_card.model_card import (\n",
    "    Citation,\n",
    "    ExplainabilityReport,\n",
    "    FairnessAssessment,\n",
    "    FairnessReport,\n",
    "    Graphic,\n",
    "    GraphicsCollection,\n",
    "    Limitation,\n",
    "    ModelCard,\n",
    "    Owner,\n",
    "    PerformanceMetric,\n",
    "    Reference,\n",
    "    Risk,\n",
    "    Tradeoff,\n",
    "    UseCase,\n",
    "    User,\n",
    ")\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "\n",
    "def plot_to_str(fig, dpi=300, transparent=True):\n",
    "    img = BytesIO()\n",
    "    fig.savefig(img, format=\"png\", dpi=dpi, transparent=transparent)\n",
    "    return f'data:image/{format};base64,\\\n",
    "        {base64.encodebytes(img.getvalue()).decode(\"utf-8\")}'\n",
    "\n",
    "\n",
    "def plot_to_str_plotly(fig, scale=2):\n",
    "    img = BytesIO()\n",
    "    fig.write_image(\n",
    "        img,\n",
    "        format=\"png\",\n",
    "        scale=scale,\n",
    "    )\n",
    "    return f'data:image/{format};base64,\\\n",
    "        {base64.encodebytes(img.getvalue()).decode(\"utf-8\")}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-south",
   "metadata": {},
   "outputs": [],
   "source": [
    "nih_ds = load_nihcxr(\"/mnt/data/clinical_datasets/NIHCXR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Compose(\n",
    "    [\n",
    "        AddChanneld(keys=(\"features\",), allow_missing_keys=True),\n",
    "        Resized(\n",
    "            keys=(\"features\",), spatial_size=(1, 224, 224), allow_missing_keys=True\n",
    "        ),\n",
    "        Lambdad(\n",
    "            keys=(\"features\",),\n",
    "            func=lambda x: ((2 * (x / 255.0)) - 1.0) * 1024,\n",
    "            allow_missing_keys=True,\n",
    "        ),\n",
    "        ToDeviced(keys=(\"features\",), device=device, allow_missing_keys=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = DenseNet(weights=\"densenet121-res224-nih\")\n",
    "source_slice = None\n",
    "target_slices = {\n",
    "    \"SEX: MALE\": SliceSpec(spec_list=[{\"Patient Gender\": {\"value\": \"M\"}}]),\n",
    "    \"SEX: FEMALE\": SliceSpec(spec_list=[{\"Patient Gender\": {\"value\": \"F\"}}]),\n",
    "    \"AGE: 18-35\": SliceSpec(\n",
    "        spec_list=[{\"Patient Age\": {\"min_value\": 18, \"max_value\": 35}}]\n",
    "    ),\n",
    "    \"AGE: 35-65\": SliceSpec(\n",
    "        spec_list=[{\"Patient Age\": {\"min_value\": 35, \"max_value\": 65}}]\n",
    "    ),\n",
    "}\n",
    "results = {}\n",
    "\n",
    "for name, target_slice in target_slices.items():\n",
    "    source_slice = None\n",
    "    shifter = ClinicalShiftApplicator(\n",
    "        \"custom\", source=source_slice, target=target_slice\n",
    "    )\n",
    "    ds_source, ds_target = shifter.apply_shift(nih_ds, num_proc=6)\n",
    "\n",
    "    ds_source = ds_source.with_transform(\n",
    "        partial(apply_transforms, transforms=transforms),\n",
    "        columns=[\"features\"],\n",
    "        output_all_columns=True,\n",
    "    )\n",
    "    ds_target = ds_target.with_transform(\n",
    "        partial(apply_transforms, transforms=transforms),\n",
    "        columns=[\"features\"],\n",
    "        output_all_columns=True,\n",
    "    )\n",
    "\n",
    "    detector = Detector(\n",
    "        \"sensitivity_test\",\n",
    "        reductor=Reductor(dr_method=\"bbse-soft\", model=model, device=device),\n",
    "        tester=TSTester(tester_method=\"mmd\"),\n",
    "        source_sample_size=1000,\n",
    "        target_sample_size=[50, 100, 200, 400, 800, 1000],\n",
    "        num_runs=3,\n",
    "    )\n",
    "    results[name] = detector.detect_shift(ds_source, ds_target)\n",
    "fig = plot_drift_experiment(results, axes_color=\"white\")\n",
    "\n",
    "drift_plot = plot_to_str(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f624ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def get_predictions_torch(examples):\n",
    "    images = torch.stack(examples[\"features\"]).squeeze(1)\n",
    "    preds = model(images)\n",
    "    return {\"predictions\": preds}\n",
    "\n",
    "\n",
    "with nih_ds.formatted_as(\n",
    "    \"custom\",\n",
    "    columns=[\"features\"],\n",
    "    transform=partial(apply_transforms, transforms=transforms),\n",
    "):\n",
    "    preds_ds = nih_ds.map(\n",
    "        get_predictions_torch,\n",
    "        batched=True,\n",
    "        batch_size=64,\n",
    "        remove_columns=nih_ds.column_names,\n",
    "    )\n",
    "\n",
    "    nih_ds = concatenate_datasets([nih_ds, preds_ds], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc334c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any rows with No Finding == 1\n",
    "nih_ds = nih_ds.filter(\n",
    "    partial(filter_value, column_name=\"No Finding\", value=1, negate=True), batched=True\n",
    ")\n",
    "\n",
    "# remove the No Finding column and adjust the predictions to account for it\n",
    "nih_ds = nih_ds.map(\n",
    "    lambda x: {\n",
    "        \"predictions\": x[\"predictions\"][:14],\n",
    "    },\n",
    "    remove_columns=[\"No Finding\"],\n",
    ")\n",
    "nih_ds.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff27cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathologies = model.pathologies[:14]\n",
    "\n",
    "auroc = create_metric(\n",
    "    metric_name=\"auroc\",\n",
    "    task=\"multilabel\",\n",
    "    num_labels=len(pathologies),\n",
    "    thresholds=np.arange(0, 1, 0.01),\n",
    ")\n",
    "\n",
    "# define the slices\n",
    "slices = [\n",
    "    {\"Patient Gender\": {\"value\": \"M\"}},\n",
    "    {\"Patient Gender\": {\"value\": \"F\"}},\n",
    "]\n",
    "\n",
    "# create the slice functions\n",
    "slice_spec = SliceSpec(spec_list=slices)\n",
    "\n",
    "nih_eval_results = evaluator.evaluate(\n",
    "    dataset=nih_ds,\n",
    "    metrics=auroc,\n",
    "    feature_columns=\"features\",\n",
    "    target_columns=pathologies,\n",
    "    prediction_column_prefix=\"predictions\",\n",
    "    remove_columns=\"features\",\n",
    "    slice_spec=slice_spec,\n",
    ")\n",
    "\n",
    "# plot the results\n",
    "plots = []\n",
    "\n",
    "for slice_name, slice_results in nih_eval_results.items():\n",
    "    plots.append(\n",
    "        go.Scatter(\n",
    "            x=pathologies,\n",
    "            y=slice_results[\"MultilabelAUROC\"],\n",
    "            name=\"Overall\" if slice_name == \"overall\" else slice_name,\n",
    "            mode=\"markers\",\n",
    "        )\n",
    "    )\n",
    "layout = go.Layout(\n",
    "    paper_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    plot_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    font=dict(color=\"white\"),\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=plots, layout=layout)\n",
    "fig.update_layout(\n",
    "    # title=\"Multilabel AUROC by Pathology and Slice\",\n",
    "    title_x=0.5,\n",
    "    title_font_size=20,\n",
    "    xaxis_title=\"Pathology\",\n",
    "    yaxis_title=\"Multilabel AUROC\",\n",
    "    width=1024,\n",
    "    height=768,\n",
    ")\n",
    "fig.update_traces(\n",
    "    marker=dict(size=12, line=dict(width=2, color=\"DarkSlateGrey\")),\n",
    "    selector=dict(mode=\"markers\"),\n",
    ")\n",
    "# perf_metric_gender = fig.to_image(format=\"svg\")\n",
    "perf_metric_gender = plot_to_str_plotly(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f2d08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathologies = model.pathologies[:14]\n",
    "\n",
    "auroc = create_metric(\n",
    "    metric_name=\"auroc\",\n",
    "    task=\"multilabel\",\n",
    "    num_labels=len(pathologies),\n",
    "    thresholds=np.arange(0, 1, 0.01),\n",
    ")\n",
    "\n",
    "# define the slices\n",
    "slices = [\n",
    "    {\"Patient Age\": {\"min_value\": 19, \"max_value\": 35}},\n",
    "    {\"Patient Age\": {\"min_value\": 35, \"max_value\": 65}},\n",
    "    {\"Patient Age\": {\"min_value\": 65, \"max_value\": 100}},\n",
    "]\n",
    "\n",
    "# create the slice functions\n",
    "slice_spec = SliceSpec(spec_list=slices)\n",
    "\n",
    "nih_eval_results = evaluator.evaluate(\n",
    "    dataset=nih_ds,\n",
    "    metrics=auroc,\n",
    "    feature_columns=\"features\",\n",
    "    target_columns=pathologies,\n",
    "    prediction_column_prefix=\"predictions\",\n",
    "    remove_columns=\"features\",\n",
    "    slice_spec=slice_spec,\n",
    ")\n",
    "\n",
    "\n",
    "# plot the results\n",
    "plots = []\n",
    "\n",
    "for slice_name, slice_results in nih_eval_results.items():\n",
    "    plots.append(\n",
    "        go.Scatter(\n",
    "            x=pathologies,\n",
    "            y=slice_results[\"MultilabelAUROC\"],\n",
    "            name=\"Overall\" if slice_name == \"overall\" else slice_name,\n",
    "            mode=\"markers\",\n",
    "        )\n",
    "    )\n",
    "layout = go.Layout(\n",
    "    paper_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    plot_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    font=dict(color=\"white\"),\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=plots, layout=layout)\n",
    "fig.update_layout(\n",
    "    # title=\"Multilabel AUROC by Pathology and Slice\",\n",
    "    title_x=0.5,\n",
    "    title_font_size=20,\n",
    "    xaxis_title=\"Pathology\",\n",
    "    yaxis_title=\"Multilabel AUROC\",\n",
    "    width=1024,\n",
    "    height=768,\n",
    ")\n",
    "fig.update_traces(\n",
    "    marker=dict(size=12, line=dict(width=2, color=\"DarkSlateGrey\")),\n",
    "    selector=dict(mode=\"markers\"),\n",
    ")\n",
    "# perf_metric_age = fig.to_image(format=\"svg\")\n",
    "perf_metric_age = plot_to_str_plotly(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c587c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "specificity = create_metric(\n",
    "    metric_name=\"specificity\",\n",
    "    task=\"multilabel\",\n",
    "    num_labels=len(pathologies),\n",
    ")\n",
    "sensitivity = create_metric(\n",
    "    metric_name=\"sensitivity\",\n",
    "    task=\"multilabel\",\n",
    "    num_labels=len(pathologies),\n",
    ")\n",
    "\n",
    "fpr = 1 - specificity\n",
    "fnr = 1 - sensitivity\n",
    "\n",
    "balanced_error_rate = (fpr + fnr) / 2\n",
    "\n",
    "nih_fairness_result = evaluate_fairness(\n",
    "    metrics=balanced_error_rate,\n",
    "    metric_name=\"BalancedErrorRate\",\n",
    "    dataset=nih_ds,\n",
    "    remove_columns=\"features\",\n",
    "    target_columns=pathologies,\n",
    "    prediction_columns=\"predictions\",\n",
    "    groups=[\"Patient Age\", \"Patient Gender\"],\n",
    "    group_bins={\"Patient Age\": [20, 40, 60, 80]},\n",
    "    group_base_values={\"Patient Age\": 20, \"Patient Gender\": \"M\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ec44ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot metrics per slice\n",
    "plots = []\n",
    "\n",
    "for slice_name, slice_results in nih_fairness_result.items():\n",
    "    plots.append(\n",
    "        go.Scatter(\n",
    "            x=pathologies,\n",
    "            y=slice_results[\"BalancedErrorRate\"],\n",
    "            name=slice_name,\n",
    "            mode=\"markers\",\n",
    "        )\n",
    "    )\n",
    "layout = go.Layout(\n",
    "    paper_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    plot_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    font=dict(color=\"white\"),\n",
    ")\n",
    "fig = go.Figure(data=plots, layout=layout)\n",
    "fig.update_layout(\n",
    "    # title=\"Balanced Error Rate by Pathology and Group\",\n",
    "    title_x=0.5,\n",
    "    title_font_size=20,\n",
    "    xaxis_title=\"Pathology\",\n",
    "    yaxis_title=\"Balanced Error Rate\",\n",
    "    width=1024,\n",
    "    height=768,\n",
    ")\n",
    "fig.update_traces(\n",
    "    marker=dict(size=12, line=dict(width=2, color=\"DarkSlateGrey\")),\n",
    "    selector=dict(mode=\"markers\"),\n",
    ")\n",
    "# fairness_1 = fig.to_image(format=\"svg\")\n",
    "fairness_1 = plot_to_str_plotly(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b1b68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot parity difference per slice\n",
    "plots = []\n",
    "\n",
    "for slice_name, slice_results in nih_fairness_result.items():\n",
    "    plots.append(\n",
    "        go.Scatter(\n",
    "            x=pathologies,\n",
    "            y=slice_results[\"BalancedErrorRate Parity\"],\n",
    "            name=slice_name,\n",
    "            mode=\"markers\",\n",
    "        )\n",
    "    )\n",
    "layout = go.Layout(\n",
    "    paper_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    plot_bgcolor=\"rgba(0,0,0,0)\",\n",
    "    font=dict(color=\"white\"),\n",
    ")\n",
    "fig = go.Figure(data=plots, layout=layout)\n",
    "fig.update_layout(\n",
    "    # title=\"Balanced Error Rate Parity by Pathology and Group\",\n",
    "    title_x=0.5,\n",
    "    title_font_size=20,\n",
    "    xaxis_title=\"Pathology\",\n",
    "    yaxis_title=\"Balanced Error Rate Parity\",\n",
    "    width=1024,\n",
    "    height=768,\n",
    ")\n",
    "fig.update_traces(\n",
    "    marker=dict(size=12, line=dict(width=2, color=\"DarkSlateGrey\")),\n",
    "    selector=dict(mode=\"markers\"),\n",
    ")\n",
    "# fairness_2 = fig.to_image(format=\"svg\")\n",
    "fairness_2 = plot_to_str_plotly(fig)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "human-martin",
   "metadata": {},
   "source": [
    "## Bootstrap model card from VerifyML model card editor and scaffold assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model card\n",
    "def scaffold_model(base_model: BaseModel) -> BaseModel:\n",
    "    \"\"\"Recursively initialize a pydantic model with default values.\"\"\"\n",
    "    assert isinstance(\n",
    "        base_model, BaseModel\n",
    "    ), f\"Expected a pydantic BaseModel instance, got {type(base_model)} instead.\"\n",
    "\n",
    "    for field in base_model.__fields__:\n",
    "        field_type = base_model.__fields__[field].type_\n",
    "\n",
    "        if (\n",
    "            type(field_type) is ModelMetaclass\n",
    "            and base_model.__fields__[field].default_factory is None\n",
    "        ):\n",
    "            sub_model = scaffold_model(field_type())\n",
    "            setattr(base_model, field, sub_model)\n",
    "        else:\n",
    "            default = base_model.__fields__[field].default\n",
    "            if base_model.__fields__[field].default_factory is not None:\n",
    "                default = base_model.__fields__[field].default_factory()\n",
    "            setattr(base_model, field, default)\n",
    "    return base_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff0664e9",
   "metadata": {},
   "source": [
    "## Populate model card fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d6fe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = ModelCard()\n",
    "mc = scaffold_model(mc)\n",
    "\n",
    "# model details for NIH Chest X-Ray model\n",
    "mc.model_details.name = \"NIH Chest X-Ray Multi-label Classification Model\"\n",
    "\n",
    "mc.model_details.overview = (\n",
    "    \"This model is a DenseNet121 model trained on the NIH Chest X-Ray dataset.\"\n",
    ")\n",
    "\n",
    "mc.model_details.documentation = \"The model was trained on the NIH Chest X-Ray dataset,\\\n",
    "    which contains 112,120 frontal-view X-ray images of 30,805 unique patients with the\\\n",
    "    fourteen text-mined disease labels from the associated radiological reports.\\\n",
    "    The labels are Atelectasis, Cardiomegaly, Effusion, Infiltration, Mass, Nodule,\\\n",
    "    Pneumonia, Pneumothorax, Consolidation, Edema, Emphysema, Fibrosis,\\\n",
    "    Pleural Thickening, and Hernia. The model was trained on 80% of the data\\\n",
    "    and evaluated on the remaining 20%.\"\n",
    "mc.model_details.references.append(\n",
    "    Reference(reference=\"https://arxiv.org/abs/2111.00595\")\n",
    ")\n",
    "mc.model_details.citations.append(\n",
    "    Citation(\n",
    "        style=\"APA\",\n",
    "        citation=\"\"\"@inproceedings{Cohen2022xrv,\n",
    "        title = {{TorchXRayVision: A library of chest X-ray datasets and models}},\n",
    "        author = {Cohen, Joseph Paul and Viviano, Joseph D. and Bertin, \\\n",
    "        Paul and Morrison,Paul and Torabian, Parsa and Guarrera, \\\n",
    "        Matteo and Lungren, Matthew P and Chaudhari,\\\n",
    "        Akshay and Brooks, Rupert and Hashir, \\\n",
    "        Mohammad and Bertrand, Hadrien},\n",
    "        booktitle = {Medical Imaging with Deep Learning},\n",
    "        url = {https://github.com/mlmed/torchxrayvision},\n",
    "        arxivId = {2111.00595},\n",
    "        year = {2022}\n",
    "        }\"\"\",\n",
    "    )\n",
    ")\n",
    "\n",
    "mc.model_details.citations.append(\n",
    "    Citation(\n",
    "        style=\"APA\",\n",
    "        citation=\"\"\"@inproceedings{cohen2020limits,\n",
    "        title={On the limits of cross-domain generalization\\\n",
    "             in automated X-ray prediction},\n",
    "        author={Cohen, Joseph Paul and Hashir, Mohammad and Brooks, \\\n",
    "            Rupert and Bertrand, Hadrien},\n",
    "        booktitle={Medical Imaging with Deep Learning},\n",
    "        year={2020},\n",
    "        url={https://arxiv.org/abs/2002.02497}\n",
    "        }\"\"\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "mc.model_details.owners = [\n",
    "    Owner(name=\"Machine Learning and Medicine Lab\", contact=\"mlmed.org\")\n",
    "]\n",
    "\n",
    "# considerations\n",
    "mc.considerations.users.extend(\n",
    "    [User(description=\"Radiologists\"), User(description=\"Data Scientists\")]\n",
    ")\n",
    "mc.considerations.use_cases.append(\n",
    "    UseCase(\n",
    "        description=\"The model can be used to predict the presence of 14 pathologies \\\n",
    "            in chest X-ray images.\"\n",
    "    )\n",
    ")\n",
    "mc.considerations.limitations.append(\n",
    "    Limitation(\n",
    "        # describe limits of chest x-ray classification model\n",
    "        description=\"The limitations of this model include its inability to detect \\\n",
    "                    pathologies that are not included in the 14 labels of the NIH \\\n",
    "                    Chest X-Ray dataset. Additionally, the model may not perform \\\n",
    "                    well on images that are of poor quality or that contain \\\n",
    "                    artifacts. Finally, the model may not generalize well to\\\n",
    "                    populations that are not well-represented in the training \\\n",
    "                    data, such as patients from different geographic regions or \\\n",
    "                    with different demographics.\"\n",
    "    )\n",
    ")\n",
    "mc.considerations.tradeoffs.append(\n",
    "    Tradeoff(\n",
    "        description=\"The model can help radiologists to detect pathologies in \\\n",
    "            chest X-ray images, but it may not generalize well to populations \\\n",
    "            that are not well-represented in the training data.\"\n",
    "    )\n",
    ")\n",
    "mc.considerations.ethical_considerations.append(\n",
    "    Risk(\n",
    "        name=\"One ethical risk of the model is that it may not generalize well to \\\n",
    "            populations that are not well-represented in the training data,\\\n",
    "            such as patients from different geographic regions \\\n",
    "            or with different demographics. \",\n",
    "        mitigation_strategy=\"A mitigation strategy for this risk is to ensure \\\n",
    "            that the training data is diverse and representative of the population \\\n",
    "              that the model will be used on. Additionally, the model should be \\\n",
    "                regularly evaluated and updated to ensure that it continues to \\\n",
    "                perform well on diverse populations. Finally, the model should \\\n",
    "                be used in conjunction with human expertise to ensure that \\\n",
    "                any biases or limitations are identified and addressed.\",\n",
    "    )\n",
    ")\n",
    "mc.considerations.fairness_assessment.append(\n",
    "    FairnessAssessment(\n",
    "        group_at_risk=\"Patients with rare pathologies\",\n",
    "        benefits=\"The model can help radiologists to detect pathologies in \\\n",
    "            chest X-ray images.\",\n",
    "        harms=\"The model may not generalize well to populations that are not \\\n",
    "            well-represented in the training data.\",\n",
    "        mitigation_strategy=\"A mitigation strategy for this risk is to ensure that \\\n",
    "            the training data is diverse and representative of the population.\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# Create 4 PerformanceMetric to store our results\n",
    "mc.quantitative_analysis.performance_metrics = [\n",
    "    PerformanceMetric() for i in range(0, 2)\n",
    "]\n",
    "\n",
    "mc.quantitative_analysis.performance_metrics[0].type = \"MultiLabel AUROC by Pathology\"\n",
    "mc.quantitative_analysis.performance_metrics[0].slice = \"Male/Female\"\n",
    "# instantiate GraphicsCollection as workaround to store graphics for the plots.\n",
    "mc.quantitative_analysis.performance_metrics[0].graphics = GraphicsCollection()\n",
    "mc.quantitative_analysis.performance_metrics[0].graphics.collection = [\n",
    "    Graphic(name=\"auroc_sex\", image=perf_metric_gender)\n",
    "]\n",
    "mc.quantitative_analysis.performance_metrics[1].type = \"MultiLabel AUROC by Pathology\"\n",
    "mc.quantitative_analysis.performance_metrics[1].slice = \"Age Brackets\"\n",
    "# instantiate GraphicsCollection as workaround to store graphics for the plots.\n",
    "mc.quantitative_analysis.performance_metrics[1].graphics = GraphicsCollection()\n",
    "mc.quantitative_analysis.performance_metrics[1].graphics.collection = [\n",
    "    Graphic(name=\"auroc_age\", image=perf_metric_age)\n",
    "]\n",
    "\n",
    "mc.fairness_analysis.fairness_reports = [FairnessReport() for i in range(0, 2)]\n",
    "\n",
    "mc.fairness_analysis.fairness_reports[0].type = \"Balanced Error Rate by Pathology\"\n",
    "mc.fairness_analysis.fairness_reports[0].slice = None\n",
    "mc.fairness_analysis.fairness_reports[0].segment = \"Age and Gender\"\n",
    "mc.fairness_analysis.fairness_reports[0].description = None\n",
    "# instantiate GraphicsCollection as workaround to store graphics for the plots.\n",
    "mc.fairness_analysis.fairness_reports[0].graphics = GraphicsCollection()\n",
    "mc.fairness_analysis.fairness_reports[0].graphics.collection = [\n",
    "    Graphic(name=\"fairness_ber\", image=fairness_1)\n",
    "]\n",
    "\n",
    "mc.fairness_analysis.fairness_reports[\n",
    "    1\n",
    "].type = \"Balanced Error Rate Parity by Pathology\"\n",
    "mc.fairness_analysis.fairness_reports[1].slice = None\n",
    "mc.fairness_analysis.fairness_reports[1].segment = \"Age and Gender\"\n",
    "mc.fairness_analysis.fairness_reports[1].description = None\n",
    "# instantiate GraphicsCollection as workaround to store graphics for the plots.\n",
    "mc.fairness_analysis.fairness_reports[1].graphics = GraphicsCollection()\n",
    "mc.fairness_analysis.fairness_reports[1].graphics.collection = [\n",
    "    Graphic(name=\"fairness_berp\", image=fairness_2)\n",
    "]\n",
    "\n",
    "mc.explainability_analysis.explainability_reports = [\n",
    "    ExplainabilityReport() for i in range(0, 1)\n",
    "]\n",
    "\n",
    "mc.explainability_analysis.explainability_reports[\n",
    "    0\n",
    "].type = \"Drift Sensitivity Experiment\"\n",
    "mc.explainability_analysis.explainability_reports[0].slice = \"Age and Sex\"\n",
    "mc.explainability_analysis.explainability_reports[\n",
    "    0\n",
    "].description = \"Conduct sensitivity experiments to determine if the model is \\\n",
    "    sensitive to changes in the input data by slicing the data along patient \\\n",
    "    attributes and increasing the prevalence of the attribute in the data.\"\n",
    "# instantiate GraphicsCollection as workaround to store graphics for the plots.\n",
    "mc.explainability_analysis.explainability_reports[0].graphics = GraphicsCollection()\n",
    "mc.explainability_analysis.explainability_reports[0].graphics.collection = [\n",
    "    Graphic(name=\"drift_exp\", image=drift_plot)\n",
    "]\n",
    "\n",
    "\n",
    "jinja_env = jinja2.Environment(\n",
    "    loader=jinja2.FileSystemLoader(\"../model_card/template/\"),\n",
    "    autoescape=True,\n",
    "    auto_reload=True,\n",
    "    cache_size=0,\n",
    ")\n",
    "\n",
    "\n",
    "# Custom filter method\n",
    "def regex_replace(s, find, replace):\n",
    "    \"\"\"A non-optimal implementation of a regex filter\"\"\"\n",
    "    return re.sub(find, replace, s)\n",
    "\n",
    "\n",
    "jinja_env.filters[\"regex_replace\"] = regex_replace\n",
    "\n",
    "jinja_env.tests[\"list\"] = lambda x: isinstance(x, list)\n",
    "\n",
    "jinja_env.tests[\"class\"] = lambda x: inspect.isclass(x)\n",
    "\n",
    "\n",
    "def empty(x):\n",
    "    empty = True\n",
    "    for _, obj in x:\n",
    "        if isinstance(obj, list):\n",
    "            if len(obj) > 0:\n",
    "                empty = False\n",
    "        elif isinstance(obj, GraphicsCollection):\n",
    "            if len(obj.collection) > 0:\n",
    "                empty = False\n",
    "        elif obj is not None:\n",
    "            empty = False\n",
    "    return empty\n",
    "\n",
    "\n",
    "jinja_env.tests[\"empty\"] = empty\n",
    "\n",
    "\n",
    "def bib2html(citation, style, exclude_fields=None):\n",
    "    HTML = find_plugin(\"pybtex.backends\", \"html\")()\n",
    "    style = style.lower()\n",
    "    if style == \"apa\":\n",
    "        style = find_plugin(\"pybtex.style.formatting\", style)()\n",
    "    else:\n",
    "        style = None\n",
    "    bibliography = parse_string(citation, \"bibtex\")\n",
    "    exclude_fields = exclude_fields or []\n",
    "    if exclude_fields:\n",
    "        for entry in bibliography.entries.values():\n",
    "            for ef in exclude_fields:\n",
    "                if ef in entry.fields.__dict__[\"_dict\"]:\n",
    "                    del entry.fields.__dict__[\"_dict\"][ef]\n",
    "    if style:\n",
    "        bibliography = style.format_bibliography(bibliography)\n",
    "    return \"<br>\".join(entry.text.render(HTML) for entry in bibliography)\n",
    "\n",
    "\n",
    "def render_citation(obj):\n",
    "    return bib2html(obj.citation, obj.style)\n",
    "\n",
    "\n",
    "jinja_env.filters[\"render_citation\"] = render_citation\n",
    "\n",
    "template = jinja_env.get_template(\"cyclops_generic_template_dark.jinja\")\n",
    "\n",
    "content = template.render(model_card=mc)\n",
    "\n",
    "with open(\"report.html\", \"w+\") as f:\n",
    "    f.write(content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycyclops-4J2PL5I8-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

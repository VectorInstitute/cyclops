{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-concept",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import jinja2\n",
    "from monai.transforms import AddChanneld, Compose, Lambdad, Resized, ToDeviced\n",
    "from pydantic import BaseModel\n",
    "from pydantic.main import ModelMetaclass\n",
    "from torchxrayvision.models import DenseNet\n",
    "\n",
    "from cyclops.data.loader import load_nihcxr\n",
    "from cyclops.data.slicer import SliceSpec\n",
    "from cyclops.data.utils import apply_transforms\n",
    "from cyclops.monitor import ClinicalShiftApplicator, Detector, Reductor, TSTester\n",
    "from cyclops.monitor.plotter import plot_drift_experiment\n",
    "from cyclops.monitor.utils import get_device\n",
    "from cyclops.report.model_card.model_card import (\n",
    "    Citation,\n",
    "    ExplainabilityReport,\n",
    "    FairnessAssessment,\n",
    "    FairnessReport,\n",
    "    Graphic,\n",
    "    GraphicsCollection,\n",
    "    Limitation,\n",
    "    ModelCard,\n",
    "    PerformanceMetric,\n",
    "    Reference,\n",
    "    Risk,\n",
    "    Tradeoff,\n",
    "    UseCase,\n",
    "    User,\n",
    "    Owner\n",
    ")\n",
    "\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-south",
   "metadata": {},
   "outputs": [],
   "source": [
    "nih_ds = load_nihcxr(\"/mnt/data/clinical_datasets/NIHCXR\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "stuck-worship",
   "metadata": {},
   "source": [
    "## Get confusion matrix and ROC curve on train/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cbf4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_to_str(fig, dpi=300, transparent=True):\n",
    "    img = BytesIO()\n",
    "    fig.savefig(img, format=\"png\", dpi=dpi, transparent=transparent)\n",
    "    return f'data:image/{format};base64,{base64.encodebytes(img.getvalue()).decode(\"utf-8\")}'\n",
    "\n",
    "\n",
    "def plot_to_str_plotly(fig, scale=2):\n",
    "    img = BytesIO()\n",
    "    fig.write_image(img, format=\"png\", scale=scale, )\n",
    "    return f'data:image/{format};base64,{base64.encodebytes(img.getvalue()).decode(\"utf-8\")}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Compose(\n",
    "    [\n",
    "        AddChanneld(keys=(\"features\",), allow_missing_keys=True),\n",
    "        Resized(\n",
    "            keys=(\"features\",), spatial_size=(1, 224, 224), allow_missing_keys=True\n",
    "        ),\n",
    "        Lambdad(\n",
    "            keys=(\"features\",),\n",
    "            func=lambda x: ((2 * (x / 255.0)) - 1.0) * 1024,\n",
    "            allow_missing_keys=True,\n",
    "        ),\n",
    "        ToDeviced(keys=(\"features\",), device=device, allow_missing_keys=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = DenseNet(weights=\"densenet121-res224-nih\")\n",
    "source_slice = None\n",
    "target_slices = {\n",
    "    \"SEX: MALE\": SliceSpec(spec_list=[{\"Patient Gender\": {\"value\": \"M\"}}]),\n",
    "    \"SEX: FEMALE\": SliceSpec(spec_list=[{\"Patient Gender\": {\"value\": \"F\"}}]),\n",
    "    \"AGE: 18-35\": SliceSpec(\n",
    "        spec_list=[{\"Patient Age\": {\"min_value\": 18, \"max_value\": 35}}]\n",
    "    ),\n",
    "    \"AGE: 35-65\": SliceSpec(\n",
    "        spec_list=[{\"Patient Age\": {\"min_value\": 35, \"max_value\": 65}}]\n",
    "    ),\n",
    "}\n",
    "results = {}\n",
    "\n",
    "for name, target_slice in target_slices.items():\n",
    "    source_slice = None\n",
    "    shifter = ClinicalShiftApplicator(\n",
    "        \"custom\", source=source_slice, target=target_slice\n",
    "    )\n",
    "    ds_source, ds_target = shifter.apply_shift(nih_ds, num_proc=6)\n",
    "\n",
    "    ds_source = ds_source.with_transform(\n",
    "        partial(apply_transforms, transforms=transforms),\n",
    "        columns=[\"features\"],\n",
    "        output_all_columns=True,\n",
    "    )\n",
    "    ds_target = ds_target.with_transform(\n",
    "        partial(apply_transforms, transforms=transforms),\n",
    "        columns=[\"features\"],\n",
    "        output_all_columns=True,\n",
    "    )\n",
    "\n",
    "    detector = Detector(\n",
    "        \"sensitivity_test\",\n",
    "        reductor=Reductor(dr_method=\"bbse-soft\", model=model, device=device),\n",
    "        tester=TSTester(tester_method=\"mmd\"),\n",
    "        source_sample_size=1000,\n",
    "        target_sample_size=[50, 100, 200, 400, 800, 1000],\n",
    "        num_runs=3,\n",
    "    )\n",
    "    results[name] = detector.detect_shift(ds_source, ds_target)\n",
    "fig = plot_drift_experiment(results, axes_color=\"white\")\n",
    "\n",
    "drift_plot = plot_to_str(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f624ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets.combine import concatenate_datasets  # noqa: E402\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def get_predictions_torch(examples):\n",
    "    images = torch.stack(examples[\"features\"]).squeeze(1)\n",
    "    preds = model(images)\n",
    "    return {\"predictions\": preds}\n",
    "\n",
    "\n",
    "with nih_ds.formatted_as(\n",
    "    \"custom\",\n",
    "    columns=[\"features\"],\n",
    "    transform=partial(apply_transforms, transforms=transforms),\n",
    "):\n",
    "    preds_ds = nih_ds.map(\n",
    "        get_predictions_torch,\n",
    "        batched=True,\n",
    "        batch_size=64,\n",
    "        remove_columns=nih_ds.column_names,\n",
    "    )\n",
    "\n",
    "    nih_ds = concatenate_datasets([nih_ds, preds_ds], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc334c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cyclops.data.slicer import filter_value  # noqa: E402\n",
    "\n",
    "# remove any rows with No Finding == 1\n",
    "nih_ds = nih_ds.filter(\n",
    "    partial(filter_value, column_name=\"No Finding\", value=1, negate=True), batched=True\n",
    ")\n",
    "\n",
    "# remove the No Finding column and adjust the predictions to account for it\n",
    "nih_ds = nih_ds.map(\n",
    "    lambda x: {\n",
    "        \"predictions\": x[\"predictions\"][:14],\n",
    "    },\n",
    "    remove_columns=[\"No Finding\"],\n",
    ")\n",
    "nih_ds.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff27cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from cyclops.evaluate import evaluator\n",
    "from cyclops.evaluate.metrics.factory import create_metric\n",
    "\n",
    "pathologies = model.pathologies[:14]\n",
    "\n",
    "auroc = create_metric(\n",
    "    metric_name=\"auroc\",\n",
    "    task=\"multilabel\",\n",
    "    num_labels=len(pathologies),\n",
    "    thresholds=np.arange(0, 1, 0.01),\n",
    ")\n",
    "\n",
    "# define the slices\n",
    "slices = [\n",
    "    {\"Patient Gender\": {\"value\": \"M\"}},\n",
    "    {\"Patient Gender\": {\"value\": \"F\"}},\n",
    "]\n",
    "\n",
    "# create the slice functions\n",
    "slice_spec = SliceSpec(spec_list=slices)\n",
    "\n",
    "nih_eval_results = evaluator.evaluate(\n",
    "    dataset=nih_ds,\n",
    "    metrics=auroc,\n",
    "    feature_columns=\"features\",\n",
    "    target_columns=pathologies,\n",
    "    prediction_column_prefix=\"predictions\",\n",
    "    remove_columns=\"features\",\n",
    "    slice_spec=slice_spec,\n",
    ")\n",
    "\n",
    "# plot the results\n",
    "plots = []\n",
    "\n",
    "for slice_name, slice_results in nih_eval_results.items():\n",
    "    plots.append(\n",
    "        go.Scatter(\n",
    "            x=pathologies,\n",
    "            y=slice_results[\"MultilabelAUROC\"],\n",
    "            name=\"Overall\" if slice_name == \"overall\" else slice_name,\n",
    "            mode=\"markers\",\n",
    "        )\n",
    "    )\n",
    "layout = go.Layout(\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    "    font=dict(color=\"white\")\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=plots, layout=layout)\n",
    "fig.update_layout(\n",
    "    # title=\"Multilabel AUROC by Pathology and Slice\",\n",
    "    title_x=0.5,\n",
    "    title_font_size=20,\n",
    "    xaxis_title=\"Pathology\",\n",
    "    yaxis_title=\"Multilabel AUROC\",\n",
    "    width=1024,\n",
    "    height=768,\n",
    ")\n",
    "fig.update_traces(\n",
    "    marker=dict(size=12, line=dict(width=2, color=\"DarkSlateGrey\")),\n",
    "    selector=dict(mode=\"markers\"),\n",
    ")\n",
    "# perf_metric_gender = fig.to_image(format=\"svg\")\n",
    "perf_metric_gender = plot_to_str_plotly(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f2d08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from cyclops.evaluate import evaluator\n",
    "from cyclops.evaluate.metrics.factory import create_metric\n",
    "\n",
    "pathologies = model.pathologies[:14]\n",
    "\n",
    "auroc = create_metric(\n",
    "    metric_name=\"auroc\",\n",
    "    task=\"multilabel\",\n",
    "    num_labels=len(pathologies),\n",
    "    thresholds=np.arange(0, 1, 0.01),\n",
    ")\n",
    "\n",
    "# define the slices\n",
    "slices = [\n",
    "    {\"Patient Age\": {\"min_value\": 19, \"max_value\": 35}},\n",
    "    {\"Patient Age\": {\"min_value\": 35, \"max_value\": 65}},\n",
    "    {\"Patient Age\": {\"min_value\": 65, \"max_value\": 100}},\n",
    "]\n",
    "\n",
    "# create the slice functions\n",
    "slice_spec = SliceSpec(spec_list=slices)\n",
    "\n",
    "nih_eval_results = evaluator.evaluate(\n",
    "    dataset=nih_ds,\n",
    "    metrics=auroc,\n",
    "    feature_columns=\"features\",\n",
    "    target_columns=pathologies,\n",
    "    prediction_column_prefix=\"predictions\",\n",
    "    remove_columns=\"features\",\n",
    "    slice_spec=slice_spec,\n",
    ")\n",
    "\n",
    "\n",
    "# plot the results\n",
    "plots = []\n",
    "\n",
    "for slice_name, slice_results in nih_eval_results.items():\n",
    "    plots.append(\n",
    "        go.Scatter(\n",
    "            x=pathologies,\n",
    "            y=slice_results[\"MultilabelAUROC\"],\n",
    "            name=\"Overall\" if slice_name == \"overall\" else slice_name,\n",
    "            mode=\"markers\",\n",
    "        )\n",
    "    )\n",
    "layout = go.Layout(\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    "    font=dict(color=\"white\")\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=plots, layout=layout)\n",
    "fig.update_layout(\n",
    "    # title=\"Multilabel AUROC by Pathology and Slice\",\n",
    "    title_x=0.5,\n",
    "    title_font_size=20,\n",
    "    xaxis_title=\"Pathology\",\n",
    "    yaxis_title=\"Multilabel AUROC\",\n",
    "    width=1024,\n",
    "    height=768,\n",
    ")\n",
    "fig.update_traces(\n",
    "    marker=dict(size=12, line=dict(width=2, color=\"DarkSlateGrey\")),\n",
    "    selector=dict(mode=\"markers\"),\n",
    ")\n",
    "# perf_metric_age = fig.to_image(format=\"svg\")\n",
    "perf_metric_age = plot_to_str_plotly(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f9b376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cyclops.evaluate.fairness import FairnessConfig  # noqa: E402\n",
    "from cyclops.evaluate.fairness import evaluate_fairness  # noqa: E402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286b75f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "specificity = create_metric(\n",
    "    metric_name=\"specificity\",\n",
    "    task=\"multilabel\",\n",
    "    num_labels=len(pathologies),\n",
    ")\n",
    "sensitivity = create_metric(\n",
    "    metric_name=\"sensitivity\",\n",
    "    task=\"multilabel\",\n",
    "    num_labels=len(pathologies),\n",
    ")\n",
    "\n",
    "fpr = 1 - specificity\n",
    "fnr = 1 - sensitivity\n",
    "\n",
    "balanced_error_rate = (fpr + fnr) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c587c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nih_fairness_result = evaluate_fairness(\n",
    "    metrics=balanced_error_rate,\n",
    "    metric_name=\"BalancedErrorRate\",\n",
    "    dataset=nih_ds,\n",
    "    remove_columns=\"features\",\n",
    "    target_columns=pathologies,\n",
    "    prediction_columns=\"predictions\",\n",
    "    groups=[\"Patient Age\", \"Patient Gender\"],\n",
    "    group_bins={\"Patient Age\": [20, 40, 60, 80]},\n",
    "    group_base_values={\"Patient Age\": 20, \"Patient Gender\": \"M\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ec44ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot metrics per slice\n",
    "plots = []\n",
    "\n",
    "for slice_name, slice_results in nih_fairness_result.items():\n",
    "    plots.append(\n",
    "        go.Scatter(\n",
    "            x=pathologies,\n",
    "            y=slice_results[\"BalancedErrorRate\"],\n",
    "            name=slice_name,\n",
    "            mode=\"markers\",\n",
    "        )\n",
    "    )\n",
    "layout = go.Layout(\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    "    font=dict(color=\"white\")\n",
    ")\n",
    "fig = go.Figure(data=plots, layout=layout)\n",
    "fig.update_layout(\n",
    "    # title=\"Balanced Error Rate by Pathology and Group\",\n",
    "    title_x=0.5,\n",
    "    title_font_size=20,\n",
    "    xaxis_title=\"Pathology\",\n",
    "    yaxis_title=\"Balanced Error Rate\",\n",
    "    width=1024,\n",
    "    height=768,\n",
    ")\n",
    "fig.update_traces(\n",
    "    marker=dict(size=12, line=dict(width=2, color=\"DarkSlateGrey\")),\n",
    "    selector=dict(mode=\"markers\"),\n",
    ")\n",
    "# fairness_1 = fig.to_image(format=\"svg\")\n",
    "fairness_1 = plot_to_str_plotly(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b1b68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot parity difference per slice\n",
    "plots = []\n",
    "\n",
    "for slice_name, slice_results in nih_fairness_result.items():\n",
    "    plots.append(\n",
    "        go.Scatter(\n",
    "            x=pathologies,\n",
    "            y=slice_results[\"BalancedErrorRate Parity\"],\n",
    "            name=slice_name,\n",
    "            mode=\"markers\",\n",
    "        )\n",
    "    )\n",
    "layout = go.Layout(\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    "    font=dict(color=\"white\")\n",
    ")\n",
    "fig = go.Figure(data=plots, layout=layout)\n",
    "fig.update_layout(\n",
    "    # title=\"Balanced Error Rate Parity by Pathology and Group\",\n",
    "    title_x=0.5,\n",
    "    title_font_size=20,\n",
    "    xaxis_title=\"Pathology\",\n",
    "    yaxis_title=\"Balanced Error Rate Parity\",\n",
    "    width=1024,\n",
    "    height=768,\n",
    ")\n",
    "fig.update_traces(\n",
    "    marker=dict(size=12, line=dict(width=2, color=\"DarkSlateGrey\")),\n",
    "    selector=dict(mode=\"markers\"),\n",
    ")\n",
    "# fairness_2 = fig.to_image(format=\"svg\")\n",
    "fairness_2 = plot_to_str_plotly(fig)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "human-martin",
   "metadata": {},
   "source": [
    "## Bootstrap model card from VerifyML model card editor and scaffold assets\n",
    "We can add the quantitative analysis, explainability analysis and fairness analysis sections to a bootstrap model card for convenience. In this example, we use an existing model card which we created from the [VerifyML model card editor](https://report.verifyml.com/create). This is meant only as an example - the dataset and risk evaluation in the model card is a fictional use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model card\n",
    "def scaffold_model(base_model: BaseModel) -> BaseModel:\n",
    "    \"\"\"Recursively initialize a pydantic model with default values.\"\"\"\n",
    "    assert isinstance(\n",
    "        base_model, BaseModel\n",
    "    ), f\"Expected a pydantic BaseModel instance, got {type(base_model)} instead.\"\n",
    "\n",
    "    for field in base_model.__fields__:\n",
    "        field_type = base_model.__fields__[field].type_\n",
    "\n",
    "        if (\n",
    "            type(field_type) is ModelMetaclass\n",
    "            and base_model.__fields__[field].default_factory is None\n",
    "        ):\n",
    "            sub_model = scaffold_model(field_type())\n",
    "            setattr(base_model, field, sub_model)\n",
    "        else:\n",
    "            default = base_model.__fields__[field].default\n",
    "            if base_model.__fields__[field].default_factory is not None:\n",
    "                default = base_model.__fields__[field].default_factory()\n",
    "            setattr(base_model, field, default)\n",
    "    return base_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff0664e9",
   "metadata": {},
   "source": [
    "## Populate model card fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d6fe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = ModelCard()\n",
    "mc = scaffold_model(mc)\n",
    "\n",
    "# model details for NIH Chest X-Ray model\n",
    "mc.model_details.name = \"NIH Chest X-Ray Multi-label Classification Model\"\n",
    "\n",
    "mc.model_details.overview = (\n",
    "    \"This model is a DenseNet121 model trained on the NIH Chest X-Ray dataset.\"\n",
    ")\n",
    "\n",
    "mc.model_details.documentation = \"The model was trained on the NIH Chest X-Ray dataset, \\\n",
    "    which contains 112,120 frontal-view X-ray images of 30,805 unique patients with the \\\n",
    "    fourteen text-mined disease labels from the associated radiological reports.  The labels \\\n",
    "    are Atelectasis, Cardiomegaly, Effusion, Infiltration, Mass, Nodule, Pneumonia, Pneumothorax, \\\n",
    "    Consolidation, Edema, Emphysema, Fibrosis, Pleural Thickening, and Hernia.  The model was \\\n",
    "    trained on 80% of the data and evaluated on the remaining 20%.\"\n",
    "mc.model_details.references.append(\n",
    "    Reference(reference=\"https://arxiv.org/abs/2111.00595\")\n",
    ")\n",
    "mc.model_details.citations.append(\n",
    "    Citation(\n",
    "        style=\"APA\",\n",
    "        citation=\"\"\"@inproceedings{Cohen2022xrv,\n",
    "        title = {{TorchXRayVision: A library of chest X-ray datasets and models}},\n",
    "        author = {Cohen, Joseph Paul and Viviano, Joseph D. and Bertin, Paul and Morrison, Paul and Torabian, Parsa and Guarrera, Matteo and Lungren, Matthew P and Chaudhari, Akshay and Brooks, Rupert and Hashir, Mohammad and Bertrand, Hadrien},\n",
    "        booktitle = {Medical Imaging with Deep Learning},\n",
    "        url = {https://github.com/mlmed/torchxrayvision},\n",
    "        arxivId = {2111.00595},\n",
    "        year = {2022}\n",
    "        }\"\"\",\n",
    "    )\n",
    ")\n",
    "\n",
    "mc.model_details.citations.append(\n",
    "    Citation(\n",
    "        style=\"APA\",\n",
    "        citation=\"\"\"@inproceedings{cohen2020limits,\n",
    "        title={On the limits of cross-domain generalization in automated X-ray prediction},\n",
    "        author={Cohen, Joseph Paul and Hashir, Mohammad and Brooks, Rupert and Bertrand, Hadrien},\n",
    "        booktitle={Medical Imaging with Deep Learning},\n",
    "        year={2020},\n",
    "        url={https://arxiv.org/abs/2002.02497}\n",
    "        }\"\"\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "mc.model_details.owners = [Owner(name = \"Machine Learning and Medicine Lab\", contact = \"mlmed.org\")]\n",
    "\n",
    "# considerations\n",
    "mc.considerations.users.extend(\n",
    "    [User(description=\"Radiologists\"), User(description=\"Data Scientists\")]\n",
    ")\n",
    "mc.considerations.use_cases.append(\n",
    "    UseCase(\n",
    "        description=\"The model can be used to predict the presence of 14 pathologies \\\n",
    "            in chest X-ray images.\"\n",
    "    )\n",
    ")\n",
    "mc.considerations.limitations.append(\n",
    "    Limitation(\n",
    "        # describe limits of chest x-ray classification model\n",
    "        description=\"The limitations of this model include its inability to detect \\\n",
    "                    pathologies that are not included in the 14 labels of the NIH Chest X-Ray \\\n",
    "                    dataset. Additionally, the model may not perform well on images that are \\\n",
    "                    of poor quality or that contain artifacts. Finally, the model may not \\\n",
    "                    generalize well to populations that are not well-represented in the training \\\n",
    "                    data, such as patients from different geographic regions or with different \\\n",
    "                    demographics.\"\n",
    "    )\n",
    ")\n",
    "mc.considerations.tradeoffs.append(\n",
    "    Tradeoff(\n",
    "        description=\"The model can help radiologists to detect pathologies in chest X-ray \\\n",
    "            images, but it may not generalize well to populations that are not well-represented \\\n",
    "            in the training data.\"\n",
    "    )\n",
    ")\n",
    "mc.considerations.ethical_considerations.append(\n",
    "    Risk(\n",
    "        name=\"One ethical risk of the model is that it may not generalize well to populations that are not well-represented in the training data,\\\n",
    "              such as patients from different geographic regions or with different demographics. \",\n",
    "        mitigation_strategy=\"A mitigation strategy for this risk is to ensure that the training data is diverse and representative of the population \\\n",
    "              that the model will be used on. Additionally, the model should be regularly evaluated and updated to ensure that it continues to perform \\\n",
    "                well on diverse populations. Finally, the model should be used in conjunction with human expertise to ensure that any biases or limitations \\\n",
    "                are identified and addressed.\",\n",
    "    )\n",
    ")\n",
    "mc.considerations.fairness_assessment.append(\n",
    "    FairnessAssessment(\n",
    "        group_at_risk=\"Patients with rare pathologies\",\n",
    "        benefits=\"The model can help radiologists to detect pathologies in chest X-ray images.\",\n",
    "        harms=\"The model may not generalize well to populations that are not well-represented in the training data.\",\n",
    "        mitigation_strategy=\"A mitigation strategy for this risk is to ensure that the training data is diverse and representative of the population.\",\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# Create 4 PerformanceMetric to store our results\n",
    "mc.quantitative_analysis.performance_metrics = [\n",
    "    PerformanceMetric() for i in range(0, 2)\n",
    "]\n",
    "\n",
    "mc.quantitative_analysis.performance_metrics[0].type = \"MultiLabel AUROC by Pathology\"\n",
    "mc.quantitative_analysis.performance_metrics[0].slice = \"Male/Female\"\n",
    "# instantiate GraphicsCollection as workaround to store graphics for the plots.\n",
    "mc.quantitative_analysis.performance_metrics[0].graphics = GraphicsCollection()\n",
    "mc.quantitative_analysis.performance_metrics[0].graphics.collection = [\n",
    "    Graphic(name=\"auroc_sex\", image=perf_metric_gender)\n",
    "]\n",
    "mc.quantitative_analysis.performance_metrics[1].type = \"MultiLabel AUROC by Pathology\"\n",
    "mc.quantitative_analysis.performance_metrics[1].slice = \"Age Brackets\"\n",
    "# instantiate GraphicsCollection as workaround to store graphics for the plots.\n",
    "mc.quantitative_analysis.performance_metrics[1].graphics = GraphicsCollection()\n",
    "mc.quantitative_analysis.performance_metrics[1].graphics.collection = [\n",
    "    Graphic(name=\"auroc_age\", image=perf_metric_age)\n",
    "]\n",
    "\n",
    "mc.fairness_analysis.fairness_reports = [FairnessReport() for i in range(0, 2)]\n",
    "\n",
    "mc.fairness_analysis.fairness_reports[0].type = \"Balanced Error Rate by Pathology\"\n",
    "mc.fairness_analysis.fairness_reports[0].slice = None\n",
    "mc.fairness_analysis.fairness_reports[0].segment = \"Age and Gender\"\n",
    "mc.fairness_analysis.fairness_reports[0].description = None\n",
    "# instantiate GraphicsCollection as workaround to store graphics for the plots.\n",
    "mc.fairness_analysis.fairness_reports[0].graphics = GraphicsCollection()\n",
    "mc.fairness_analysis.fairness_reports[0].graphics.collection = [\n",
    "    Graphic(name=\"fairness_ber\", image=fairness_1)\n",
    "]\n",
    "\n",
    "mc.fairness_analysis.fairness_reports[\n",
    "    1\n",
    "].type = \"Balanced Error Rate Parity by Pathology\"\n",
    "mc.fairness_analysis.fairness_reports[1].slice = None\n",
    "mc.fairness_analysis.fairness_reports[1].segment = \"Age and Gender\"\n",
    "mc.fairness_analysis.fairness_reports[1].description = None\n",
    "# instantiate GraphicsCollection as workaround to store graphics for the plots.\n",
    "mc.fairness_analysis.fairness_reports[1].graphics = GraphicsCollection()\n",
    "mc.fairness_analysis.fairness_reports[1].graphics.collection = [\n",
    "    Graphic(name=\"fairness_berp\", image=fairness_2)\n",
    "]\n",
    "\n",
    "mc.explainability_analysis.explainability_reports = [\n",
    "    ExplainabilityReport() for i in range(0, 1)\n",
    "]\n",
    "\n",
    "mc.explainability_analysis.explainability_reports[\n",
    "    0\n",
    "].type = \"Drift Sensitivity Experiment\"\n",
    "mc.explainability_analysis.explainability_reports[0].slice = \"Age and Sex\"\n",
    "mc.explainability_analysis.explainability_reports[\n",
    "    0\n",
    "].description = \"Conduct sensitivity experiments to determine if the model is sensitive to changes in the input data \\\n",
    "    by slicing the data along patient attributes and increasing the prevalence of the attribute in the data.\"\n",
    "# instantiate GraphicsCollection as workaround to store graphics for the plots.\n",
    "mc.explainability_analysis.explainability_reports[0].graphics = GraphicsCollection()\n",
    "mc.explainability_analysis.explainability_reports[0].graphics.collection = [\n",
    "    Graphic(name=\"drift_exp\", image=drift_plot)\n",
    "]\n",
    "\n",
    "\n",
    "jinja_env = jinja2.Environment(\n",
    "    loader=jinja2.FileSystemLoader(\"../model_card/template/\"),\n",
    "    autoescape=True,\n",
    "    auto_reload=True,\n",
    "    cache_size=0,\n",
    ")\n",
    "\n",
    "\n",
    "# Custom filter method\n",
    "import re\n",
    "def regex_replace(s, find, replace):\n",
    "    \"\"\"A non-optimal implementation of a regex filter\"\"\"\n",
    "    return re.sub(find, replace, s)\n",
    "jinja_env.filters['regex_replace'] = regex_replace\n",
    "\n",
    "jinja_env.tests['list'] = lambda x: isinstance(x, list)\n",
    "\n",
    "\n",
    "import inspect\n",
    "jinja_env.tests['class'] = lambda x: inspect.isclass(x)\n",
    "\n",
    "\n",
    "def empty(x):\n",
    "    empty=True\n",
    "    for _, obj in x:\n",
    "        if isinstance(obj, list):\n",
    "            if len(obj) > 0:\n",
    "                empty=False\n",
    "        elif isinstance(obj, GraphicsCollection):\n",
    "            if len(obj.collection) > 0:\n",
    "                empty=False\n",
    "        elif obj is not None:\n",
    "            empty=False\n",
    "    return empty\n",
    "jinja_env.tests['empty'] = empty\n",
    "\n",
    "\n",
    "from pybtex.plugin import find_plugin\n",
    "from pybtex.database import parse_string\n",
    "def bib2html(citation, style, exclude_fields=None):\n",
    "    HTML = find_plugin('pybtex.backends', 'html')()\n",
    "    style = style.lower()\n",
    "    if style == \"apa\":\n",
    "        style = find_plugin('pybtex.style.formatting', style)()\n",
    "    else:\n",
    "        style = None\n",
    "    bibliography = parse_string(citation, 'bibtex')\n",
    "    exclude_fields = exclude_fields or []\n",
    "    if exclude_fields:\n",
    "        for entry in bibliography.entries.values():\n",
    "            for ef in exclude_fields:\n",
    "                if ef in entry.fields.__dict__['_dict']:\n",
    "                    del entry.fields.__dict__['_dict'][ef]\n",
    "    if style:\n",
    "        bibliography = style.format_bibliography(bibliography)\n",
    "    return \"<br>\".join(entry.text.render(HTML) for entry in bibliography)\n",
    "\n",
    "def render_citation(obj):\n",
    "    return bib2html(obj.citation, obj.style)\n",
    "jinja_env.filters['render_citation'] = render_citation\n",
    "\n",
    "template = jinja_env.get_template(\"cyclops_generic_template_dark.jinja\")\n",
    "\n",
    "content = template.render(\n",
    "    model_card=mc\n",
    ")\n",
    "\n",
    "with open(\"report.html\", \"w+\") as f:\n",
    "    f.write(content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycyclops-4J2PL5I8-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

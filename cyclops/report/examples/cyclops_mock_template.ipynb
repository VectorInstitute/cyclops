{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-concept",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "import category_encoders as ce\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    RocCurveDisplay,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from cyclops.report import ModelCardReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c984c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = ModelCardReport()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9126fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "report.log_from_dict(\n",
    "    {\n",
    "        \"description\": inspect.cleandoc(\n",
    "            \"\"\"\n",
    "            Sample example of a risk assessment of a credit card fraud model.\n",
    "            Binary prediction problem (fraud or no fraud). Customers flagged as\n",
    "            potentially fraudulent will be passed to internal investigation team\n",
    "            for follow-up.\"\"\"\n",
    "        ),\n",
    "        \"references\": [\n",
    "            {\n",
    "                \"link\": \"https://www.kaggle.com/mlg-ulb/creditcardfraud\",\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    \"Model Details\",\n",
    ")\n",
    "report.log_citation(\n",
    "    citation=inspect.cleandoc(\n",
    "        \"\"\"\n",
    "    Markelle Kelly, Rachel Longjohn, Kolby Nottingham, The UCI Machine Learning\n",
    "    Repository, https://archive.ics.uci.edu\n",
    "    \"\"\"\n",
    "    ),\n",
    ")\n",
    "report.log_license(identifier=\"MIT\", some_other_license=\"some other license\")\n",
    "report.log_owner(name=\"John Doe\", contact=\"john.doe@email.com\", role=\"Researcher\")\n",
    "report.log_version(\"1.0.0\", \"2021-01-01\", \"Initial release\")\n",
    "report.log_regulation(\"Accountability and Transparency (FEAT) principles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bd1196",
   "metadata": {},
   "outputs": [],
   "source": [
    "report.log_user(description=\"Credit card fraud team and credit card holders\")\n",
    "report.log_use_case(\n",
    "    description=inspect.cleandoc(\n",
    "        \"\"\"\n",
    "        Increase accuracy of predicting credit card fraud over the existing rule-based\n",
    "        model, saving the bank time and energy for each false positive case and\n",
    "        avoiding reputation harm from false negative cases.\"\"\"\n",
    "    )\n",
    ")\n",
    "report.log_descriptor(\n",
    "    name=\"limitation\",\n",
    "    description=\"The model is trained on a dataset that is highly unbalanced,\\\n",
    "        the positive class (frauds) account for 0.172% of all transactions.\",\n",
    "    section_name=\"considerations\",\n",
    ")\n",
    "report.log_descriptor(\n",
    "    name=\"tradeoff\",\n",
    "    description=\"The tradeoffs of using this model are that it can help banks\\\n",
    "            to detect fraudulent transactions, but it can lead to false positives,\\\n",
    "            which can lead to inconvenience for customers.\",\n",
    "    section_name=\"considerations\",\n",
    ")\n",
    "report.log_risk(\n",
    "    risk=\"The model is trained on a dataset that is highly unbalanced, \\\n",
    "        the positive class (frauds) account for 0.172% of all transactions.\",\n",
    "    mitigation_strategy=\"We can mitigate this by using a different dataset\\\n",
    "        that is more balanced.\",\n",
    ")\n",
    "report.log_fairness_assessment(\n",
    "    affected_group=\"Race, age, geneder\",\n",
    "    benefit=inspect.cleandoc(\n",
    "        \"\"\"\n",
    "        A more precise model will reduce the number of customers being mistakenly\n",
    "        labelled as fraudulent in the existing rules based model, which takes 7\n",
    "        man-days to resolve before a credit card could be unfrozen.\"\"\"\n",
    "    ),\n",
    "    harm=inspect.cleandoc(\n",
    "        \"\"\"\n",
    "        Customers who are in the false-positive category will have their credit card\n",
    "        frozen and may be excluded from the financial services of the bank for up\n",
    "        to 7 days.\"\"\"\n",
    "    ),\n",
    "    mitigation_strategy=inspect.cleandoc(\n",
    "        \"\"\"\n",
    "        Because there is less data for certain demographic groups (e.g. youth, elderly),\n",
    "        the model can have much higher/lower false-positive rates for that segment\n",
    "        than that of others. We will prioritize such cases after the initial model\n",
    "        score to add a 2nd level of check and minimise disruption to the customer.\"\"\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-south",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit card fraud Dataset\n",
    "df = pd.read_csv(\"data/fraud.csv\")\n",
    "\n",
    "# get 5000 samples of fraud and 5000 samples of non-fraud\n",
    "df = pd.concat(\n",
    "    [\n",
    "        df.loc[df.is_fraud == 1].sample(5000, replace=True),\n",
    "        df.loc[df.is_fraud == 0].sample(5000, replace=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# split out features and target\n",
    "x = df.drop(\"is_fraud\", axis=1)\n",
    "y = df[\"is_fraud\"]\n",
    "\n",
    "# Train-Test data Split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.5, random_state=50\n",
    ")\n",
    "\n",
    "\n",
    "# Build ML model with protected attributes as model features\n",
    "\n",
    "# Apply one hot encoding to categorical columns (auto-detect object columns)\n",
    "# and random forest model in the pipeline\n",
    "estimator = Pipeline(\n",
    "    steps=[\n",
    "        (\"onehot\", ce.OneHotEncoder(use_cat_names=True)),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            RandomForestClassifier(\n",
    "                n_estimators=4, max_features=\"sqrt\", random_state=882\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "report.log_model_parameters(estimator[-1].get_params())\n",
    "\n",
    "# Fit, predict and compute performance metrics\n",
    "estimator.fit(x_train, y_train)\n",
    "\n",
    "output = x_test.copy()  # x_test df with output columns, to be appended later\n",
    "y_pred = estimator.predict(x_test)\n",
    "y_probas = estimator.predict_proba(x_test)[::, 1]\n",
    "\n",
    "precision_train = round(precision_score(y_train, estimator.predict(x_train)), 3)\n",
    "recall_train = round(recall_score(y_train, estimator.predict(x_train)), 3)\n",
    "precision_test = round(precision_score(y_test, y_pred), 3)\n",
    "recall_test = round(recall_score(y_test, y_pred), 3)\n",
    "\n",
    "\n",
    "# Add output columns to this dataframe, to be used as a input for feat tests\n",
    "output[\"truth\"] = y_test\n",
    "output[\"prediction\"] = y_pred\n",
    "output[\"prediction_probas\"] = y_probas\n",
    "\n",
    "\n",
    "# Dataframe with categorical features encoded\n",
    "x_train_encoded = estimator[0].transform(x_train)\n",
    "x_test_encoded = estimator[0].transform(x_test)\n",
    "\n",
    "\n",
    "# Get feature importance values\n",
    "df_importance = pd.DataFrame(\n",
    "    {\"features\": x_test_encoded.columns, \"value\": estimator[-1].feature_importances_}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e578557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "report.log_performance_metrics(\n",
    "    {\n",
    "        \"train/precision\": precision_train,\n",
    "        \"train/recall\": recall_train,\n",
    "        \"test/precision\": precision_test,\n",
    "        \"test/recall\": recall_test,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "stuck-worship",
   "metadata": {},
   "source": [
    "## Get confusion matrix and ROC curve on train/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train set\n",
    "ConfusionMatrixDisplay.from_estimator(estimator, x_train, y_train)\n",
    "# confusion_matrix_train = plot_to_str()\n",
    "RocCurveDisplay.from_estimator(estimator, x_train, y_train)\n",
    "# roc_curve_train = plot_to_str()\n",
    "\n",
    "# Test set\n",
    "ConfusionMatrixDisplay.from_estimator(estimator, x_test, y_test)\n",
    "# confusion_matrix_test = plot_to_str()\n",
    "RocCurveDisplay.from_estimator(estimator, x_test, y_test)\n",
    "# roc_curve_test = plot_to_str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86783ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "report.export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyclops",
   "language": "python",
   "name": "cyclops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

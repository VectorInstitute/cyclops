{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-concept",
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "import jinja2\n",
    "import pandas as pd\n",
    "import plotly.offline as py\n",
    "from pydantic import BaseModel\n",
    "from pydantic.main import ModelMetaclass\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    RocCurveDisplay,\n",
    "    accuracy_score,\n",
    "    precision_recall_curve,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from cyclops.report.model_card.model_card import (\n",
    "    Citation,\n",
    "    Dataset,\n",
    "    FairnessAssessment,\n",
    "    Graphic,\n",
    "    GraphicsCollection,\n",
    "    KeyVal,\n",
    "    License,\n",
    "    Limitation,\n",
    "    ModelCard,\n",
    "    Owner,\n",
    "    PerformanceMetric,\n",
    "    Reference,\n",
    "    Risk,\n",
    "    SensitiveData,\n",
    "    Tradeoff,\n",
    "    UseCase,\n",
    "    User,\n",
    ")\n",
    "from cyclops.report.plot.classification import ClassificationPlotter\n",
    "from cyclops.report.plot.utils import fig_to_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-south",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit card fraud Dataset\n",
    "# df = pd.read_csv(\"data/fraud.csv\")\n",
    "df = pd.read_csv(\"creditcard.csv\")\n",
    "\n",
    "# get 5000 samples of fraud and 5000 samples of non-fraud\n",
    "#\n",
    "df = pd.concat(\n",
    "    [\n",
    "        df.loc[df.Class == 1].sample(5000, replace=True),\n",
    "        df.loc[df.Class == 0].sample(5000, replace=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# split out features and target\n",
    "x = df.drop(\"Class\", axis=1)\n",
    "y = df[\"Class\"]\n",
    "\n",
    "\n",
    "# split out features and target\n",
    "# x = df.drop(\"is_fraud\", axis=1)\n",
    "# y = df[\"is_fraud\"]\n",
    "\n",
    "# Train-Test data Split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.5, random_state=50\n",
    ")\n",
    "\n",
    "\n",
    "# Build ML model with protected attributes as model features\n",
    "\n",
    "# Apply one hot encoding to categorical columns (auto-detect object columns)\n",
    "# and random forest model in the pipeline\n",
    "estimator = Pipeline(\n",
    "    steps=[\n",
    "        (\"onehot\", ce.OneHotEncoder(use_cat_names=True)),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            RandomForestClassifier(\n",
    "                n_estimators=4, max_features=\"sqrt\", random_state=882\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Fit, predict and compute performance metrics\n",
    "estimator.fit(x_train, y_train)\n",
    "\n",
    "output = x_test.copy()  # x_test df with output columns, to be appended later\n",
    "y_pred = estimator.predict(x_test)\n",
    "y_probas = estimator.predict_proba(x_test)[::, 1]\n",
    "\n",
    "precision_train = round(precision_score(y_train, estimator.predict(x_train)), 3)\n",
    "recall_train = round(recall_score(y_train, estimator.predict(x_train)), 3)\n",
    "precision_test = round(precision_score(y_test, y_pred), 3)\n",
    "recall_test = round(recall_score(y_test, y_pred), 3)\n",
    "\n",
    "\n",
    "# Add output columns to this dataframe, to be used as a input for feat tests\n",
    "output[\"truth\"] = y_test\n",
    "output[\"prediction\"] = y_pred\n",
    "output[\"prediction_probas\"] = y_probas\n",
    "\n",
    "\n",
    "# Dataframe with categorical features encoded\n",
    "x_train_encoded = estimator[0].transform(x_train)\n",
    "x_test_encoded = estimator[0].transform(x_test)\n",
    "\n",
    "\n",
    "# Get feature importance values\n",
    "df_importance = pd.DataFrame(\n",
    "    {\"features\": x_test_encoded.columns, \"value\": estimator[-1].feature_importances_}\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "stuck-worship",
   "metadata": {},
   "source": [
    "## Get confusion matrix and ROC curve on train/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train set\n",
    "ConfusionMatrixDisplay.from_estimator(estimator, x_train, y_train)\n",
    "# confusion_matrix_train = plot_to_str()\n",
    "RocCurveDisplay.from_estimator(estimator, x_train, y_train)\n",
    "# roc_curve_train = plot_to_str()\n",
    "\n",
    "# Test set\n",
    "ConfusionMatrixDisplay.from_estimator(estimator, x_test, y_test)\n",
    "# confusion_matrix_test = plot_to_str()\n",
    "RocCurveDisplay.from_estimator(estimator, x_test, y_test)\n",
    "# roc_curve_test = plot_to_str()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4266061e",
   "metadata": {},
   "source": [
    "## Use ClassificationPlotter to to plot evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246266d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9309102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = ClassificationPlotter(task_type=\"binary\", class_names=[\"0\", \"1\"])\n",
    "plotter.set_template(\"plotly_white\")\n",
    "plotter.set_colorway([\"#006ba6\", \"#ffbc42\", \"#d81159\", \"#0496ff\", \"#8f2d56\"])\n",
    "\n",
    "precicion_recall_curve = precision_recall_curve(y_test, y_probas)\n",
    "prc_fig = plotter.precision_recall_curve(precicion_recall_curve)\n",
    "prc_str = fig_to_html(prc_fig)\n",
    "\n",
    "\n",
    "roc = roc_curve(y_test, y_probas)\n",
    "auroc = roc_auc_score(y_test, y_probas)\n",
    "roc_fig = plotter.roc_curve(roc, auroc=auroc)\n",
    "roc_str = fig_to_html(roc_fig)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "metrics_fig = plotter.classification_metrics(\n",
    "    {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall},\n",
    "    title_suffix=\"Test Set\",\n",
    ")\n",
    "metrics_str = fig_to_html(metrics_fig)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "human-martin",
   "metadata": {},
   "source": [
    "## Bootstrap model card from VerifyML model card editor and scaffold assets\n",
    "We can add the quantitative analysis, explainability analysis and fairness analysis sections to a bootstrap model card for convenience. In this example, we use an existing model card which we created from the [VerifyML model card editor](https://report.verifyml.com/create). This is meant only as an example - the dataset and risk evaluation in the model card is a fictional use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model card\n",
    "def scaffold_model(base_model: BaseModel) -> BaseModel:\n",
    "    \"\"\"Recursively initialize a pydantic model with default values.\"\"\"\n",
    "    assert isinstance(\n",
    "        base_model, BaseModel\n",
    "    ), f\"Expected a pydantic BaseModel instance, got {type(base_model)} instead.\"\n",
    "\n",
    "    for field in base_model.__fields__:\n",
    "        field_type = base_model.__fields__[field].type_\n",
    "\n",
    "        if (\n",
    "            type(field_type) is ModelMetaclass\n",
    "            and base_model.__fields__[field].default_factory is None\n",
    "        ):\n",
    "            sub_model = scaffold_model(field_type())\n",
    "            setattr(base_model, field, sub_model)\n",
    "        else:\n",
    "            default = base_model.__fields__[field].default\n",
    "            if base_model.__fields__[field].default_factory is not None:\n",
    "                default = base_model.__fields__[field].default_factory()\n",
    "            setattr(base_model, field, default)\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a42c62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = ModelCard()\n",
    "mc = scaffold_model(mc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff0664e9",
   "metadata": {},
   "source": [
    "## Populate model card fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0897a12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model details\n",
    "mc.model_details.name = \"Credit Card Fraud Detection\"\n",
    "\n",
    "mc.model_details.overview = \"This model predicts whether a credit card transaction \\\n",
    "    is fraudulent or not.\"\n",
    "\n",
    "mc.model_details.documentation = \"This model is trained on the Credit Card Fraud \\\n",
    "    Detection dataset from Kaggle. The dataset contains transactions made by credit \\\n",
    "    cards in September 2013 by European cardholders. This dataset presents \\\n",
    "    transactions that occurred in two days, where we have 492 frauds out of 284,807 \\\n",
    "    transactions. The dataset is highly unbalanced, the positive class (frauds) \\\n",
    "    account for 0.172% of all transactions. The model is trained on 80% of the data \\\n",
    "    and tested on the remaining 20%.\"\n",
    "\n",
    "mc.model_details.owners.append(Owner(name=\"John Doe\", contact=\"\", role=\"Researcher\"))\n",
    "\n",
    "mc.model_details.version.name = \"1.0\"\n",
    "mc.model_details.version.date = \"2021-01-01\"\n",
    "mc.model_details.version.diff = \"Initial release\"\n",
    "\n",
    "mc.model_details.licenses.append(\n",
    "    License(\n",
    "        identifier=\"Apache 2.0\",\n",
    "        custom_text=\"https://www.apache.org/licenses/LICENSE-2.0\",\n",
    "    )\n",
    ")\n",
    "mc.model_details.references.append(\n",
    "    Reference(reference=\"https://www.kaggle.com/mlg-ulb/creditcardfraud\")\n",
    ")\n",
    "mc.model_details.citations.append(\n",
    "    Citation(\n",
    "        style=\"APA\",\n",
    "        citation=\"Dua, D. and Graff, C. (2019). UCI Machine Learning Repository \\\n",
    "            [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, \\\n",
    "            School of Information and Computer Science.\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f764feb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "mc.model_parameters.model_architecture = \"Random Forest\"\n",
    "mc.model_parameters.data.append(  # training set\n",
    "    Dataset(\n",
    "        name=\"Credit Card Fraud Detection\",\n",
    "        split=\"train\",\n",
    "        size=len(x_train),\n",
    "        attributes=x.columns.tolist(),\n",
    "        sensitive=SensitiveData(\n",
    "            sensitive_data=[\"gender\", \"age\"],\n",
    "            sensitive_data_used=[\"gender\", \"age\"],\n",
    "            justification=\"Gender and age of the cardholder may be informative of\\\n",
    "                 the likelihood of fraud.\",\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "mc.model_parameters.data.append(  # test set\n",
    "    Dataset(\n",
    "        name=\"Credit Card Fraud Detection\",\n",
    "        split=\"test\",\n",
    "        size=len(x_test),\n",
    "        attributes=x.columns.tolist(),\n",
    "    )\n",
    ")\n",
    "mc.model_parameters.input_format = \"NumPy array\"\n",
    "mc.model_parameters.input_format_map.extend(\n",
    "    [\n",
    "        KeyVal(\n",
    "            key=\"x\",\n",
    "            value=\"NumPy array of shape (n_samples, n_features) containing the \\\n",
    "                input features.\",\n",
    "        ),\n",
    "        KeyVal(\n",
    "            key=\"y\",\n",
    "            value=\"NumPy array of shape (n_samples,) containing the target values.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "mc.model_parameters.output_format = \"NumPy array\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110e7ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# considerations\n",
    "mc.considerations.users.append(User(description=\"Data Scientists\")),\n",
    "mc.considerations.use_cases.append(\n",
    "    UseCase(\n",
    "        description=\"This model predicts whether a credit card transaction is \\\n",
    "            fraudulent or not.\"\n",
    "    )\n",
    ")\n",
    "mc.considerations.limitations.append(\n",
    "    Limitation(\n",
    "        description=\"The model is trained on a dataset that is highly unbalanced,\\\n",
    "              the positive class (frauds) account for 0.172% of all transactions.\"\n",
    "    )\n",
    ")\n",
    "mc.considerations.tradeoffs.append(\n",
    "    Tradeoff(\n",
    "        description=\"The tradeoffs of using this model are that it can help banks\\\n",
    "             to detect fraudulent transactions, but it can lead to false positives,\\\n",
    "             which can lead to inconvenience for customers.\"\n",
    "    )\n",
    ")\n",
    "mc.considerations.ethical_considerations.append(\n",
    "    Risk(\n",
    "        name=\"The model is trained on a dataset that is highly unbalanced, \\\n",
    "            the positive class (frauds) account for 0.172% of all transactions.\",\n",
    "        mitigation_strategy=\"We can mitigate this by using a different dataset\\\n",
    "            that is more balanced.\",\n",
    "    )\n",
    ")\n",
    "mc.considerations.fairness_assessment.append(\n",
    "    FairnessAssessment(\n",
    "        group_at_risk=\"Fraudulent transactions\",\n",
    "        benefits=\"The model can help banks to detect fraudulent transactions.\",\n",
    "        harms=\"The model can lead to false positives, which can lead to inconvenience\\\n",
    "            for customers.\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d6fe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantitative analysis\n",
    "\n",
    "# Create 4 PerformanceMetric to store our results\n",
    "mc.quantitative_analysis.performance_metrics = [\n",
    "    PerformanceMetric() for i in range(0, 6)\n",
    "]\n",
    "mc.quantitative_analysis.performance_metrics[0].type = \"Recall\"\n",
    "mc.quantitative_analysis.performance_metrics[0].value = recall_train\n",
    "mc.quantitative_analysis.performance_metrics[0].slice = \"Training Set\"\n",
    "\n",
    "mc.quantitative_analysis.performance_metrics[1].type = \"Precision\"\n",
    "mc.quantitative_analysis.performance_metrics[1].value = precision_train\n",
    "mc.quantitative_analysis.performance_metrics[1].slice = \"Training Set\"\n",
    "# mc.quantitative_analysis.performance_metrics[1].graphics.description = (\n",
    "#   'Confusion matrix and ROC Curve')\n",
    "# mc.quantitative_analysis.performance_metrics[1].graphics.collection = [\n",
    "#     Graphic(image=confusion_matrix_train), Graphic(image=roc_curve_train)\n",
    "# ]\n",
    "\n",
    "mc.quantitative_analysis.performance_metrics[2].type = \"Recall\"\n",
    "mc.quantitative_analysis.performance_metrics[2].value = recall_test\n",
    "mc.quantitative_analysis.performance_metrics[2].slice = \"Test Set\"\n",
    "\n",
    "mc.quantitative_analysis.performance_metrics[3].type = \"Precision\"\n",
    "mc.quantitative_analysis.performance_metrics[3].value = precision_test\n",
    "mc.quantitative_analysis.performance_metrics[3].slice = \"Test Set\"\n",
    "mc.quantitative_analysis.performance_metrics[3].graphics = GraphicsCollection()\n",
    "mc.quantitative_analysis.performance_metrics[3].graphics.collection = [\n",
    "    Graphic(image=metrics_str)\n",
    "]\n",
    "# mc.quantitative_analysis.performance_metrics[3].graphics.description = (\n",
    "#   'Confusion matrix and ROC Curve')\n",
    "# mc.quantitative_analysis.performance_metrics[3].graphics.collection = [\n",
    "#     Graphic(image=confusion_matrix_test), Graphic(image=roc_curve_test)\n",
    "# ]\n",
    "mc.quantitative_analysis.performance_metrics[4].type = \"Precision Recall Curve\"\n",
    "mc.quantitative_analysis.performance_metrics[4].slice = \"Test Set\"\n",
    "mc.quantitative_analysis.performance_metrics[4].graphics = GraphicsCollection()\n",
    "mc.quantitative_analysis.performance_metrics[4].graphics.collection = [\n",
    "    Graphic(image=prc_str)\n",
    "]\n",
    "\n",
    "mc.quantitative_analysis.performance_metrics[5].type = \"ROC Curve\"\n",
    "mc.quantitative_analysis.performance_metrics[5].slice = \"Test Set\"\n",
    "mc.quantitative_analysis.performance_metrics[5].graphics = GraphicsCollection()\n",
    "mc.quantitative_analysis.performance_metrics[5].graphics.collection = [\n",
    "    Graphic(image=roc_str)\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "superior-compact",
   "metadata": {},
   "source": [
    "## Model Card Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3224ae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "jinja_env = jinja2.Environment(\n",
    "    loader=jinja2.FileSystemLoader(\"../model_card/template/\"),\n",
    "    autoescape=True,\n",
    "    auto_reload=True,\n",
    "    cache_size=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca62624",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = jinja_env.get_template(\"cyclops_template.jinja\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae5b80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotlyjs = py.get_plotlyjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650f3f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = template.render(\n",
    "    plotlyjs=plotlyjs,\n",
    "    model_details=mc.model_details,\n",
    "    model_parameters=mc.model_parameters,\n",
    "    quantitative_analysis=mc.quantitative_analysis,\n",
    "    explainability_analysis=mc.explainability_analysis,\n",
    "    fairness_analysis=mc.fairness_analysis,\n",
    "    considerations=mc.considerations,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81df125",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"report.html\", \"w+\") as f:\n",
    "    f.write(content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cycenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

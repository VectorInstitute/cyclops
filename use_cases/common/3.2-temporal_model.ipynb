{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd4e001b-4921-4a4f-8c2c-0c364d082a3f",
   "metadata": {},
   "source": [
    "# Time-series modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4681dab-9200-4063-9544-f2013bdcd2ba",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cce5e9ec-e3d0-4719-a7ee-43e88dcde8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn import metrics\n",
    "\n",
    "from cyclops.processors.column_names import EVENT_NAME\n",
    "from cyclops.utils.file import load_pickle\n",
    "from drift_detection.baseline_models.temporal.pytorch.optimizer import Optimizer\n",
    "from drift_detection.baseline_models.temporal.pytorch.utils import (\n",
    "    get_data,\n",
    "    get_device,\n",
    "    get_temporal_model,\n",
    "    print_metrics_binary,\n",
    ")\n",
    "from use_cases.common.util import get_use_case_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84f6267-96ee-40f0-aab0-c695734fd583",
   "metadata": {},
   "source": [
    "# Choose dataset and use-case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1887c9ca-f290-4ce2-a085-da3e66044a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "WARNING: LOADING CONSTANTS FROM <module 'use_cases.gemini.mortality_decompensation.constants' from '/mnt/nfs/home/krishnanam/cyclops/use_cases/gemini/mortality_decompensation/constants.py'> \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET = \"gemini\"\n",
    "USE_CASE = \"mortality_decompensation\"\n",
    "\n",
    "use_case_params = get_use_case_params(DATASET, USE_CASE)\n",
    "input(f\"WARNING: LOADING CONSTANTS FROM {use_case_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e583ae-7a70-49d1-9e93-26b692c85d89",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9656bc84-fa96-4ee1-8359-3e8659ad6805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whether to use the combined data (tabular + temporal)\n",
    "# or simply the temporal data\n",
    "use_comb = True\n",
    "\n",
    "batch_size = 64\n",
    "output_dim = 1\n",
    "hidden_dim = 64\n",
    "layer_dim = 2\n",
    "dropout = 0.2\n",
    "n_epochs = 256\n",
    "learning_rate = 2e-3\n",
    "weight_decay = 1e-6\n",
    "last_timestep_only = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff98f1e3-e275-4719-a456-dd45c67b2069",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a65bf786-0156-4f77-9de2-909a8e206168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(vec):\n",
    "    arr = np.squeeze(vec.data, 0)\n",
    "    arr = np.moveaxis(arr, 2, 0)\n",
    "    arr = np.nan_to_num(arr)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76f54b30-f296-4def-9bb2-d325ee2e7807",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 14:03:23,980 \u001b[1;37mINFO\u001b[0m cyclops.utils.file - Loading pickled data from /mnt/nfs/project/delirium/cyclops/use_cases/gemini/mortality_decompensation/./data/4-final/aligned_comb_train_X.pkl\n",
      "2022-10-24 14:03:25,250 \u001b[1;37mINFO\u001b[0m cyclops.utils.file - Loading pickled data from /mnt/nfs/project/delirium/cyclops/use_cases/gemini/mortality_decompensation/./data/4-final/aligned_comb_train_y.pkl\n",
      "2022-10-24 14:03:25,332 \u001b[1;37mINFO\u001b[0m cyclops.utils.file - Loading pickled data from /mnt/nfs/project/delirium/cyclops/use_cases/gemini/mortality_decompensation/./data/4-final/aligned_comb_val_X.pkl\n",
      "2022-10-24 14:03:25,477 \u001b[1;37mINFO\u001b[0m cyclops.utils.file - Loading pickled data from /mnt/nfs/project/delirium/cyclops/use_cases/gemini/mortality_decompensation/./data/4-final/aligned_comb_val_y.pkl\n",
      "2022-10-24 14:03:25,486 \u001b[1;37mINFO\u001b[0m cyclops.utils.file - Loading pickled data from /mnt/nfs/project/delirium/cyclops/use_cases/gemini/mortality_decompensation/./data/4-final/aligned_comb_test_X.pkl\n",
      "2022-10-24 14:03:25,638 \u001b[1;37mINFO\u001b[0m cyclops.utils.file - Loading pickled data from /mnt/nfs/project/delirium/cyclops/use_cases/gemini/mortality_decompensation/./data/4-final/aligned_comb_test_y.pkl\n"
     ]
    }
   ],
   "source": [
    "if use_comb:\n",
    "    X_train_vec = load_pickle(use_case_params.TAB_VEC_COMB + \"comb_train_X\")\n",
    "    y_train_vec = load_pickle(use_case_params.TAB_VEC_COMB + \"comb_train_y\")\n",
    "    X_val_vec = load_pickle(use_case_params.TAB_VEC_COMB + \"comb_val_X\")\n",
    "    y_val_vec = load_pickle(use_case_params.TAB_VEC_COMB + \"comb_val_y\")\n",
    "    X_test_vec = load_pickle(use_case_params.TAB_VEC_COMB + \"comb_test_X\")\n",
    "    y_test_vec = load_pickle(use_case_params.TAB_VEC_COMB + \"comb_test_y\")\n",
    "else:\n",
    "    X_train_vec = load_pickle(use_case_params.TAB_VEC_COMB + \"temp_train_X\")\n",
    "    y_train_vec = load_pickle(use_case_params.TAB_VEC_COMB + \"temp_train_y\")\n",
    "    X_val_vec = load_pickle(use_case_params.TAB_VEC_COMB + \"temp_val_X\")\n",
    "    y_val_vec = load_pickle(use_case_params.TAB_VEC_COMB + \"temp_val_y\")\n",
    "    X_test_vec = load_pickle(use_case_params.TAB_VEC_COMB + \"temp_test_X\")\n",
    "    y_test_vec = load_pickle(use_case_params.TAB_VEC_COMB + \"temp_test_y\")\n",
    "\n",
    "X_train = prep(X_train_vec.data)\n",
    "y_train = prep(y_train_vec.data)\n",
    "X_val = prep(X_val_vec.data)\n",
    "y_val = prep(y_val_vec.data)\n",
    "X_test = prep(X_test_vec.data)\n",
    "y_test = prep(y_test_vec.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04361b4b-408f-4643-81d7-a86e52b29fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['admit_via_ambulance_', 'admit_via_ambulance_air',\n",
       "       'admit_via_ambulance_ground', 'admit_via_ambulance_no_ambulance',\n",
       "       'admit_via_ambulance_no_info', 'age', 'albumin', 'alp', 'alt',\n",
       "       'aptt', 'arterial paco2', 'arterial pao2', 'arterial ph', 'ast',\n",
       "       'bicarbonate', 'bilirubin', 'blood urea nitrogen', 'calcium',\n",
       "       'calcium, ionized', 'creatinine', 'crp', 'ct', 'd-dimer',\n",
       "       'diagnosis_trajectory_A00_B99', 'diagnosis_trajectory_C00_D49',\n",
       "       'diagnosis_trajectory_D50_D89', 'diagnosis_trajectory_E00_E89',\n",
       "       'diagnosis_trajectory_F01_F99', 'diagnosis_trajectory_G00_G99',\n",
       "       'diagnosis_trajectory_H00_H59', 'diagnosis_trajectory_H60_H95',\n",
       "       'diagnosis_trajectory_I00_I99', 'diagnosis_trajectory_J00_J99',\n",
       "       'diagnosis_trajectory_K00_K95', 'diagnosis_trajectory_L00_L99',\n",
       "       'diagnosis_trajectory_M00_M99', 'diagnosis_trajectory_N00_N99',\n",
       "       'diagnosis_trajectory_O00_O99', 'diagnosis_trajectory_Q00_Q99',\n",
       "       'diagnosis_trajectory_R00_R99', 'diagnosis_trajectory_S00_T88',\n",
       "       'diagnosis_trajectory_V00_Y99', 'diagnosis_trajectory_Z00_Z99',\n",
       "       'dialysis_mapped', 'echo', 'endoscopy_mapped', 'esr', 'ferritin',\n",
       "       'fibrinogen', 'from_acute_care_institution_mapped',\n",
       "       'from_nursing_home_mapped', 'glucose fasting',\n",
       "       'glucose point of care', 'glucose random', 'hba1c', 'hematocrit',\n",
       "       'hemoglobin', 'high sensitivity troponin', 'hospital_id_MSH',\n",
       "       'hospital_id_SBK', 'hospital_id_SMH', 'hospital_id_THPC',\n",
       "       'hospital_id_THPM', 'hospital_id_UHNTG', 'hospital_id_UHNTW',\n",
       "       'influenza', 'inr', 'interventional', 'inv_mech_vent_mapped',\n",
       "       'ketone', 'lactate arterial', 'lactate venous', 'ldh', 'lipase',\n",
       "       'lymphocyte', 'mean cell volume', 'mri', 'neutrophils', 'non-rbc',\n",
       "       'other', 'platelet count', 'potassium', 'prev_encounter_count',\n",
       "       'pt', 'rbc', 'readmission_', 'readmission_new_to_acute',\n",
       "       'readmission_nota', 'readmission_planned_from_acute',\n",
       "       'readmission_unplanned_7_day_acute',\n",
       "       'readmission_unplanned_7_day_day_surg',\n",
       "       'readmission_unplanned_8_to_28_day_acute', 'serum alcohol',\n",
       "       'serum osmolality', 'sex', 'sodium', 'surgery_mapped',\n",
       "       'triage_level_', 'triage_level_emergent', 'triage_level_no_info',\n",
       "       'triage_level_non-urgent', 'triage_level_resuscitation',\n",
       "       'triage_level_semi-urgent', 'triage_level_urgent', 'troponin',\n",
       "       'tsh', 'ultrasound', 'unmapped_intervention', 'urinalysis',\n",
       "       'urine osmolality', 'urine sodium', 'urine specific gravity',\n",
       "       'venous pco2', 'venous ph', 'vitamin b12', 'vitamin d',\n",
       "       'white blood cell count', 'x-ray'], dtype='<U39')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vec.get_index(EVENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75d041a8-142a-41de-bf27-1b7e353a4b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 106694, 118), (6, 106694, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "500b3307-0a5b-42e0-be22-f5f3b989e2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04802831774357821"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_train == 1).sum() / y_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a745850c-e9d6-417a-b81c-8919a246ff58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.,  0.,  1.]), array([241121, 368297,  30746]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3676e60d-4fe0-4b84-8067-523adbd5ed8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 13337, 118), (6, 13337, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e4578e0-ca27-4c6a-a38b-a87e4457f476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04753692734498013"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_val == 1).sum() / y_val.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e76157c-afe4-4b8f-b132-e94ce9b90779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.,  0.,  1.]), array([30067, 46151,  3804]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_val, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b492d92-48d1-4a44-a6f1-842330ed79d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 13337, 118), (6, 13337, 1))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abad0373-12d5-45ca-8502-ba6d437aa99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04858663867436455"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test == 1).sum() / y_test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97ea4d4b-27bf-447e-896d-0c195ce9b0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.,  0.,  1.]), array([30462, 45672,  3888]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1152bd98-00bf-45f2-af83-6ff5d64be909",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isnan(X_train).sum() == 0\n",
    "assert np.isnan(y_train).sum() == 0\n",
    "assert np.isnan(X_val).sum() == 0\n",
    "assert np.isnan(y_val).sum() == 0\n",
    "assert np.isnan(X_test).sum() == 0\n",
    "assert np.isnan(y_test).sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1df8e7a-a65e-46b9-9881-8eea1d10b4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_data(X_train, y_train)\n",
    "train_loader = train_dataset.to_loader(batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = get_data(X_val, y_val)\n",
    "val_loader = val_dataset.to_loader(batch_size)\n",
    "\n",
    "test_dataset = get_data(X_test, y_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b513c70d-8f5a-4620-8d0c-0f221684ca66",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_train.shape[2]\n",
    "timesteps = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4823c346-db3c-40f6-aa03-a7cad54aee17",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab2b413b-2442-4289-a178-7e09cc7675df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de703fc0-006e-49d1-a0df-fb99cdf7acb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"device\": device,\n",
    "    \"input_dim\": n_features,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"layer_dim\": layer_dim,\n",
    "    \"output_dim\": output_dim,\n",
    "    \"dropout_prob\": dropout,\n",
    "    \"last_timestep_only\": last_timestep_only,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70b823a8-b6cd-4312-8f8d-03184cfefa42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (lstm): LSTM(118, 64, num_layers=2, batch_first=True, dropout=0.2)\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_temporal_model(\"lstm\", model_params).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388af42e-49ac-48c5-a285-8ce66a714518",
   "metadata": {},
   "source": [
    "# Training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd5ba463-b493-46f6-8ec9-90774ae35b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.978696415793925"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reweight_positive = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "reweight_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89bdb2aa-8cb2-4632-b6bd-753033903716",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "optimizer = optim.Adagrad(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=weight_decay\n",
    ")\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=128, gamma=0.5)\n",
    "activation = nn.Sigmoid()\n",
    "opt = Optimizer(\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    activation=activation,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    reweight_positive=\"mini-batch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcaebba-37d7-4972-9262-c495f52d876e",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23618166-deb0-4422-918b-eb600c342e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/256] Training loss: 1.2805\t Validation loss: 1.2781\n",
      "[2/256] Training loss: 1.2771\t Validation loss: 1.2758\n",
      "[3/256] Training loss: 1.2747\t Validation loss: 1.2735\n",
      "[4/256] Training loss: 1.2723\t Validation loss: 1.2710\n",
      "[5/256] Training loss: 1.2699\t Validation loss: 1.2683\n",
      "[6/256] Training loss: 1.2671\t Validation loss: 1.2653\n",
      "[7/256] Training loss: 1.2641\t Validation loss: 1.2621\n",
      "[8/256] Training loss: 1.2607\t Validation loss: 1.2584\n",
      "[9/256] Training loss: 1.2571\t Validation loss: 1.2545\n",
      "[10/256] Training loss: 1.2531\t Validation loss: 1.2501\n",
      "[11/256] Training loss: 1.2486\t Validation loss: 1.2453\n",
      "[12/256] Training loss: 1.2436\t Validation loss: 1.2400\n",
      "[13/256] Training loss: 1.2382\t Validation loss: 1.2340\n",
      "[14/256] Training loss: 1.2320\t Validation loss: 1.2272\n",
      "[15/256] Training loss: 1.2252\t Validation loss: 1.2195\n",
      "[16/256] Training loss: 1.2172\t Validation loss: 1.2105\n",
      "[17/256] Training loss: 1.2078\t Validation loss: 1.2005\n",
      "[18/256] Training loss: 1.1973\t Validation loss: 1.1903\n",
      "[19/256] Training loss: 1.1864\t Validation loss: 1.1802\n",
      "[20/256] Training loss: 1.1759\t Validation loss: 1.1697\n",
      "[21/256] Training loss: 1.1649\t Validation loss: 1.1587\n",
      "[22/256] Training loss: 1.1533\t Validation loss: 1.1469\n",
      "[23/256] Training loss: 1.1413\t Validation loss: 1.1342\n",
      "[24/256] Training loss: 1.1282\t Validation loss: 1.1209\n",
      "[25/256] Training loss: 1.1148\t Validation loss: 1.1077\n",
      "[26/256] Training loss: 1.1017\t Validation loss: 1.0962\n",
      "[27/256] Training loss: 1.0906\t Validation loss: 1.0851\n",
      "[28/256] Training loss: 1.0809\t Validation loss: 1.0773\n",
      "[29/256] Training loss: 1.0716\t Validation loss: 1.0662\n",
      "[30/256] Training loss: 1.0620\t Validation loss: 1.0586\n",
      "[31/256] Training loss: 1.0535\t Validation loss: 1.0486\n",
      "[32/256] Training loss: 1.0443\t Validation loss: 1.0414\n",
      "[33/256] Training loss: 1.0360\t Validation loss: 1.0333\n",
      "[34/256] Training loss: 1.0293\t Validation loss: 1.0268\n",
      "[35/256] Training loss: 1.0213\t Validation loss: 1.0197\n",
      "[36/256] Training loss: 1.0141\t Validation loss: 1.0137\n",
      "[37/256] Training loss: 1.0084\t Validation loss: 1.0077\n",
      "[38/256] Training loss: 1.0019\t Validation loss: 1.0023\n",
      "[39/256] Training loss: 0.9966\t Validation loss: 0.9971\n",
      "[40/256] Training loss: 0.9917\t Validation loss: 0.9923\n",
      "[41/256] Training loss: 0.9864\t Validation loss: 0.9877\n",
      "[42/256] Training loss: 0.9809\t Validation loss: 0.9834\n",
      "[43/256] Training loss: 0.9775\t Validation loss: 0.9794\n",
      "[44/256] Training loss: 0.9721\t Validation loss: 0.9755\n",
      "[45/256] Training loss: 0.9688\t Validation loss: 0.9719\n",
      "[46/256] Training loss: 0.9649\t Validation loss: 0.9685\n",
      "[47/256] Training loss: 0.9613\t Validation loss: 0.9652\n",
      "[48/256] Training loss: 0.9579\t Validation loss: 0.9622\n",
      "[49/256] Training loss: 0.9552\t Validation loss: 0.9593\n",
      "[50/256] Training loss: 0.9513\t Validation loss: 0.9565\n",
      "[51/256] Training loss: 0.9485\t Validation loss: 0.9538\n",
      "[52/256] Training loss: 0.9455\t Validation loss: 0.9513\n",
      "[53/256] Training loss: 0.9419\t Validation loss: 0.9489\n",
      "[54/256] Training loss: 0.9401\t Validation loss: 0.9466\n",
      "[55/256] Training loss: 0.9378\t Validation loss: 0.9443\n",
      "[56/256] Training loss: 0.9349\t Validation loss: 0.9422\n",
      "[57/256] Training loss: 0.9330\t Validation loss: 0.9402\n",
      "[58/256] Training loss: 0.9306\t Validation loss: 0.9382\n",
      "[59/256] Training loss: 0.9293\t Validation loss: 0.9363\n",
      "[60/256] Training loss: 0.9264\t Validation loss: 0.9345\n",
      "[61/256] Training loss: 0.9251\t Validation loss: 0.9328\n",
      "[62/256] Training loss: 0.9227\t Validation loss: 0.9311\n",
      "[63/256] Training loss: 0.9207\t Validation loss: 0.9294\n",
      "[64/256] Training loss: 0.9185\t Validation loss: 0.9278\n",
      "[65/256] Training loss: 0.9174\t Validation loss: 0.9263\n",
      "[66/256] Training loss: 0.9159\t Validation loss: 0.9249\n",
      "[67/256] Training loss: 0.9138\t Validation loss: 0.9234\n",
      "[68/256] Training loss: 0.9119\t Validation loss: 0.9220\n",
      "[69/256] Training loss: 0.9107\t Validation loss: 0.9207\n",
      "[70/256] Training loss: 0.9095\t Validation loss: 0.9194\n",
      "[71/256] Training loss: 0.9075\t Validation loss: 0.9181\n",
      "[72/256] Training loss: 0.9064\t Validation loss: 0.9168\n",
      "[73/256] Training loss: 0.9050\t Validation loss: 0.9156\n",
      "[74/256] Training loss: 0.9038\t Validation loss: 0.9145\n",
      "[75/256] Training loss: 0.9025\t Validation loss: 0.9134\n",
      "[76/256] Training loss: 0.9007\t Validation loss: 0.9123\n",
      "[77/256] Training loss: 0.8998\t Validation loss: 0.9113\n",
      "[78/256] Training loss: 0.8981\t Validation loss: 0.9102\n",
      "[79/256] Training loss: 0.8976\t Validation loss: 0.9092\n",
      "[80/256] Training loss: 0.8957\t Validation loss: 0.9082\n",
      "[81/256] Training loss: 0.8945\t Validation loss: 0.9074\n",
      "[82/256] Training loss: 0.8948\t Validation loss: 0.9065\n",
      "[83/256] Training loss: 0.8929\t Validation loss: 0.9057\n",
      "[84/256] Training loss: 0.8925\t Validation loss: 0.9048\n",
      "[85/256] Training loss: 0.8906\t Validation loss: 0.9039\n",
      "[86/256] Training loss: 0.8903\t Validation loss: 0.9030\n",
      "[87/256] Training loss: 0.8898\t Validation loss: 0.9023\n",
      "[88/256] Training loss: 0.8890\t Validation loss: 0.9014\n",
      "[89/256] Training loss: 0.8865\t Validation loss: 0.9005\n",
      "[90/256] Training loss: 0.8862\t Validation loss: 0.8996\n",
      "[91/256] Training loss: 0.8849\t Validation loss: 0.8989\n",
      "[92/256] Training loss: 0.8833\t Validation loss: 0.8981\n",
      "[93/256] Training loss: 0.8828\t Validation loss: 0.8973\n",
      "[94/256] Training loss: 0.8823\t Validation loss: 0.8966\n",
      "[95/256] Training loss: 0.8812\t Validation loss: 0.8958\n",
      "[96/256] Training loss: 0.8808\t Validation loss: 0.8951\n",
      "[97/256] Training loss: 0.8799\t Validation loss: 0.8945\n",
      "[98/256] Training loss: 0.8792\t Validation loss: 0.8938\n",
      "[99/256] Training loss: 0.8785\t Validation loss: 0.8932\n",
      "[100/256] Training loss: 0.8773\t Validation loss: 0.8925\n",
      "[101/256] Training loss: 0.8763\t Validation loss: 0.8919\n",
      "[102/256] Training loss: 0.8762\t Validation loss: 0.8913\n",
      "[103/256] Training loss: 0.8765\t Validation loss: 0.8908\n",
      "[104/256] Training loss: 0.8744\t Validation loss: 0.8901\n",
      "[105/256] Training loss: 0.8744\t Validation loss: 0.8896\n",
      "[106/256] Training loss: 0.8722\t Validation loss: 0.8891\n",
      "[107/256] Training loss: 0.8718\t Validation loss: 0.8884\n",
      "[108/256] Training loss: 0.8703\t Validation loss: 0.8879\n",
      "[109/256] Training loss: 0.8698\t Validation loss: 0.8873\n",
      "[110/256] Training loss: 0.8694\t Validation loss: 0.8868\n",
      "[111/256] Training loss: 0.8701\t Validation loss: 0.8864\n",
      "[112/256] Training loss: 0.8688\t Validation loss: 0.8859\n",
      "[113/256] Training loss: 0.8684\t Validation loss: 0.8853\n",
      "[114/256] Training loss: 0.8669\t Validation loss: 0.8849\n",
      "[115/256] Training loss: 0.8659\t Validation loss: 0.8843\n",
      "[116/256] Training loss: 0.8652\t Validation loss: 0.8839\n",
      "[117/256] Training loss: 0.8648\t Validation loss: 0.8834\n",
      "[118/256] Training loss: 0.8651\t Validation loss: 0.8830\n",
      "[119/256] Training loss: 0.8639\t Validation loss: 0.8825\n",
      "[120/256] Training loss: 0.8640\t Validation loss: 0.8821\n",
      "[121/256] Training loss: 0.8628\t Validation loss: 0.8817\n",
      "[122/256] Training loss: 0.8614\t Validation loss: 0.8812\n",
      "[123/256] Training loss: 0.8622\t Validation loss: 0.8808\n",
      "[124/256] Training loss: 0.8608\t Validation loss: 0.8805\n",
      "[125/256] Training loss: 0.8608\t Validation loss: 0.8800\n",
      "[126/256] Training loss: 0.8595\t Validation loss: 0.8797\n",
      "[127/256] Training loss: 0.8586\t Validation loss: 0.8793\n",
      "[128/256] Training loss: 0.8578\t Validation loss: 0.8790\n",
      "[129/256] Training loss: 0.8574\t Validation loss: 0.8786\n",
      "[130/256] Training loss: 0.8578\t Validation loss: 0.8785\n",
      "[131/256] Training loss: 0.8558\t Validation loss: 0.8783\n",
      "[132/256] Training loss: 0.8568\t Validation loss: 0.8781\n",
      "[133/256] Training loss: 0.8565\t Validation loss: 0.8779\n",
      "[134/256] Training loss: 0.8566\t Validation loss: 0.8778\n",
      "[135/256] Training loss: 0.8560\t Validation loss: 0.8776\n",
      "[136/256] Training loss: 0.8553\t Validation loss: 0.8774\n",
      "[137/256] Training loss: 0.8554\t Validation loss: 0.8772\n",
      "[138/256] Training loss: 0.8562\t Validation loss: 0.8771\n",
      "[139/256] Training loss: 0.8540\t Validation loss: 0.8769\n",
      "[140/256] Training loss: 0.8552\t Validation loss: 0.8767\n",
      "[141/256] Training loss: 0.8545\t Validation loss: 0.8766\n",
      "[142/256] Training loss: 0.8539\t Validation loss: 0.8764\n",
      "[143/256] Training loss: 0.8540\t Validation loss: 0.8763\n",
      "[144/256] Training loss: 0.8547\t Validation loss: 0.8761\n",
      "[145/256] Training loss: 0.8537\t Validation loss: 0.8759\n",
      "[146/256] Training loss: 0.8535\t Validation loss: 0.8758\n",
      "[147/256] Training loss: 0.8533\t Validation loss: 0.8756\n"
     ]
    }
   ],
   "source": [
    "opt.train(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    batch_size=batch_size,\n",
    "    n_epochs=n_epochs,\n",
    "    n_features=n_features,\n",
    "    timesteps=timesteps,\n",
    ")\n",
    "opt.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a11dbaa-02e3-4415-84ee-abc159a5337a",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f74137-9a38-40c6-92ee-1e6f4e02290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_labels, y_pred_values, y_pred_labels = opt.evaluate(\n",
    "    test_loader, batch_size=1, n_features=n_features, timesteps=timesteps\n",
    ")\n",
    "\n",
    "y_pred_values = y_pred_values[y_test_labels != -1]\n",
    "y_pred_labels = y_pred_labels[y_test_labels != -1]\n",
    "y_test_labels = y_test_labels[y_test_labels != -1]\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_test_labels, y_pred_labels)\n",
    "print(confusion_matrix)\n",
    "\n",
    "pred_metrics = print_metrics_binary(y_test_labels, y_pred_values, y_pred_labels)\n",
    "prec = (pred_metrics[\"prec0\"] + pred_metrics[\"prec1\"]) / 2\n",
    "rec = (pred_metrics[\"rec0\"] + pred_metrics[\"rec1\"]) / 2\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612d8bf4-79c5-449f-ad60-f20217377827",
   "metadata": {},
   "source": [
    "## Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449a9b82-1081-4140-814f-a5ce083662ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(confusion_matrix, class_names):\n",
    "    confusion_matrix = (\n",
    "        confusion_matrix.astype(\"float\") / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
    "    )\n",
    "\n",
    "    layout = {\n",
    "        \"title\": \"Confusion Matrix\",\n",
    "        \"xaxis\": {\"title\": \"Predicted value\"},\n",
    "        \"yaxis\": {\"title\": \"Real value\"},\n",
    "    }\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=go.Heatmap(\n",
    "            z=confusion_matrix,\n",
    "            x=class_names,\n",
    "            y=class_names,\n",
    "            hoverongaps=False,\n",
    "            colorscale=\"Greens\",\n",
    "        ),\n",
    "        layout=layout,\n",
    "    )\n",
    "    fig.update_layout(height=512, width=1024)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "plot_confusion_matrix(\n",
    "    confusion_matrix, [\"low risk of mortality\", \"high risk of mortality\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b930e-ed63-454c-91af-0d0863a2a6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_labels, y_pred_values, y_pred_labels = opt.evaluate(\n",
    "    test_loader, batch_size=1, n_features=n_features, timesteps=timesteps, flatten=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8825f3a-a941-456b-b418-db620c224eb0",
   "metadata": {},
   "source": [
    "## Visualize model outputs and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6fbfab-57bc-4f07-9645-740b588d2ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_risk_mortality(predictions, labels=None):\n",
    "    prediction_hours = list(range(24, 168, 24))\n",
    "    is_mortality = labels == 1\n",
    "    after_discharge = labels == -1\n",
    "    label_h = -0.2\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Scatter(\n",
    "                mode=\"markers\",\n",
    "                x=prediction_hours,\n",
    "                y=[label_h for x in prediction_hours],\n",
    "                line=dict(color=\"Black\"),\n",
    "                name=\"low risk of mortality label\",\n",
    "                marker=dict(color=\"Green\", size=20, line=dict(color=\"Black\", width=2)),\n",
    "            ),\n",
    "            go.Scatter(\n",
    "                mode=\"markers\",\n",
    "                x=[prediction_hours[i] for i, v in enumerate(is_mortality) if v],\n",
    "                y=[label_h for _, v in enumerate(is_mortality) if v],\n",
    "                line=dict(color=\"Red\"),\n",
    "                name=\"high risk of mortality label\",\n",
    "                marker=dict(color=\"Red\", size=20, line=dict(color=\"Black\", width=2)),\n",
    "            ),\n",
    "            go.Scatter(\n",
    "                mode=\"markers\",\n",
    "                x=[prediction_hours[i] for i, v in enumerate(after_discharge) if v],\n",
    "                y=[label_h for _, v in enumerate(after_discharge) if v],\n",
    "                line=dict(color=\"Grey\"),\n",
    "                name=\"post discharge label\",\n",
    "                marker=dict(color=\"Grey\", size=20, line=dict(color=\"Black\", width=2)),\n",
    "            ),\n",
    "            go.Bar(\n",
    "                x=prediction_hours,\n",
    "                y=predictions,\n",
    "                marker_color=\"Red\",\n",
    "                name=\"model confidence\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    fig.update_yaxes(range=[label_h, 1])\n",
    "    fig.update_xaxes(tickvals=prediction_hours)\n",
    "    fig.update_xaxes(showline=True, linewidth=2, linecolor=\"black\")\n",
    "\n",
    "    fig.add_hline(y=0.5)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Model output visualization\",\n",
    "        autosize=False,\n",
    "        xaxis_title=\"No. of hours after admission\",\n",
    "        yaxis_title=\"Model confidence\",\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "mortality_cases = list(range(y_test_labels.shape[1]))\n",
    "sample_idx = random.choice(mortality_cases)\n",
    "fig = plot_risk_mortality(\n",
    "    y_pred_values[:, sample_idx].squeeze(), y_test_labels[:, sample_idx].squeeze()\n",
    ")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyclops",
   "language": "python",
   "name": "cyclops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

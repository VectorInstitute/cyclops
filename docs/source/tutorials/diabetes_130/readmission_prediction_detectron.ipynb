{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readmission Prediction Detectron Implementation\n",
    "\n",
    "This notebook showcases readmission prediction on the [Diabetes 130-US Hospitals for Years 1999-2008](https://archive.ics.uci.edu/dataset/296/diabetes+130-us+hospitals+for+years+1999-2008) using CyclOps. The task is formulated as a binary classification task, where we predict the probability of early readmission of the patient within 30 days of discharge.  The model health is then evaluated on a\n",
    "held-out test set using the [Detectron](https://github.com/rgklab/detectron) method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pycyclops[xgboost]\n",
    "!pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"Readmission prediction.\"\"\"\n",
    "\n",
    "# ruff: noqa: E402\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from datasets import Dataset, DatasetDict\n",
    "from datasets.features import ClassLabel\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "from cyclops.data.df.feature import TabularFeatures\n",
    "from cyclops.evaluate.metrics import create_metric\n",
    "from cyclops.evaluate.metrics.experimental.metric_dict import MetricDict\n",
    "from cyclops.models.catalog import create_model\n",
    "from cyclops.monitor.tester import Detectron\n",
    "from cyclops.report.utils import flatten_results_dict\n",
    "from cyclops.tasks import BinaryTabularClassificationTask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 85\n",
    "NAN_THRESHOLD = 0.75\n",
    "TRAIN_SIZE = 0.05\n",
    "EVAL_NUM = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diabetes_130_data = fetch_ucirepo(id=296)\n",
    "features = diabetes_130_data[\"data\"][\"features\"]\n",
    "targets = diabetes_130_data[\"data\"][\"targets\"]\n",
    "metadata = diabetes_130_data[\"metadata\"]\n",
    "variables = diabetes_130_data[\"variables\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform_label(value):\n",
    "    \"\"\"Transform string labels of readmission into 0/1 binary labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    value: str\n",
    "        Input value\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        0 if not readmitted or if greater than 30 days, 1 if less than 30 days\n",
    "\n",
    "    \"\"\"\n",
    "    if value in [\"NO\", \">30\"]:\n",
    "        return 0\n",
    "    if value == \"<30\":\n",
    "        return 1\n",
    "\n",
    "    raise ValueError(\"Unexpected value for readmission!\")\n",
    "\n",
    "\n",
    "df = features\n",
    "targets[\"readmitted\"] = targets[\"readmitted\"].apply(transform_label)\n",
    "df[\"readmitted\"] = targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a small subset for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[0:1000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove features that are NaNs or have just a single unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"outcome\"] = df[\"readmitted\"].astype(\"int\")\n",
    "df = df.drop(columns=[\"readmitted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_to_remove = []\n",
    "for col in df:\n",
    "    if len(df[col].value_counts()) <= 1:\n",
    "        features_to_remove.append(col)\n",
    "df = df.drop(columns=features_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_counts = df[\"outcome\"].value_counts()\n",
    "class_ratio = class_counts[0] / class_counts[1]\n",
    "print(class_ratio, class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the features in the dataset, we select all of them to train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_list = list(df.columns)\n",
    "features_list.remove(\"outcome\")\n",
    "features_list = sorted(features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying feature types\n",
    "\n",
    "Cyclops `TabularFeatures` class helps to identify feature types, an essential step before preprocessing the data. Understanding feature types (numerical/categorical/binary) allows us to apply appropriate preprocessing steps for each type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tab_features = TabularFeatures(\n",
    "    data=df.reset_index(),\n",
    "    features=features_list,\n",
    "    by=\"index\",\n",
    "    targets=\"outcome\",\n",
    ")\n",
    "print(tab_features.types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating data preprocessors\n",
    "\n",
    "We create a data preprocessor using sklearn's ColumnTransformer. This helps in applying different preprocessing steps to different columns in the dataframe. For instance, binary features might be processed differently from numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())],\n",
    ")\n",
    "\n",
    "binary_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"most_frequent\"))],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_features = sorted((tab_features.features_by_type(\"numeric\")))\n",
    "numeric_indices = [\n",
    "    df[features_list].columns.get_loc(column) for column in numeric_features\n",
    "]\n",
    "print(numeric_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "binary_features = sorted(tab_features.features_by_type(\"binary\"))\n",
    "binary_features.remove(\"outcome\")\n",
    "ordinal_features = sorted(\n",
    "    tab_features.features_by_type(\"ordinal\")\n",
    "    + [\"medical_specialty\", \"diag_1\", \"diag_2\", \"diag_3\"]\n",
    ")\n",
    "binary_indices = [\n",
    "    df[features_list].columns.get_loc(column) for column in binary_features\n",
    "]\n",
    "ordinal_indices = [\n",
    "    df[features_list].columns.get_loc(column) for column in ordinal_features\n",
    "]\n",
    "print(binary_features, ordinal_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_indices),\n",
    "        (\n",
    "            \"onehot\",\n",
    "            OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
    "            binary_indices + ordinal_indices,\n",
    "        ),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Hugging Face Dataset\n",
    "\n",
    "We convert our processed Pandas dataframe into a Hugging Face dataset, a powerful and easy-to-use data format which is also compatible with CyclOps models and evaluator modules. The dataset is then split to train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df)\n",
    "dataset.cleanup_cache_files()\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = dataset.cast_column(\"outcome\", ClassLabel(num_classes=2))\n",
    "dataset = dataset.train_test_split(\n",
    "    train_size=TRAIN_SIZE,\n",
    "    stratify_by_column=\"outcome\",\n",
    "    seed=RANDOM_SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation\n",
    "\n",
    "CyclOps model registry allows for straightforward creation and selection of models. This registry maintains a list of pre-configured models, which can be instantiated with a single line of code. Here we use a SGD classifier to fit a logisitic regression model. The model configurations can be passed to `create_model` based on the sklearn parameters for SGDClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"xgb_classifier\"\n",
    "model = create_model(model_name, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Creation\n",
    "\n",
    "We use Cyclops tasks to define our model's task (in this case, readmission prediction), train the model, make predictions, and evaluate performance. Cyclops task classes encapsulate the entire ML pipeline into a single, cohesive structure, making the process smooth and easy to manage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "readmission_prediction_task = BinaryTabularClassificationTask(\n",
    "    {model_name: model},\n",
    "    task_features=features_list,\n",
    "    task_target=\"outcome\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "readmission_prediction_task.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "If `best_model_params` is passed to the `train` method, the best model will be selected after the hyperparameter search. The parameters in `best_model_params` indicate the values to create the parameters grid.\n",
    "\n",
    "Note that the data preprocessor needs to be passed to the tasks methods if the Hugging Face dataset is not already preprocessed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model_params = {\n",
    "    \"n_estimators\": [100, 250, 500],\n",
    "    \"learning_rate\": [0.1, 0.01],\n",
    "    \"max_depth\": [2, 5],\n",
    "    \"reg_lambda\": [0, 1, 10],\n",
    "    \"colsample_bytree\": [0.7, 0.8, 1],\n",
    "    \"gamma\": [0, 1, 2, 10],\n",
    "    \"method\": \"random\",\n",
    "    \"scale_pos_weight\": [int(class_ratio)],\n",
    "}\n",
    "dataset[\"train\"] = dataset[\"train\"].train_test_split(train_size=0.8, seed=RANDOM_SEED)\n",
    "\n",
    "train_dataset = dataset[\"train\"]\n",
    "val = train_dataset.pop(\"test\")\n",
    "train_dataset[\"validation\"] = val\n",
    "\n",
    "readmission_prediction_task.train(\n",
    "    train_dataset,\n",
    "    model_name=model_name,\n",
    "    transforms=preprocessor,\n",
    "    best_model_params=best_model_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = readmission_prediction_task.list_models_params()[model_name]\n",
    "print(model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize detectron model with pre-trained weights and training/validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = Detectron(\n",
    "    X_s=dataset[\"train\"],\n",
    "    base_model=readmission_prediction_task.models[\"xgb_classifier\"],\n",
    "    feature_column=features_list,\n",
    "    transforms=preprocessor,\n",
    "    splits_mapping={\"train\": \"train\", \"test\": \"validation\"},\n",
    "    sample_size=50,\n",
    "    num_runs=5,\n",
    "    ensemble_size=5,\n",
    "    task=\"binary\",\n",
    "    save_dir=\"detectron\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get model health using the training data and all the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = tester.predict(\n",
    "    X_t=DatasetDict({\"train\": dataset[\"train\"][\"train\"], \"validation\": dataset[\"test\"]})\n",
    ")\n",
    "print(results[\"data\"][\"model_health\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the test data into multiple bins and plot the model health and performance metrics for each bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = dataset[\"test\"]\n",
    "test_data_list = []\n",
    "\n",
    "indices = np.arange(0, len(test_data))\n",
    "\n",
    "bins = np.array_split(indices, 20)\n",
    "\n",
    "for b in bins:\n",
    "    test_data_list.append(test_data.select(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = [\n",
    "    \"binary_accuracy\",\n",
    "    \"binary_precision\",\n",
    "    \"binary_recall\",\n",
    "    \"binary_f1_score\",\n",
    "    \"binary_auroc\",\n",
    "    \"binary_average_precision\",\n",
    "    \"binary_roc_curve\",\n",
    "    \"binary_precision_recall_curve\",\n",
    "]\n",
    "metrics = [\n",
    "    create_metric(metric_name, experimental=True) for metric_name in metric_names\n",
    "]\n",
    "metric_collection = MetricDict(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []\n",
    "for data in test_data_list:\n",
    "    results, dataset_with_preds = readmission_prediction_task.evaluate(\n",
    "        dataset=data,\n",
    "        metrics=metric_collection,\n",
    "        model_names=model_name,\n",
    "        transforms=preprocessor,\n",
    "        prediction_column_prefix=\"preds\",\n",
    "        batch_size=-1,\n",
    "        override_fairness_metrics=False,\n",
    "    )\n",
    "    results_list.append(flatten_results_dict(results)[\"model_for_preds.xgb_classifier\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_health = []\n",
    "for data in test_data_list:\n",
    "    results = tester.predict(\n",
    "        X_t=DatasetDict({\"train\": dataset[\"train\"][\"train\"], \"validation\": data})\n",
    "    )\n",
    "    model_health.append(results[\"data\"][\"model_health\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score = [result[\"overall/BinaryF1Score\"] for result in results_list]\n",
    "precision = [result[\"overall/BinaryPrecision\"] for result in results_list]\n",
    "recall = [result[\"overall/BinaryRecall\"] for result in results_list]\n",
    "auroc = [result[\"overall/BinaryAUROC\"] for result in results_list]\n",
    "average_precision = [\n",
    "    result[\"overall/BinaryAveragePrecision\"] for result in results_list\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_health_df = pd.DataFrame(\n",
    "    {\n",
    "        \"bin\": np.arange(0, len(model_health)),\n",
    "        \"model_health\": model_health,\n",
    "        \"f1_score\": f1_score,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"auroc\": auroc,\n",
    "        \"average_precision\": average_precision,\n",
    "    }\n",
    ")\n",
    "model_health_df = model_health_df.astype(float)\n",
    "\n",
    "# Define metrics to plot\n",
    "metrics = [\"f1_score\", \"precision\", \"recall\", \"auroc\", \"average_precision\"]\n",
    "\n",
    "# Define a color palette for metrics\n",
    "metric_colors = {\n",
    "    \"f1_score\": \"red\",\n",
    "    \"precision\": \"green\",\n",
    "    \"recall\": \"purple\",\n",
    "    \"auroc\": \"orange\",\n",
    "    \"average_precision\": \"brown\",\n",
    "}\n",
    "\n",
    "# Create subplots with secondary_y set to True for all subplots\n",
    "fig = make_subplots(\n",
    "    rows=len(metrics),\n",
    "    cols=1,\n",
    "    shared_xaxes=True,\n",
    "    vertical_spacing=0.05,\n",
    "    subplot_titles=[\n",
    "        f\"Model Health and {metric.replace('_', ' ').title()}\" for metric in metrics\n",
    "    ],\n",
    "    specs=[[{\"secondary_y\": True}] for _ in metrics],\n",
    ")\n",
    "\n",
    "# Add traces for each metric\n",
    "for i, metric in enumerate(metrics, start=1):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=model_health_df[\"bin\"],\n",
    "            y=model_health_df[\"model_health\"],\n",
    "            mode=\"lines\",\n",
    "            name=\"Model Health\",\n",
    "            line={\"color\": \"blue\"},\n",
    "        ),\n",
    "        row=i,\n",
    "        col=1,\n",
    "        secondary_y=False,\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=model_health_df[\"bin\"],\n",
    "            y=model_health_df[metric],\n",
    "            mode=\"lines\",\n",
    "            name=metric.replace(\"_\", \" \").title(),\n",
    "            line={\"color\": metric_colors[metric]},\n",
    "        ),\n",
    "        row=i,\n",
    "        col=1,\n",
    "        secondary_y=True,\n",
    "    )\n",
    "\n",
    "    # Update y-axes titles\n",
    "    fig.update_yaxes(title_text=\"Model Health\", secondary_y=False, row=i, col=1)\n",
    "    fig.update_yaxes(\n",
    "        title_text=metric.replace(\"_\", \" \").title(), secondary_y=True, row=i, col=1\n",
    "    )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title_text=\"Model Health and Metrics on Test Data\",\n",
    "    height=300 * len(metrics),  # Adjust height based on number of subplots\n",
    "    legend_tracegroupgap=5,\n",
    ")\n",
    "\n",
    "# Update x-axis title for the bottom subplot only\n",
    "fig.update_xaxes(title_text=\"Bin\", row=len(metrics), col=1)\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

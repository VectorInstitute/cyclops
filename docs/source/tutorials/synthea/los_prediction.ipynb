{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e337389b-1cfe-4796-a846-b4e1ba5690d6",
   "metadata": {},
   "source": [
    "# Length of Stay Prediction\n",
    "\n",
    "This notebook showcases length of stay prediction on the [Synthea](https://github.com/synthetichealth/synthea) dataset using CyclOps. The task is formulated as a binary classification task, where we predict the probability that a patient will stay 7 days or longer.\n",
    "\n",
    "To generate the synthetic patient data:\n",
    "\n",
    "1. Generate synthea data using their releases. We used [v3.0.0](https://github.com/synthetichealth/synthea/releases/tag/v3.0.0).\n",
    "2. Follow instructions provided in [ETL-Synthea](https://github.com/OHDSI/ETL-Synthea) to load the CSV data into a postgres database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c18656-7f16-4230-85d0-944563d6a13e",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53009e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datasets import Dataset\n",
    "from datasets.features import ClassLabel\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "import cyclops.query.ops as qo\n",
    "from cyclops.evaluate.metrics import MetricCollection, create_metric\n",
    "from cyclops.models.catalog import create_model\n",
    "from cyclops.process.feature.feature import TabularFeatures\n",
    "from cyclops.query import DatasetQuerier\n",
    "from cyclops.report import ModelCardReport\n",
    "from cyclops.report.plot.classification import ClassificationPlotter\n",
    "from cyclops.report.utils import flatten_results_dict\n",
    "from cyclops.tasks.mortality_prediction import MortalityPredictionTask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c35352-ccef-47c9-8d1a-3062c62adb97",
   "metadata": {},
   "source": [
    "CyclOps offers a package for documentation of the model through a model card. The `ModelCardReport` class is used to populate and generate the model card as an HTML file. The model card has the following sections:\n",
    "- Model Details: This section contains descriptive metadata about the model such as the owners, version, license, etc.\n",
    "- Model Parameters: This section contains the technical details of the model such as the model architecture, training parameters, etc.\n",
    "- Considerations: This section contains descriptions of the considerations involved in developing and using the model such as the intended use, limitations, etc.\n",
    "- Quantitative Analysis: This section contains the performance metrics of the model for different sets of the data and subpopulations.\n",
    "- Explainaibility Analysis: This section contains the explainability metrics of the model.\n",
    "- Fairness Analysis: This section contains the fairness metrics of the model.\n",
    "\n",
    "We will use this to document the model development process as we go along and generate the model card at the end.\n",
    "\n",
    "`The model card tool is a work in progress and is subject to change.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afae58a8-5708-4e05-8695-25ba3ce1a71f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "report = ModelCardReport()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28becf40-dc5f-4a1d-a1c9-5d6a41f797aa",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739b109a-011b-4e6e-a3de-964edeffddbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NAN_THRESHOLD = 0.25\n",
    "NUM_DAYS = 7\n",
    "TRAIN_SIZE = 0.8\n",
    "RANDOM_SEED = 85"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d5aa23-6ae5-4ab6-824f-b68c47f471ae",
   "metadata": {},
   "source": [
    "## Data Querying\n",
    "\n",
    "### Compute length of stay (labels)\n",
    "\n",
    "1. Get encounters, compute length of stay.\n",
    "2. Filter out encounters less than 2 days and greater than 20 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e497df9f-0f3d-4e9c-845c-539627a37f67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "querier = DatasetQuerier(\n",
    "    dbms=\"postgresql\",\n",
    "    port=5432,\n",
    "    host=\"localhost\",\n",
    "    database=\"synthea_demo\",\n",
    "    user=\"postgres\",\n",
    "    password=\"pwd\",\n",
    ")\n",
    "\n",
    "\n",
    "def get_encounters():\n",
    "    \"\"\"Get encounters data.\"\"\"\n",
    "    patients = querier.native.patients(\n",
    "        ops=qo.Sequential([qo.Keep([\"id\", \"birthdate\", \"gender\", \"race\", \"ethnicity\"])])\n",
    "    )\n",
    "    ops = qo.Sequential(\n",
    "        [\n",
    "            qo.Join(patients.query, on=(\"patient\", \"id\"), isouter=True),\n",
    "            qo.ExtractTimestampComponent(\"start\", \"year\", \"start_year\"),\n",
    "            qo.ExtractTimestampComponent(\"birthdate\", \"year\", \"birthdate_year\"),\n",
    "            qo.AddColumn(\n",
    "                \"start_year\", \"birthdate_year\", new_col_labels=\"age\", negative=True\n",
    "            ),\n",
    "            qo.AddColumn(\"stop\", \"start\", new_col_labels=\"los\", negative=True),\n",
    "            qo.ConditionGreaterThan(\"los\", 1),\n",
    "            qo.ConditionLessThan(\"los\", 21),\n",
    "            qo.Keep(\n",
    "                [\n",
    "                    \"id\",\n",
    "                    \"los\",\n",
    "                    \"age\",\n",
    "                    \"gender\",\n",
    "                ]\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    encounters = querier.native.encounters(ops=ops)\n",
    "\n",
    "    return encounters\n",
    "\n",
    "\n",
    "def get_observations(cohort):\n",
    "    \"\"\"Get observations data.\"\"\"\n",
    "    ops = qo.Sequential(\n",
    "        [\n",
    "            qo.Join(cohort.query, on=(\"encounter\", \"id\")),\n",
    "            qo.ConditionIn(\n",
    "                \"category\",\n",
    "                [\n",
    "                    \"laboratory\",\n",
    "                    \"vital-signs\",\n",
    "                ],\n",
    "            ),\n",
    "            qo.ConditionEquals(\"type\", \"numeric\"),\n",
    "        ]\n",
    "    )\n",
    "    observations = querier.native.observations(ops=ops).run()\n",
    "    ops = qo.Sequential(\n",
    "        [\n",
    "            qo.Join(cohort.query, on=(\"encounter\", \"id\")),\n",
    "            qo.GroupByAggregate(\n",
    "                \"encounter\",\n",
    "                {\"description\": (\"count\", \"n_obs\")},\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    observations_count = querier.native.observations(ops=ops).run()\n",
    "    observations_stats = observations.pivot_table(\n",
    "        index=\"encounter\", columns=\"description\", values=\"value\", aggfunc=\"max\"\n",
    "    ).add_prefix(\"obs_\")\n",
    "\n",
    "    return [observations_count, observations_stats]\n",
    "\n",
    "\n",
    "def get_medications(cohort):\n",
    "    \"\"\"Get medications data.\"\"\"\n",
    "    ops = qo.Sequential(\n",
    "        [\n",
    "            qo.Join(cohort.query, on=(\"encounter\", \"id\")),\n",
    "            qo.GroupByAggregate(\n",
    "                \"encounter\",\n",
    "                {\"description\": (\"count\", \"n_meds\")},\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    medications = querier.native.medications(ops=ops).run()\n",
    "\n",
    "    return medications\n",
    "\n",
    "\n",
    "def get_procedures(cohort):\n",
    "    \"\"\"Get procedures data.\"\"\"\n",
    "    ops = qo.Sequential(\n",
    "        [\n",
    "            qo.Join(cohort.query, on=(\"encounter\", \"id\")),\n",
    "            qo.GroupByAggregate(\n",
    "                \"encounter\",\n",
    "                {\"description\": (\"count\", \"n_procedures\")},\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    procedures = querier.native.procedures(ops=ops).run()\n",
    "\n",
    "    return procedures\n",
    "\n",
    "\n",
    "def run_query():\n",
    "    \"\"\"Run query pipeline.\"\"\"\n",
    "    cohort_query = get_encounters()\n",
    "    to_merge = []\n",
    "    observations = get_observations(cohort_query)\n",
    "    to_merge.extend(observations)\n",
    "    medications = get_medications(cohort_query)\n",
    "    to_merge.append(medications)\n",
    "    procedures = get_procedures(cohort_query)\n",
    "    to_merge.append(procedures)\n",
    "    cohort = cohort_query.run()\n",
    "    for to_merge_df in to_merge:\n",
    "        cohort = cohort.merge(\n",
    "            to_merge_df, left_on=\"id\", right_on=\"encounter\", how=\"left\"\n",
    "        )\n",
    "    to_drop = list(cohort.columns[cohort.columns.str.startswith(\"encounter\")])\n",
    "    cohort = cohort.drop(columns=to_drop)\n",
    "\n",
    "    return cohort\n",
    "\n",
    "\n",
    "cohort = run_query()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389796a5-5abb-4c8f-bcb9-229d0e3e2108",
   "metadata": {},
   "source": [
    "## Data Inspection and Preprocessing\n",
    "\n",
    "#### Drop NaNs based on the `NAN_THRESHOLD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c576ee51-e825-4970-86e8-3e5f221f145c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "null_counts = cohort.isnull().sum()[cohort.isnull().sum() > 0]\n",
    "fig = go.Figure(data=[go.Bar(x=null_counts.index, y=null_counts.values)])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Number of Null Values per Column\",\n",
    "    xaxis_title=\"Columns\",\n",
    "    yaxis_title=\"Number of Null Values\",\n",
    "    height=600,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77e5839-8c2f-4599-a511-2c3737e20772",
   "metadata": {},
   "source": [
    "**Add the figure to the report**\n",
    "\n",
    "We can use the log_plotly_figure method to add the figure to a section of the report. One can specify whether the figure should be interactive or not by setting the `interactive` parameter to `True` or `False` respectively. The default value is `True`. This\n",
    "also affects the final size of the report. If the figure is interactive, the size of the report will be larger than if the figure is not interactive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190bcac3-2eda-4acc-bf1b-81cfd39a10b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "report.log_plotly_figure(\n",
    "    fig=fig,\n",
    "    caption=\"Number of Null Values per Column\",\n",
    "    section_name=\"datasets\",\n",
    "    interactive=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d67235-d839-4b70-bbd4-5126d8c6da49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "thresh_nan = int(NAN_THRESHOLD * len(cohort))\n",
    "cohort = cohort.dropna(axis=1, thresh=thresh_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5b45cb-2406-4330-b2fc-3b4823ff0c17",
   "metadata": {},
   "source": [
    "#### Length of stay distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cd2841-a992-4a89-936c-19bb90e6234d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "length_of_stay = cohort[\"los\"]\n",
    "length_of_stay_counts = list(length_of_stay.value_counts().values)\n",
    "length_of_stay_keys = [key for key in length_of_stay.value_counts().keys()]\n",
    "cohort[\"outcome\"] = cohort[\"los\"] < NUM_DAYS\n",
    "\n",
    "fig = go.Figure(data=[go.Bar(x=length_of_stay_keys, y=length_of_stay_counts)])\n",
    "fig.update_layout(\n",
    "    title=\"Length of stay\",\n",
    "    xaxis_title=\"Days\",\n",
    "    yaxis_title=\"Number of encounters\",\n",
    "    height=600,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05156094-56e8-49c5-8e3c-478a1797db62",
   "metadata": {},
   "source": [
    "#### Outcome distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae75c8a1-9316-4e47-ad45-7291a7b783bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort[\"outcome\"] = cohort[\"outcome\"].astype(\"int\")\n",
    "fig = px.pie(cohort, names=\"outcome\")\n",
    "fig.update_traces(textinfo=\"percent+label\")\n",
    "fig.update_layout(title_text=\"Outcome Distribution\")\n",
    "fig.update_traces(\n",
    "    hovertemplate=\"Outcome: %{label}<br>Count: %{value}<br>Percent: %{percent}\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742ba610-b754-458d-a77f-fc9469dcadab",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Add the figure to the report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794e085d-2dae-4dba-ade8-ab8cdc982af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "report.log_plotly_figure(\n",
    "    fig=fig,\n",
    "    caption=\"Outcome Distribution\",\n",
    "    section_name=\"datasets\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab6a390-95f4-4876-a63d-210c95262960",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = cohort[\"outcome\"].value_counts()\n",
    "class_ratio = class_counts[0] / class_counts[1]\n",
    "class_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dcc6ca-fc77-4fc4-ae25-b50560a7d6bb",
   "metadata": {},
   "source": [
    "**Add the figure to the report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca0724c-62b9-4d5b-946b-199170229054",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "report.log_plotly_figure(\n",
    "    fig=fig,\n",
    "    caption=\"Length of stay distribution\",\n",
    "    section_name=\"datasets\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48376c2-a437-41f4-96fa-ea75f182f7b7",
   "metadata": {},
   "source": [
    "#### Gender distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ef4a36-3f9f-490a-befd-8e5fe41596ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.pie(cohort, names=\"gender\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Gender Distribution\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b3673d-8df6-4aa8-9fff-f623f4d800ff",
   "metadata": {},
   "source": [
    "**Add the figure to the report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd741fb-d0fe-4add-8d66-6b8baf271395",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "report.log_plotly_figure(\n",
    "    fig=fig,\n",
    "    caption=\"Gender Distribution\",\n",
    "    section_name=\"datasets\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0e832a-5763-42dc-a2e0-d91fef955ea5",
   "metadata": {
    "tags": []
   },
   "source": [
    "####  Age distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb2b6cf-ee4d-4f83-8e56-6adcbe91f854",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.histogram(cohort, x=\"age\")\n",
    "fig.update_layout(\n",
    "    title=\"Age Distribution\",\n",
    "    xaxis_title=\"Age\",\n",
    "    yaxis_title=\"Count\",\n",
    "    bargap=0.2,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53519265-e826-459e-a6d6-de9c4cde41e7",
   "metadata": {},
   "source": [
    "**Add the figure to the report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c4c351-8eb5-41cd-8a50-006cfcfb13c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "report.log_plotly_figure(\n",
    "    fig=fig,\n",
    "    caption=\"Age Distribution\",\n",
    "    section_name=\"datasets\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483c9bb5-57bf-4a2c-960f-35f7e76eff1d",
   "metadata": {},
   "source": [
    "#### Identifying feature types\n",
    "\n",
    "Cyclops `TabularFeatures` class helps to identify feature types, an essential step before preprocessing the data. Understanding feature types (numerical/categorical/binary) allows us to apply appropriate preprocessing steps for each type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb987af-f056-4886-84fa-4d4e1106e9b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_list = [\n",
    "    \"age\",\n",
    "    \"gender\",\n",
    "    \"n_obs\",\n",
    "    # 'n_meds',\n",
    "    # 'n_procedures',\n",
    "    \"obs_Alanine aminotransferase [Enzymatic activity/volume] in Serum or Plasma\",\n",
    "    \"obs_Albumin [Mass/volume] in Serum or Plasma\",\n",
    "    \"obs_Alkaline phosphatase [Enzymatic activity/volume] in Serum or Plasma\",\n",
    "    \"obs_Aspartate aminotransferase [Enzymatic activity/volume] in Serum or Plasma\",\n",
    "    \"obs_Bilirubin.total [Mass/volume] in Serum or Plasma\",\n",
    "    \"obs_Body Weight\",\n",
    "    \"obs_Calcium [Mass/volume] in Serum or Plasma\",\n",
    "    \"obs_Carbon dioxide  total [Moles/volume] in Serum or Plasma\",\n",
    "    \"obs_Chloride [Moles/volume] in Serum or Plasma\",\n",
    "    \"obs_Creatinine [Mass/volume] in Serum or Plasma\",\n",
    "    \"obs_Diastolic Blood Pressure\",\n",
    "    \"obs_Erythrocyte distribution width [Ratio] by Automated count\",\n",
    "    \"obs_Erythrocytes [#/volume] in Blood by Automated count\",\n",
    "    \"obs_Ferritin [Mass/volume] in Serum or Plasma\",\n",
    "    \"obs_Glomerular filtration rate/1.73 sq M.predicted\",\n",
    "    \"obs_Glucose [Mass/volume] in Serum or Plasma\",\n",
    "    \"obs_Hematocrit [Volume Fraction] of Blood by Automated count\",\n",
    "    \"obs_Hemoglobin [Mass/volume] in Blood\",\n",
    "    \"obs_Leukocytes [#/volume] in Blood by Automated count\",\n",
    "    \"obs_MCH [Entitic mass] by Automated count\",\n",
    "    \"obs_MCHC [Mass/volume] by Automated count\",\n",
    "    \"obs_MCV [Entitic volume] by Automated count\",\n",
    "    \"obs_Oxygen saturation in Arterial blood\",\n",
    "    \"obs_Platelets [#/volume] in Blood by Automated count\",\n",
    "    \"obs_Potassium [Moles/volume] in Serum or Plasma\",\n",
    "    \"obs_Protein [Mass/volume] in Serum or Plasma\",\n",
    "    \"obs_Sodium [Moles/volume] in Serum or Plasma\",\n",
    "    \"obs_Systolic Blood Pressure\",\n",
    "    \"obs_Troponin I.cardiac [Mass/volume] in Serum or Plasma by High sensitivity method\",\n",
    "    \"obs_Urea nitrogen [Mass/volume] in Serum or Plasma\",\n",
    "]\n",
    "features_list = sorted(features_list)\n",
    "tab_features = TabularFeatures(\n",
    "    data=cohort.reset_index(),\n",
    "    features=features_list,\n",
    "    by=\"id\",\n",
    "    targets=\"outcome\",\n",
    ")\n",
    "tab_features.types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2738074-00be-46fa-999f-77f85add9469",
   "metadata": {},
   "source": [
    "#### Creating data preprocessors\n",
    "\n",
    "We create a data preprocessor using sklearn's ColumnTransformer. This helps in applying different preprocessing steps to different columns in the dataframe. For instance, binary features might be processed differently from numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb80cfb-2e48-4ecf-a325-0026dad4aef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())]\n",
    ")\n",
    "\n",
    "binary_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"most_frequent\"))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ec3441-7dba-4b9a-9256-ad6b0293829d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_features = sorted((tab_features.features_by_type(\"numeric\")))\n",
    "numeric_indices = [\n",
    "    cohort[features_list].columns.get_loc(column) for column in numeric_features\n",
    "]\n",
    "numeric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fb5345-17f9-44ac-b944-079324a098e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "binary_features = sorted(tab_features.features_by_type(\"binary\"))\n",
    "binary_features.remove(\"outcome\")\n",
    "binary_indices = [\n",
    "    cohort[features_list].columns.get_loc(column) for column in binary_features\n",
    "]\n",
    "binary_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868fa57c-f12a-4821-a85e-31c6c95d6e76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_indices),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"), binary_indices),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a178f34-3883-43c2-8009-28063619df2c",
   "metadata": {},
   "source": [
    "## Creating Hugging Face Dataset\n",
    "\n",
    "We convert our processed Pandas dataframe into a Hugging Face dataset, a powerful and easy-to-use data format which is also compatible with CyclOps models and evaluator modules. The dataset is then split to train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b72a66-fc46-4e7a-a612-1f66de811c0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cohort = cohort.drop(columns=[\"id\", \"los\"])\n",
    "dataset = Dataset.from_pandas(cohort)\n",
    "dataset.cleanup_cache_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6370e7a-c559-431f-9ebc-0b35bcdfb029",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = dataset.cast_column(\"outcome\", ClassLabel(num_classes=2))\n",
    "dataset = dataset.train_test_split(\n",
    "    train_size=TRAIN_SIZE, stratify_by_column=\"outcome\", seed=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71007875-2e2c-460f-a956-bcd419cb2017",
   "metadata": {},
   "source": [
    "## Model Creation\n",
    "\n",
    "CyclOps model registry allows for straightforward creation and selection of models. This registry maintains a list of pre-configured models, which can be instantiated with a single line of code. Here we use a SGD classifier to fit a logisitic regression model. The model configurations can be passed to `create_model` based on the sllearn parameters for SGDClassifer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e8d147-545c-47a7-9a91-b06b27a37d47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"xgb_classifier\"\n",
    "model = create_model(model_name, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3ae174-59c0-41df-954c-f6e05f64c8dd",
   "metadata": {},
   "source": [
    "## Task Creation\n",
    "\n",
    "We use Cyclops tasks to define our model's task (in this case, MortalityPrediction), train the model, make predictions, and evaluate performance. Cyclops task classes encapsulate the entire ML pipeline into a single, cohesive structure, making the process smooth and easy to manage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d36851-292a-4849-98e0-9183c2dec87a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "los_task = MortalityPredictionTask(\n",
    "    {model_name: model}, task_features=features_list, task_target=\"outcome\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96323637-f5ea-41dd-8899-ce6680d5d58d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "los_task.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb95f1e-ae78-469c-88d8-750d9c36a349",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "If `best_model_params` is passed to the `train` method, the best model will be selected after the hyperparameter search. The parameters in `best_model_params` indicate the values to create the parameters grid.\n",
    "\n",
    "Note that the data preprocessor needs to be passed to the tasks methods if the Hugging Face dataset is not already preprocessed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572b0fe0-5891-4aca-9e63-8d556851caec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model_params = {\n",
    "    \"n_estimators\": [100, 250, 500],\n",
    "    \"learning_rate\": [0.1, 0.01],\n",
    "    \"max_depth\": [2, 5],\n",
    "    \"reg_lambda\": [0, 1, 10],\n",
    "    \"colsample_bytree\": [0.7, 0.8, 1],\n",
    "    \"gamma\": [0, 1, 2, 10],\n",
    "    \"method\": \"random\",\n",
    "}\n",
    "los_task.train(\n",
    "    dataset[\"train\"],\n",
    "    model_name=model_name,\n",
    "    transforms=preprocessor,\n",
    "    best_model_params=best_model_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b687a58-a6e5-46f7-bd9e-106376912086",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_params = los_task.list_models_params()[model_name]\n",
    "model_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e699187-2650-41ab-aba8-42bf9c635819",
   "metadata": {},
   "source": [
    "**Log the model parameters to the report.**\n",
    "\n",
    "We can add model parameters to the model card using the `log_model_parameters` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfdfe29-c813-45cd-9ae7-2959daa0cd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "report.log_model_parameters(params=model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d772526e-f595-4f4a-8026-7ab39523b3df",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "\n",
    "The prediction output can be either the whole Hugging Face dataset with the prediction columns added to it or the single column containing the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fee35c-902e-4c54-89b7-c42c1e935e1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = los_task.predict(\n",
    "    dataset[\"test\"],\n",
    "    model_name=model_name,\n",
    "    transforms=preprocessor,\n",
    "    proba=False,\n",
    "    only_predictions=True,\n",
    ")\n",
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2eb06bb-9c85-4597-a07d-f3f16c841c56",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Evaluation is done using various evaluation metrics that provide different perspectives on the model's predictive abilities i.e. standard performance metrics and fairness metrics.\n",
    "\n",
    "The standard performance metrics can be created using the `MetricCollection` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d5b101-17a8-4610-ae17-e04cf962d2d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric_names = [\n",
    "    \"accuracy\",\n",
    "    \"precision\",\n",
    "    \"recall\",\n",
    "    \"f1_score\",\n",
    "    \"auroc\",\n",
    "    \"roc_curve\",\n",
    "    \"precision_recall_curve\",\n",
    "]\n",
    "metrics = [create_metric(metric_name, task=\"binary\") for metric_name in metric_names]\n",
    "metric_collection = MetricCollection(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3797fe8c-886e-426f-8ea9-ad5afad3b65b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results, dataset_with_preds = los_task.evaluate(\n",
    "    dataset[\"test\"],\n",
    "    metric_collection,\n",
    "    model_names=model_name,\n",
    "    transforms=preprocessor,\n",
    "    prediction_column_prefix=\"preds\",\n",
    "    batch_size=64,\n",
    "    override_fairness_metrics=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2d1d75-f7d8-44d3-a782-2aba9a4fbac0",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Log the performance metrics to the report.**\n",
    "\n",
    "We can add a performance metric to the model card using the `log_performance_metric` method, which expects a dictionary where the keys are in the following format: `slice_name/metric_name`. For instance, `overall/accuracy`. \n",
    "\n",
    "We first need to process the evaluation results to get the metrics in the right format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d322a86f-1f7c-42f6-8a97-8a18ea8622e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_flat = flatten_results_dict(\n",
    "    results=results,\n",
    "    remove_metrics=[\"BinaryROCCurve\", \"BinaryPrecisionRecallCurve\"],\n",
    "    model_name=model_name,\n",
    ")\n",
    "results_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33a171c-02ef-4bc9-a3bf-87320c7c83d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for name, metric in results_flat.items():\n",
    "    split, name = name.split(\"/\")\n",
    "    if name == \"BinaryAUROC\":\n",
    "        report.log_quantitative_analysis(\n",
    "            \"performance\",\n",
    "            name=name,\n",
    "            value=metric,\n",
    "            metric_slice=split,\n",
    "            pass_fail_thresholds=0.8,\n",
    "            pass_fail_threshold_fns=lambda x, threshold: x >= threshold,\n",
    "        )\n",
    "    elif name == \"BinaryAccuracy\":\n",
    "        report.log_quantitative_analysis(\n",
    "            \"performance\",\n",
    "            name=name,\n",
    "            value=metric,\n",
    "            metric_slice=split,\n",
    "            pass_fail_thresholds=0.6,\n",
    "            pass_fail_threshold_fns=lambda x, threshold: x >= threshold,\n",
    "        )\n",
    "    elif name == \"BinaryPrecision\":\n",
    "        report.log_quantitative_analysis(\n",
    "            \"performance\",\n",
    "            name=name,\n",
    "            value=metric,\n",
    "            metric_slice=split,\n",
    "            pass_fail_thresholds=0.6,\n",
    "            pass_fail_threshold_fns=lambda x, threshold: x >= threshold,\n",
    "        )\n",
    "    elif name == \"BinaryRecall\":\n",
    "        report.log_quantitative_analysis(\n",
    "            \"performance\",\n",
    "            name=name,\n",
    "            value=metric,\n",
    "            metric_slice=split,\n",
    "            pass_fail_thresholds=0.6,\n",
    "            pass_fail_threshold_fns=lambda x, threshold: x >= threshold,\n",
    "        )\n",
    "    elif name == \"BinaryF1Score\":\n",
    "        report.log_quantitative_analysis(\n",
    "            \"performance\",\n",
    "            name=name,\n",
    "            value=metric,\n",
    "            metric_slice=split,\n",
    "            pass_fail_thresholds=0.6,\n",
    "            pass_fail_threshold_fns=lambda x, threshold: x >= threshold,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee464d3-7246-4c6f-ac2d-8cca2a985f22",
   "metadata": {},
   "source": [
    "We can also use the `ClassificationPlotter` to plot the performance metrics and the add the figure to the model card using the `log_plotly_figure` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1acc80b-9dce-4f10-9641-dba86cae0a50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plotter = ClassificationPlotter(task_type=\"binary\", class_names=[\"0\", \"1\"])\n",
    "plotter.set_template(\"plotly_white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3a525b-63d5-4d35-b248-8fa67dc5a2c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extracting the ROC curves and AUROC results for all the slices\n",
    "roc_curves = {\n",
    "    slice_name: slice_results[\"BinaryROCCurve\"]\n",
    "    for slice_name, slice_results in results[model_name].items()\n",
    "}\n",
    "aurocs = {\n",
    "    slice_name: slice_results[\"BinaryAUROC\"]\n",
    "    for slice_name, slice_results in results[model_name].items()\n",
    "}\n",
    "roc_curves.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9774f0ef-89a9-4c65-9021-635a90122676",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plotting the ROC curves for all the slices\n",
    "roc_plot = plotter.roc_curve_comparison(roc_curves, aurocs=aurocs)\n",
    "report.log_plotly_figure(\n",
    "    fig=roc_plot,\n",
    "    caption=\"ROC Curve for Female Patients\",\n",
    "    section_name=\"quantitative analysis\",\n",
    ")\n",
    "roc_plot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyclops",
   "language": "python",
   "name": "cyclops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-tension",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from os import path\n",
    "from time import localtime, strftime, time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from drift_detection.fsd import FeatureShiftDetector\n",
    "from gemini.utils import import_dataset_hospital\n",
    "from sklearn.metrics import confusion_matrix as sklearn_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-hampton",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOSPITAL = [\"SMH\", \"MSH\", \"THPC\", \"THPM\", \"UHNTG\", \"UHNTW\", \"PMH\", \"SBK\"]\n",
    "NA_CUTOFF = 0.6\n",
    "SHIFT_EXPERIMENT = input(\"Select experiment: \")\n",
    "OUTCOME = input(\"Select outcome variable: \")\n",
    "\n",
    "(\n",
    "    (X_train, y_train),\n",
    "    (X_val, y_val),\n",
    "    (X_test, y_test),\n",
    "    feats,\n",
    "    orig_dims,\n",
    ") = import_dataset_hospital(\n",
    "    SHIFT_EXPERIMENT,\n",
    "    OUTCOME,\n",
    "    HOSPITAL,\n",
    "    NA_CUTOFF,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Global Experiment Parameters\n",
    "n_samples = 100  # The number of samples in p, q (thus n_samples_total = n_samples*2)\n",
    "n_bootstrap_runs = 50\n",
    "n_conditional_expectation = 30\n",
    "n_inner_expectation = n_conditional_expectation\n",
    "alpha = 0.05  # Significance level\n",
    "data_family = \"Copula\"\n",
    "a = 0.5\n",
    "b = 0.5\n",
    "rng = np.random.RandomState(42)\n",
    "torch.manual_seed(rng.randint(1000))\n",
    "method_list = [\n",
    "    \"score-method\",\n",
    "]  # we do not take the deep method into account with the simple boot.\n",
    "dataset_list = [\"COVID\"]\n",
    "t_split_interval = 50\n",
    "n_comp_sensors_list = [1]\n",
    "window_size_list = [i * 100 for i in range(0, 11)]\n",
    "n_comp_sensors = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-warrior",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = int(np.ceil((X_train.shape[0] - 2 * n_samples) / t_split_interval))\n",
    "n_dim = X_train.shape[1]\n",
    "sqrtn = int(np.floor(np.sqrt(n_dim)))\n",
    "n_dataset_samples = X_train[n_samples:].shape[\n",
    "    0\n",
    "]  # to account for taking out n_samples for reference dist, p\n",
    "rng = np.random.RandomState(42)\n",
    "torch.manual_seed(rng.randint(1000))\n",
    "print(n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_data = callable()\n",
    "do_diff = False\n",
    "do_power_transform = False\n",
    "\n",
    "dataset_name = \"gemini\"\n",
    "for method in method_list:\n",
    "    for shuffle_data_set in [False, True]:\n",
    "        # Experiment Switches\n",
    "        if shuffle_data_set:\n",
    "            shuffle_string = \"time axis shuffled\"\n",
    "            experiment_name = f\"time-boot-{method}-time-axis-shuffled-on-{dataset_name}\"\n",
    "        else:\n",
    "            shuffle_string = \"time axis unshuffled\"\n",
    "            experiment_name = (\n",
    "                f\"time-boot-{method}-time-axis-unshuffled-on-{dataset_name}\"\n",
    "            )\n",
    "        print()\n",
    "        print(\n",
    "            f\"Starting {method} on {dataset_name} dataset with \\\n",
    "                 {shuffle_string} and simple boot\",\n",
    "        )\n",
    "\n",
    "        n_trials = int(np.ceil((X_train.shape[0] - 2 * n_samples) / t_split_interval))\n",
    "        n_dim = X_train.shape[1]\n",
    "        sqrtn = int(np.floor(np.sqrt(n_dim)))\n",
    "        n_dataset_samples = X_train[n_samples:].shape[\n",
    "            0\n",
    "        ]  # to account for taking out n_samples for reference dist, p\n",
    "\n",
    "        # Attack testing\n",
    "        rng = np.random.RandomState(42)\n",
    "        torch.manual_seed(rng.randint(1000))\n",
    "\n",
    "        time_list = np.zeros(n_trials)\n",
    "        global_truth = np.zeros(n_trials)\n",
    "        detection = np.zeros(n_trials)\n",
    "        detection_results = np.zeros(shape=(n_dim, n_trials, 3))\n",
    "        j_attack = rng.choice(np.arange(n_dim), replace=True, size=n_trials)\n",
    "        for idx, feature in enumerate(j_attack[: int(n_trials / 2)]):\n",
    "            detection_results[feature, idx, 1] = 1  # recording where attacks happen\n",
    "            global_truth[idx] = 1\n",
    "\n",
    "        exception_occured = 0\n",
    "        exception_vector = np.full(shape=(n_trials), fill_value=False)\n",
    "        for test_idx, split_idx in enumerate(\n",
    "            range(0, X_train.shape[0] - 2 * n_samples, t_split_interval),\n",
    "        ):\n",
    "            start = time()\n",
    "            test_idx = int(test_idx)\n",
    "            split_idx = int(split_idx)\n",
    "            slice1 = split_idx\n",
    "            slice2 = split_idx + 2 * n_samples\n",
    "            pq = X_train[slice1:slice2]  # Two sets of samples\n",
    "            pq = transform_data(\n",
    "                pq,\n",
    "                do_diff=do_diff,\n",
    "                do_power_transform=do_power_transform,\n",
    "            )\n",
    "            p = pq[:n_samples]\n",
    "            q = pq[n_samples : n_samples * 2].copy()\n",
    "\n",
    "            if np.any(detection_results[:, test_idx, 1] == 1):  # attack!\n",
    "                attacked_features = j_attack[test_idx]\n",
    "                q[:, attacked_features] = rng.permutation(\n",
    "                    q[:, attacked_features],\n",
    "                )  # permutes q\n",
    "\n",
    "            # Bootstrap every time\n",
    "            fsd = FeatureShiftDetector(\n",
    "                p,\n",
    "                q,\n",
    "                rng=rng,\n",
    "                samples_generator=np.nan,\n",
    "                detection_method=method,\n",
    "                n_bootstrap_runs=n_bootstrap_runs,\n",
    "                n_conditional_expectation=n_conditional_expectation,\n",
    "                n_attacks=np.nan,\n",
    "                alpha=alpha,\n",
    "                j_attack=np.nan,\n",
    "                attack_testing=False,\n",
    "            )\n",
    "            bonferroni_threshold_vector = fsd.bonferroni_threshold_vector\n",
    "            threshold_vector = fsd.threshold_vector\n",
    "            bootstrap_score_means_vector = fsd.bootstrap_distribution.mean(axis=0)\n",
    "            bootstrap_score_std_vector = (\n",
    "                np.std(fsd.bootstrap_distribution, axis=0) + 1e-5\n",
    "            )\n",
    "\n",
    "            # now check after getting new threshold\n",
    "            score_vector = np.array(fsd.get_score(p, q))\n",
    "            detection_results[:, test_idx, 0] = score_vector\n",
    "            # predicting attack\n",
    "            if np.any(score_vector >= bonferroni_threshold_vector):\n",
    "                detection[test_idx] = 1\n",
    "                normalized_score_vector = (\n",
    "                    score_vector - bootstrap_score_means_vector\n",
    "                ) / bootstrap_score_std_vector\n",
    "                attacked_features = normalized_score_vector.argsort()[-1]\n",
    "                detection_results[attacked_features, test_idx, 2] = 1\n",
    "            time_list[test_idx] = time() - start\n",
    "\n",
    "        # Recording Attack Results\n",
    "        confusion_tensor = np.zeros(shape=(n_dim, 2, 2))\n",
    "        for feature_idx, feature_results in enumerate(detection_results):\n",
    "            confusion_tensor[feature_idx] = sklearn_confusion_matrix(\n",
    "                feature_results[:, 1],\n",
    "                feature_results[:, 2],\n",
    "                labels=[0, 1],\n",
    "            )\n",
    "\n",
    "        # overall detection confusion matrix\n",
    "        global_detection_confusion_matrix = sklearn_confusion_matrix(\n",
    "            global_truth,\n",
    "            detection,\n",
    "            labels=[0, 1],\n",
    "        )\n",
    "\n",
    "        full_tn, full_fp, full_fn, full_tp = confusion_tensor.sum(axis=0).flatten()\n",
    "        micro_precision = full_tp / (full_tp + full_fp)\n",
    "        micro_recall = full_tp / (full_tp + full_fn)\n",
    "\n",
    "        if shuffle_data_set:\n",
    "            print(\"Time axis shuffled\")\n",
    "        else:\n",
    "            print(\"Time axis unshuffled\")\n",
    "\n",
    "        tn, fp, fn, tp = global_detection_confusion_matrix.flatten()\n",
    "        detection_precision = tp / (tp + fp)\n",
    "        detection_recall = tp / (tp + fn)\n",
    "\n",
    "        print(\"Results for: \", experiment_name)\n",
    "        print(f\"Precision: {detection_precision * 100:.2f}%\")\n",
    "        print(f\"Recall: {detection_recall * 100:.2f}%\")\n",
    "\n",
    "        print(f\"Micro-precision: {micro_precision * 100:.2f}%\")\n",
    "        print(f\"Micro-recall: {micro_recall * 100:.2f}%\")\n",
    "\n",
    "        print(f\"Avg time per test: {time_list.mean():.2f} sec\")\n",
    "        print(f\"Total time: {time_list.sum():.2f} sec\")\n",
    "\n",
    "        # Saving Score Distributions\n",
    "        results_dict = {\n",
    "            \"detection_results\": detection_results,\n",
    "            \"global_confusion_matrix\": global_detection_confusion_matrix,\n",
    "            \"confusion_tensor\": confusion_tensor,\n",
    "            \"times\": time_list,\n",
    "        }\n",
    "        experiment_save_name = experiment_name + \"-results_dict.p\"\n",
    "        pickle.dump(\n",
    "            results_dict,\n",
    "            open(path.join(\"..\", \"..\", \"results\", experiment_save_name), \"wb\"),\n",
    "        )\n",
    "print(f'Experiment completed at {strftime(\"%a, %d %b %Y %I:%M%p\", localtime())}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('cyclops-4J2PL5I8-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd2cd438e1c6ddffa3035fc73b17ac5cc0e0ea8897eb8be17cc645c6abf0c8cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

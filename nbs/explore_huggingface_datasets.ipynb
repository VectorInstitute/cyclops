{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Extensibility of the ðŸ¤— Datasets Library for Medical Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "from functools import partial\n",
    "from typing import Dict, List\n",
    "\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import plotly.graph_objects as go\n",
    "import psutil\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torchxrayvision as xrv\n",
    "import yaml\n",
    "from datasets import Dataset, load_dataset\n",
    "from datasets.features import ClassLabel, Image\n",
    "from datasets.splits import Split\n",
    "from monai.transforms import (\n",
    "    AddChanneld,\n",
    "    CenterSpatialCropd,\n",
    "    Compose,\n",
    "    Lambdad,\n",
    "    ToDeviced,\n",
    ")\n",
    "from omegaconf import OmegaConf\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from torchvision.transforms import PILToTensor\n",
    "\n",
    "from cyclops.data.slicer import SliceSpec\n",
    "from cyclops.evaluate.metrics import MetricCollection, create_metric\n",
    "from cyclops.models.catalog import create_model, list_models\n",
    "from cyclops.models.constants import CONFIG_ROOT\n",
    "from cyclops.utils.file import join\n",
    "from use_cases.params.mimiciv.mortality_decompensation.constants_v1 import (\n",
    "    ENCOUNTERS_FILE,\n",
    "    QUERIED_DIR,\n",
    "    TAB_FEATURES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "NUM_PROC = 4\n",
    "TORCH_BATCH_SIZE = 64"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring existing functionalities that are relevant to CyclOps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabular Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constructing a ðŸ¤— Dataset from MIMICIV-v2.0 PostgreSQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_cfg = OmegaConf.load(join(\"..\", \"cyclops\", \"query\", \"configs\", \"config.yaml\"))\n",
    "\n",
    "con_str = (\n",
    "    db_cfg.dbms\n",
    "    + \"://\"\n",
    "    + db_cfg.user\n",
    "    + \":\"\n",
    "    + db_cfg.password\n",
    "    + \"@\"\n",
    "    + db_cfg.host\n",
    "    + \"/\"\n",
    "    + db_cfg.database\n",
    ")\n",
    "\n",
    "ds = Dataset.from_sql(\n",
    "    sql=\"SELECT * FROM mimiciv_hosp.patients LIMIT 1000\",\n",
    "    con=con_str,\n",
    "    keep_in_memory=True,\n",
    ")\n",
    "ds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constructing a ðŸ¤— Dataset from local parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_files = list(glob.glob(join(QUERIED_DIR, \"*.parquet\")))\n",
    "len(parquet_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the first 300 files\n",
    "parquet_files = parquet_files[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimiciv_ds = load_dataset(\n",
    "    \"parquet\", data_files=parquet_files, split=Split.ALL, num_proc=NUM_PROC\n",
    ")\n",
    "\n",
    "# clear all other cache files, except for the current cache file\n",
    "mimiciv_ds.cleanup_cache_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_gb = mimiciv_ds.dataset_size / (1024**3)\n",
    "print(f\"Dataset size (cache file) : {size_gb:.2f} GB\")\n",
    "print(f\"RAM used: {psutil.Process().memory_info().rss / (1024 * 1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimiciv_ds.features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Benchmarking Filtering operations: ðŸ¤— Dataset vs. Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.config.set(scheduler=\"processes\", num_workers=NUM_PROC)\n",
    "\n",
    "ddf = dd.read_parquet(parquet_files)\n",
    "len(ddf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Filtering on 1 column**\n",
    "\n",
    "Get all rows where the values in column `event_cateogry` is in a list of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_filter = [\n",
    "    \"Cadiovascular\",\n",
    "    \"Dialysis\",\n",
    "    \"Hemodynamics\",\n",
    "    \"Neurological\",\n",
    "    \"Toxicology\",\n",
    "    \"General\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "events_ddf = ddf[ddf[\"event_category\"].isin(event_filter)].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "events_ds = mimiciv_ds.filter(\n",
    "    lambda examples: [\n",
    "        example in event_filter for example in examples[\"event_category\"]\n",
    "    ],\n",
    "    batched=True,\n",
    "    num_proc=NUM_PROC,\n",
    "    load_from_cache_file=False,  # timeit will run multiple times\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Filtering on multiple columns**\n",
    "\n",
    "Get all items where the values in two columns are in a list of values for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discharge_location_filter = [\"HOME\", \"HOME HEALTH CARE\"]\n",
    "admission_location_filter = [\n",
    "    \"TRANSFER FROM HOSPITAL\",\n",
    "    \"PHYSICIAN REFERRAL\",\n",
    "    \"CLINIC REFERRAL\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "location_ddf = ddf[\n",
    "    (ddf[\"discharge_location\"].isin(discharge_location_filter))\n",
    "    & (ddf[\"admission_location\"].isin(admission_location_filter))\n",
    "].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "location_ds = mimiciv_ds.filter(\n",
    "    lambda examples: [\n",
    "        example[0] in discharge_location_filter\n",
    "        and example[1] in admission_location_filter\n",
    "        for example in zip(\n",
    "            examples[\"discharge_location\"], examples[\"admission_location\"]\n",
    "        )\n",
    "    ],\n",
    "    batched=True,\n",
    "    num_proc=NUM_PROC,\n",
    "    load_from_cache_file=False,  # timeit will run multiple times\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Filtering on a datetime condition**\n",
    "\n",
    "Get all rows where `date of death` occurred after January 1, 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "dod_ddf = ddf[ddf[\"dod\"] > datetime.datetime(2020, 1, 1)].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "dod_ds = mimiciv_ds.filter(\n",
    "    lambda examples: [\n",
    "        example is not None and example > datetime.datetime(2020, 1, 1)\n",
    "        for example in examples[\"dod\"]\n",
    "    ],\n",
    "    batched=True,\n",
    "    num_proc=NUM_PROC,\n",
    "    load_from_cache_file=False,  # timeit will run multiple times\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Filter on a condition on a column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "millenials_ddf = ddf[(ddf.age <= 40) & (ddf.age >= 25)].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "millenials_ds = mimiciv_ds.filter(\n",
    "    lambda examples: [25 <= example <= 40 for example in examples[\"age\"]],\n",
    "    batched=True,\n",
    "    num_proc=NUM_PROC,\n",
    "    load_from_cache_file=False,  # timeit will run multiple times\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Data - Constructing a ðŸ¤— Dataset from image folder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the ðŸ¤— Datasets documentation, there are 3 ways to load local image data into a ðŸ¤— Dataset:\n",
    "1. **Load images from a folder with the following structure:**\n",
    "    ```bash\n",
    "    root_folder/train/class1/img1.png\n",
    "    root_folder/train/class1/img2.png\n",
    "    root_folder/train/class2/img1.png\n",
    "    root_folder/train/class2/img2.png\n",
    "    root_folder/test/class1/img1.png\n",
    "    root_folder/test/class1/img2.png\n",
    "    root_folder/test/class2/img1.png\n",
    "    root_folder/test/class2/img2.png\n",
    "    ...\n",
    "    ```\n",
    "    The folder names are the class names and the dataset splits (train/test) will automatically be recognized.\n",
    "    The dataset can be loaded using the following code:\n",
    "    ```python\n",
    "    from datasets import load_dataset\n",
    "    dataset = load_dataset(\"imagefolder\", data_dir=\"root_folder\")\n",
    "    ```\n",
    "    (This method also supports loading remote image folders from URLs.)\n",
    "    \n",
    "    The downside of this approach is that it uses PIL to load the images, which does not support many medical image formats like DICOM and NIfTI.\n",
    "\n",
    "2. **Load images using a list of image paths**\n",
    "    ```python\n",
    "    from datasets import Dataset\n",
    "    from datasets.features import Image\n",
    "    dataset = Dataset.from_dict({\"image\": [\"path/to/img1.png\", \"path/to/img2.png\", ...]}).cast_column(\"image\", Image())\n",
    "    ```\n",
    "    This approach is more flexible than the previous one, but it still has the same limitation of not supporting many medical image formats.\n",
    "\n",
    "3. **Create a dataset loading script**\n",
    "\n",
    "    This is the most flexible way to load and share different types of datasets that are not natively supported by ðŸ¤— Datasets library.\n",
    "    In fact, the `imagefolder` dataset is an example of a dataset loading script. In essence, we can extend that script to support more image formats like DICOM and NIfTI. That solves half the problem. The other half is that we need to create a new feature to extend the `Image` class to support decoding medical image formats."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case Study: MIMIC-CXR-JPG v2.0.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this case study, we will combine CSV metadata and the `Image` feature to create a ðŸ¤— Dataset from the MIMIC-CXR-JPG v2.0.0 dataset. The dataset is available on [PhysioNet](https://physionet.org/content/mimic-cxr-jpg/2.0.0/).\n",
    "\n",
    "The dataset comes with 4 compressed CSV metadata files. The metadata files are `mimic-cxr-2.0.0-split.csv.gz`, `mimic-cxr-2.0.0-chexpert.csv.gz`, `mimic-cxr-2.0.0-negbio.csv.gz`, and `mimic-cxr-2.0.0-metadata.csv.gz`. The `mimic-cxr-2.0.0-split.csv.gz` file contains the train/val/test split for each image. The `mimic-cxr-2.0.0-chexpert.csv.gz` file contains the CheXpert labels for each image. The `mimic-cxr-2.0.0-negbio.csv.gz` file contains the NegBio labels for each image. The `mimic-cxr-2.0.0-metadata.csv.gz` file contains other metadata for each image. All the metadata files can be joined on the `subject_id` and `study_id` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_cxr_jpg_dir = \"/mnt/data/clinical_datasets/mimic-cxr-jpg-2.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read metdata files using pandas\n",
    "metadata_df = pd.read_csv(\n",
    "    os.path.join(mimic_cxr_jpg_dir, \"mimic-cxr-2.0.0-metadata.csv.gz\")\n",
    ")\n",
    "negbio_df = pd.read_csv(\n",
    "    os.path.join(mimic_cxr_jpg_dir, \"mimic-cxr-2.0.0-negbio.csv.gz\")\n",
    ")\n",
    "split_df = pd.read_csv(os.path.join(mimic_cxr_jpg_dir, \"mimic-cxr-2.0.0-split.csv.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the 3 metadata dataframes on subject_id and study_id\n",
    "metadata_df = metadata_df.merge(\n",
    "    split_df, on=[\"subject_id\", \"study_id\", \"dicom_id\"]\n",
    ").merge(negbio_df, on=[\"subject_id\", \"study_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows with images in folder 'p10' i.e. subject_id starts with 10\n",
    "metadata_df = metadata_df[metadata_df[\"subject_id\"].astype(str).str.startswith(\"10\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create HuggingFace Dataset from pandas DataFrame\n",
    "mimic_cxr_ds = Dataset.from_pandas(\n",
    "    metadata_df[metadata_df.split == \"train\"], split=\"train\", preserve_index=False\n",
    ")\n",
    "mimic_cxr_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column with the full path to the image:\n",
    "# mimic_cxr_jpg_dir + \"p10\" + \"p\" + subject_id + study_id + dicom_id + \".jpg\"\n",
    "\n",
    "\n",
    "def get_filename(examples):\n",
    "    subject_ids = examples[\"subject_id\"]\n",
    "    study_ids = examples[\"study_id\"]\n",
    "    dicom_ids = examples[\"dicom_id\"]\n",
    "    examples[\"image\"] = [\n",
    "        os.path.join(\n",
    "            mimic_cxr_jpg_dir,\n",
    "            \"files\",\n",
    "            \"p10\",\n",
    "            \"p\" + str(subject_id),\n",
    "            \"s\" + str(study_id),\n",
    "            dicom_id + \".jpg\",\n",
    "        )\n",
    "        for subject_id, study_id, dicom_id in zip(subject_ids, study_ids, dicom_ids)\n",
    "    ]\n",
    "    return examples\n",
    "\n",
    "\n",
    "mimic_cxr_ds = mimic_cxr_ds.map(\n",
    "    get_filename,\n",
    "    batched=True,\n",
    "    num_proc=NUM_PROC,\n",
    "    remove_columns=[\"dicom_id\", \"split\", \"Rows\", \"Columns\"],\n",
    ")\n",
    "mimic_cxr_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_cxr_ds = mimic_cxr_ds.cast_column(\"image\", Image())\n",
    "mimic_cxr_ds.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cyclops.data.utils import set_decode  # noqa: E402\n",
    "\n",
    "set_decode(mimic_cxr_ds, decode=False)\n",
    "mimic_cxr_ds[0][\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_decode(dataset=mimic_cxr_ds, decode=True)\n",
    "mimic_cxr_ds[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending ðŸ¤— Dataset to Load DICOM (and NIfTI) images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "\n",
    "# code for plotting 3D images\n",
    "# Taken from: https://www.datacamp.com/tutorial/matplotlib-3d-volumetric-data\n",
    "def multi_slice_viewer(volume):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.volume = volume\n",
    "    ax.index = volume.shape[0] // 2\n",
    "    ax.imshow(volume[ax.index], cmap=\"gray\")\n",
    "    fig.canvas.mpl_connect(\"key_press_event\", process_key)\n",
    "\n",
    "\n",
    "def process_key(event):\n",
    "    fig = event.canvas.figure\n",
    "    ax = fig.axes[0]\n",
    "    if event.key == \"a\":\n",
    "        previous_slice(ax)\n",
    "    elif event.key == \"d\":\n",
    "        next_slice(ax)\n",
    "    fig.canvas.draw()\n",
    "\n",
    "\n",
    "def previous_slice(ax):\n",
    "    \"\"\"Go to the previous slice.\"\"\"\n",
    "    volume = ax.volume\n",
    "    ax.index = (ax.index - 1) % volume.shape[0]  # wrap around using %\n",
    "    ax.images[0].set_array(volume[ax.index])\n",
    "\n",
    "\n",
    "def next_slice(ax):\n",
    "    \"\"\"Go to the next slice.\"\"\"\n",
    "    volume = ax.volume\n",
    "    ax.index = (ax.index + 1) % volume.shape[0]\n",
    "    ax.images[0].set_array(volume[ax.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/mnt/data/clinical_datasets/coherent-11-07-2022/dicom/\"\n",
    "# ROOT_DIR = \"/mnt/data/clinical_datasets/pseudo_phi_dataset/Pseudo-PHI-DICOM-Data/\"\n",
    "\n",
    "dcm_files = glob.glob(ROOT_DIR + \"/**/*.dcm\", recursive=True)\n",
    "len(dcm_files)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a new feature class that extends the `Image` class to support decoding medical image formats. Let's call it `MedicalImage`. This will use MONAI to decode the medical image formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cyclops.data import MedicalImage  # noqa: E402\n",
    "\n",
    "# or\n",
    "# from cyclops.data.features import MedicalImage  # noqa: E402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_ds = Dataset.from_dict({\"image\": dcm_files}).cast_column(\"image\", MedicalImage())\n",
    "print(\"Number of rows: \", dicom_ds.num_rows)\n",
    "print(\"Features: \", dicom_ds.features)\n",
    "print(\"Image column contents: \", list(dicom_ds[0][\"image\"].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = dicom_ds[0][\"image\"][\"array\"].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a new dataset loading script that extends the `imagefolder` dataset \n",
    "loading script to support the `MedicalImage` feature class. We can call it \n",
    "`medical_imagefolder`. \n",
    "\n",
    "For cyclops, the dataset loading script can be found in `cyclops/datasets/packaged_loading_scripts`.\n",
    "Our new dataset loading script can be used with `load_dataset` by simply passing\n",
    "the string `\"medical_imagefolder\"` to the `path` argument. This works because\n",
    "we haved added the path to the script to huggingface's _PACKAGED_DATASETS_MODULES\n",
    "registry in `cyclops/datasets/__init__.py`. This means that `cyclops.data`\n",
    "must be imported for the script to be registered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_ds = load_dataset(\"medicalimagefolder\", data_files=dcm_files, split=Split.ALL)\n",
    "print(\"Number of rows: \", med_ds.num_rows)\n",
    "print(\"Features: \", med_ds.features)\n",
    "print(\"Image column contents: \", list(med_ds[0][\"image\"].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_img = med_ds[150][\"image\"][\"array\"]\n",
    "multi_slice_viewer(med_img.T)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Challenges\n",
    "\n",
    "1. Handling metadata. What to do with it?\n",
    "2. Encoding and decoding image bytes in the formats that are supported by the `MedicalImage` feature class."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Training and Evaluation of Scikit-Learn and PyTorch Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cyclops.evaluate.evaluator as evaluator  # noqa: E402\n",
    "from cyclops.evaluate.fairness import FairnessConfig  # noqa: E402\n",
    "from cyclops.evaluate.fairness import evaluate_fairness  # noqa: E402"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-Learn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encounters_ds = load_dataset(\n",
    "    \"parquet\", data_files=ENCOUNTERS_FILE, split=Split.ALL, keep_in_memory=True\n",
    ")\n",
    "encounters_ds.cleanup_cache_files()\n",
    "encounters_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test - 0.6, 0.4\n",
    "# NOTE: train_test_split does not work with IterableDataset objects\n",
    "encounters_ds = encounters_ds.cast_column(TAB_FEATURES[-1], ClassLabel(num_classes=2))\n",
    "encounters_ds = encounters_ds.train_test_split(\n",
    "    test_size=0.4, seed=42, stratify_by_column=TAB_FEATURES[-1]\n",
    ")\n",
    "encounters_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAB_FEATURES"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing pipeline\n",
    "numeric_features = [0]  # ['age']\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "categorical_features = [1, 2, 3]  # ['sex', 'admission_type', 'admission_location']\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a count of the positive and negative samples\n",
    "import pyarrow.compute as pc  # noqa: E402\n",
    "\n",
    "value_counts = pc.value_counts(encounters_ds[\"train\"]._data[TAB_FEATURES[-1]]).tolist()\n",
    "pos_count = value_counts[1][\"counts\"]\n",
    "neg_count = value_counts[0][\"counts\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "\n",
    "for model_name in list_models(\"sklearn\"):\n",
    "    if \"classifier\" not in model_name:  # use only classifiers\n",
    "        continue\n",
    "\n",
    "    # load the config file for the model\n",
    "    config_path = join(CONFIG_ROOT, model_name + \".yaml\")\n",
    "    with open(config_path, \"r\") as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "\n",
    "    if model_name == \"xgb_classifier\":\n",
    "        # set the scale_pos_weight parameter to account for the class imbalance\n",
    "        cfg[\"scale_pos_weight\"] = neg_count / pos_count\n",
    "\n",
    "    model_dict[model_name] = create_model(model_name, **cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in model_dict.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model_dict[model_name] = model.fit(\n",
    "        encounters_ds[\"train\"],\n",
    "        feature_columns=TAB_FEATURES[:-1],\n",
    "        target_columns=[TAB_FEATURES[-1]],\n",
    "        transforms=preprocessor,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify some filters to apply to the dataset\n",
    "slice_list = [\n",
    "    # remove null values in column\n",
    "    {\"dod\": {\"keep_nulls\": False}},\n",
    "    {\n",
    "        \"admission_type\": {\"keep_nulls\": True, \"negate\": True},\n",
    "        \"admission_location\": {\"keep_nulls\": False},\n",
    "    },\n",
    "    # filter by exact value\n",
    "    {\"sex\": {\"value\": \"M\"}},\n",
    "    # filter numeric values by range\n",
    "    {\n",
    "        \"age\": {\n",
    "            \"min_value\": 18,\n",
    "            \"max_value\": 65,\n",
    "            \"min_inclusive\": True,\n",
    "            \"max_inclusive\": False,\n",
    "        }\n",
    "    },\n",
    "    # filter by value in list\n",
    "    {\"admission_type\": {\"value\": [\"EW EMER.\", \"DIRECT EMER.\", \"URGENT\"]}},\n",
    "    # filter string values by substring\n",
    "    {\"admission_location\": {\"contains\": \"REFERRAL\"}},\n",
    "    # filter by date range (time string format: YYYY-MM-DD)\n",
    "    {\"dod\": {\"max_value\": \"2019-12-01\", \"keep_nulls\": True}},\n",
    "    # negate a filter\n",
    "    {\"dod\": {\"max_value\": \"2019-12-01\", \"negate\": True}},\n",
    "    # filter by month (1-12)\n",
    "    {\"admit_timestamp\": {\"month\": [6, 7, 8, 9], \"keep_nulls\": False}},\n",
    "    {\n",
    "        \"sex\": {\"value\": \"F\"},\n",
    "        \"race\": {\"contains\": [\"BLACK\", \"WHITE\"]},\n",
    "        \"age\": {\"min_value\": 25, \"max_value\": 40},\n",
    "    },  # compound slice\n",
    "]\n",
    "\n",
    "# create the slice functions\n",
    "slice_spec = SliceSpec()\n",
    "for slice_ in slice_list:\n",
    "    slice_spec.add_slice_spec(slice_)\n",
    "\n",
    "# or\n",
    "# slice_spec = SliceSpec(spec_list=slice_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the metrics\n",
    "metric_names = [\"accuracy\", \"precision\", \"recall\", \"f1_score\", \"auroc\"]\n",
    "metrics = [create_metric(metric_name, task=\"binary\") for metric_name in metric_names]\n",
    "tab_metrics = MetricCollection(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_eval_result = evaluator.evaluate(\n",
    "    encounters_ds,\n",
    "    tab_metrics,\n",
    "    split=\"test\",\n",
    "    models=model_dict,\n",
    "    transforms=preprocessor,\n",
    "    feature_columns=TAB_FEATURES[:-1],\n",
    "    target_columns=TAB_FEATURES[-1],\n",
    "    slice_spec=slice_spec,\n",
    "    batch_size=None,  # load all data into memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot evaluation results\n",
    "reformed_dict = {}\n",
    "for outerKey, innerDict in tab_eval_result.items():\n",
    "    for innerKey, values in innerDict.items():\n",
    "        reformed_dict[(outerKey, innerKey)] = values\n",
    "\n",
    "tidy_df = pd.melt(\n",
    "    pd.DataFrame(reformed_dict).T.rename_axis([\"model\", \"slice\"]),\n",
    "    ignore_index=False,\n",
    "    var_name=\"metric\",\n",
    ").reset_index()\n",
    "\n",
    "sns.catplot(\n",
    "    data=tidy_df,\n",
    "    x=\"slice\",\n",
    "    y=\"value\",\n",
    "    hue=\"model\",\n",
    "    row=\"slice\",\n",
    "    col=\"metric\",\n",
    "    kind=\"bar\",\n",
    "    sharey=True,\n",
    "    sharex=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specificity = create_metric(metric_name=\"specificity\", task=\"binary\")\n",
    "sensitivity = create_metric(metric_name=\"sensitivity\", task=\"binary\")\n",
    "\n",
    "fpr = 1 - specificity\n",
    "fnr = 1 - sensitivity\n",
    "ber = (fpr + fnr) / 2  # balanced error rate\n",
    "\n",
    "fairness_metric_collection = MetricCollection(\n",
    "    {\n",
    "        \"Sensitivity\": sensitivity,\n",
    "        \"Specificity\": specificity,\n",
    "        \"FPR\": fpr,\n",
    "        \"FNR\": fnr,\n",
    "        \"BER\": ber,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness_config = FairnessConfig(\n",
    "    metrics=fairness_metric_collection,\n",
    "    dataset=None,  # dataset is passed from the evaluator\n",
    "    target_columns=None,  # target columns are passed from the evaluator\n",
    "    groups=[\"sex\", \"age\"],\n",
    "    group_bins={\"age\": [26, 42, 58, 68]},\n",
    "    group_base_values={\"sex\": \"M\", \"age\": 40},\n",
    "    thresholds=[0.1, 0.5, 0.9],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_model_analysis_results = evaluator.evaluate(\n",
    "    encounters_ds,\n",
    "    tab_metrics,\n",
    "    split=\"test\",\n",
    "    models=model_dict,\n",
    "    feature_columns=TAB_FEATURES[:-1],\n",
    "    target_columns=TAB_FEATURES[-1],\n",
    "    transforms=preprocessor,\n",
    "    slice_spec=slice_spec,\n",
    "    batch_size=-1,  # use all examples at once\n",
    "    fairness_config=fairness_config,\n",
    "    override_fairness_metrics=False,  # use separate metrics for evaluating fairness\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reformed_fairness_dict = {}\n",
    "for outerKey, innerDict in tab_model_analysis_results[\"fairness\"].items():\n",
    "    for innerKey, values in innerDict.items():\n",
    "        reformed_fairness_dict[(outerKey, innerKey)] = values\n",
    "\n",
    "tidy_fairness_df = pd.melt(\n",
    "    pd.DataFrame(reformed_fairness_dict).T.rename_axis([\"model\", \"slice\"]),\n",
    "    ignore_index=False,\n",
    "    var_name=\"metric\",\n",
    ").reset_index()\n",
    "\n",
    "sns.catplot(\n",
    "    data=tidy_fairness_df,\n",
    "    x=\"slice\",\n",
    "    y=\"value\",\n",
    "    hue=\"model\",\n",
    "    row=\"metric\",\n",
    "    col=\"slice\",\n",
    "    kind=\"bar\",\n",
    "    sharey=False,\n",
    "    sharex=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nihcxr_preprocess(df: pd.DataFrame, nihcxr_dir: str) -> pd.DataFrame:\n",
    "    \"\"\"Preprocess NIHCXR dataframe.\n",
    "\n",
    "    Add a column with the path to the image and create one-hot encoded pathogies\n",
    "    from Finding Labels column.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): NIHCXR dataframe.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: pre-processed NIHCXR dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    # Add path column\n",
    "    df[\"image\"] = df[\"Image Index\"].apply(\n",
    "        lambda x: os.path.join(nihcxr_dir, \"images\", x)\n",
    "    )\n",
    "\n",
    "    # Create one-hot encoded pathologies\n",
    "    pathologies = df[\"Finding Labels\"].str.get_dummies(sep=\"|\")\n",
    "\n",
    "    # Add one-hot encoded pathologies to dataframe\n",
    "    df = pd.concat([df, pathologies], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "nihcxr_dir = \"/mnt/data/clinical_datasets/NIHCXR\"\n",
    "\n",
    "test_df = pd.read_csv(\n",
    "    join(nihcxr_dir, \"test_list.txt\"), header=None, names=[\"Image Index\"]\n",
    ")\n",
    "\n",
    "# select only the images in the test list\n",
    "df = pd.read_csv(join(nihcxr_dir, \"Data_Entry_2017.csv\"))\n",
    "df.dropna(how=\"all\", axis=\"columns\", inplace=True)  # drop empty columns\n",
    "df = df[df[\"Image Index\"].isin(test_df[\"Image Index\"])]\n",
    "\n",
    "df = nihcxr_preprocess(df, nihcxr_dir)\n",
    "\n",
    "# create a Dataset object\n",
    "nih_ds = Dataset.from_pandas(df, preserve_index=False)\n",
    "nih_ds = nih_ds.cast_column(\"image\", Image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nih_ds.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Compose(\n",
    "    [\n",
    "        # TorchVisiond(keys=(\"image\",), name=\"PILToTensor\"), doesn't work\n",
    "        AddChanneld(keys=(\"image\",)),\n",
    "        CenterSpatialCropd(keys=(\"image\",), roi_size=(1, 224, 224)),\n",
    "        Lambdad(keys=(\"image\"), func=lambda x: ((2 * (x / 255.0)) - 1.0) * 1024),\n",
    "        ToDeviced(keys=(\"image\",), device=device),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "def apply_transforms(examples: Dict[str, List], transforms: callable) -> dict:\n",
    "    \"\"\"Apply transforms to examples.\"\"\"\n",
    "\n",
    "    # examples is a dict of lists; convert to list of dicts.\n",
    "    # doing a conversion from PIL to tensor is necessary here when working\n",
    "    # with the Image feature type.\n",
    "    value_len = len(list(examples.values())[0])\n",
    "    examples = [\n",
    "        {\n",
    "            k: PILToTensor()(v[i]) if isinstance(v[i], PIL.Image.Image) else v[i]\n",
    "            for k, v in examples.items()\n",
    "        }\n",
    "        for i in range(value_len)\n",
    "    ]\n",
    "\n",
    "    # apply the transforms to each example\n",
    "    examples = [transforms(example) for example in examples]\n",
    "\n",
    "    # convert back to a dict of lists\n",
    "    examples = {k: [d[k] for d in examples] for k in examples[0]}\n",
    "\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "# from torch.utils.data.sampler import BatchSampler, RandomSampler\n",
    "\n",
    "# nih_dl = DataLoader(\n",
    "#     nih_ds.with_transform(\n",
    "#         partial(apply_transforms, transforms=transforms),\n",
    "#         columns=[\"image\"],\n",
    "#         output_all_columns=True,\n",
    "#     ),\n",
    "#     batch_size=TORCH_BATCH_SIZE,\n",
    "#     drop_last=False\n",
    "# )\n",
    "\n",
    "# for batch in nih_dl:\n",
    "#     print(batch)\n",
    "#     break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xrv.models.DenseNet(weights=\"densenet121-res224-nih\")\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.combine import concatenate_datasets  # noqa: E402\n",
    "\n",
    "\n",
    "def get_predictions_torch(examples):\n",
    "    images = torch.stack(examples[\"image\"]).squeeze(1)\n",
    "    preds = model(images)\n",
    "    return {\"predictions\": preds}\n",
    "\n",
    "\n",
    "with nih_ds.formatted_as(\n",
    "    \"custom\",\n",
    "    columns=[\"image\"],\n",
    "    transform=partial(apply_transforms, transforms=transforms),\n",
    "):\n",
    "    preds_ds = nih_ds.map(\n",
    "        get_predictions_torch,\n",
    "        batched=True,\n",
    "        batch_size=TORCH_BATCH_SIZE,\n",
    "        remove_columns=nih_ds.column_names,\n",
    "    )\n",
    "\n",
    "    nih_ds = concatenate_datasets([nih_ds, preds_ds], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nih_ds.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cyclops.data.slicer import filter_value  # noqa: E402\n",
    "\n",
    "# remove any rows with No Finding == 1\n",
    "nih_ds = nih_ds.filter(\n",
    "    partial(filter_value, column_name=\"No Finding\", value=1, negate=True), batched=True\n",
    ")\n",
    "\n",
    "# remove the No Finding column and adjust the predictions to account for it\n",
    "nih_ds = nih_ds.map(\n",
    "    lambda x: {\n",
    "        \"predictions\": x[\"predictions\"][:14],\n",
    "    },\n",
    "    remove_columns=[\"No Finding\"],\n",
    ")\n",
    "nih_ds.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of pathologies\n",
    "pathologies = model.pathologies[:14]\n",
    "pathologies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the slices\n",
    "slices = [\n",
    "    {\"Patient Gender\": {\"value\": \"M\"}},\n",
    "    {\"Patient Age\": {\"min_value\": 20, \"max_value\": 40}},\n",
    "]\n",
    "\n",
    "# create the slice functions\n",
    "slice_spec = SliceSpec(spec_list=slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc = create_metric(\n",
    "    metric_name=\"auroc\",\n",
    "    task=\"multilabel\",\n",
    "    num_labels=len(pathologies),\n",
    "    thresholds=np.arange(0, 1, 0.01),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nih_eval_results = evaluator.evaluate(\n",
    "    dataset=nih_ds,\n",
    "    metrics=auroc,\n",
    "    feature_columns=\"image\",\n",
    "    target_columns=pathologies,\n",
    "    prediction_column_prefix=\"predictions\",\n",
    "    remove_columns=\"image\",\n",
    "    slice_spec=slice_spec,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "plots = []\n",
    "\n",
    "for slice_name, slice_results in nih_eval_results.items():\n",
    "    plots.append(\n",
    "        go.Scatter(\n",
    "            x=pathologies,\n",
    "            y=slice_results[\"MultilabelAUROC\"],\n",
    "            name=\"Overall\" if slice_name == \"overall\" else slice_name,\n",
    "            mode=\"markers\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig = go.Figure(data=plots)\n",
    "fig.update_layout(\n",
    "    title=\"Multilabel AUROC by Pathology and Slice\",\n",
    "    title_x=0.5,\n",
    "    title_font_size=20,\n",
    "    xaxis_title=\"Pathology\",\n",
    "    yaxis_title=\"Multilabel AUROC\",\n",
    ")\n",
    "fig.update_traces(\n",
    "    marker=dict(size=12, line=dict(width=2, color=\"DarkSlateGrey\")),\n",
    "    selector=dict(mode=\"markers\"),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specificity = create_metric(\n",
    "    metric_name=\"specificity\",\n",
    "    task=\"multilabel\",\n",
    "    num_labels=len(pathologies),\n",
    ")\n",
    "sensitivity = create_metric(\n",
    "    metric_name=\"sensitivity\",\n",
    "    task=\"multilabel\",\n",
    "    num_labels=len(pathologies),\n",
    ")\n",
    "\n",
    "fpr = 1 - specificity\n",
    "fnr = 1 - sensitivity\n",
    "\n",
    "balanced_error_rate = (fpr + fnr) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nih_fairness_result = evaluate_fairness(\n",
    "    metrics=balanced_error_rate,\n",
    "    metric_name=\"BalancedErrorRate\",\n",
    "    dataset=nih_ds,\n",
    "    remove_columns=\"image\",\n",
    "    target_columns=pathologies,\n",
    "    prediction_columns=\"predictions\",\n",
    "    groups=[\"Patient Age\", \"Patient Gender\"],\n",
    "    group_bins={\"Patient Age\": [20, 40, 60, 80]},\n",
    "    group_base_values={\"Patient Age\": 20, \"Patient Gender\": \"M\"},\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot group size per slice\n",
    "plots = []\n",
    "\n",
    "for slice_name, slice_results in nih_fairness_result.items():\n",
    "    plots.append(\n",
    "        go.Bar(\n",
    "            x=[slice_name],\n",
    "            y=[slice_results[\"Group Size\"]],\n",
    "            name=slice_name,\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig = go.Figure(data=plots)\n",
    "fig.update_layout(\n",
    "    title=\"Size of Each Group\",\n",
    "    title_x=0.5,\n",
    "    title_font_size=20,\n",
    "    xaxis_title=\"Group\",\n",
    "    yaxis_title=\"Group Size\",\n",
    "    showlegend=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot metrics per slice\n",
    "plots = []\n",
    "\n",
    "for slice_name, slice_results in nih_fairness_result.items():\n",
    "    plots.append(\n",
    "        go.Scatter(\n",
    "            x=pathologies,\n",
    "            y=slice_results[\"BalancedErrorRate\"],\n",
    "            name=slice_name,\n",
    "            mode=\"markers\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig = go.Figure(data=plots)\n",
    "fig.update_layout(\n",
    "    title=\"Balanced Error Rate by Pathology and Group\",\n",
    "    title_x=0.5,\n",
    "    title_font_size=20,\n",
    "    xaxis_title=\"Pathology\",\n",
    "    yaxis_title=\"Balanced Error Rate\",\n",
    ")\n",
    "fig.update_traces(\n",
    "    marker=dict(size=12, line=dict(width=2, color=\"DarkSlateGrey\")),\n",
    "    selector=dict(mode=\"markers\"),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot parity difference per slice\n",
    "plots = []\n",
    "\n",
    "for slice_name, slice_results in nih_fairness_result.items():\n",
    "    plots.append(\n",
    "        go.Scatter(\n",
    "            x=pathologies,\n",
    "            y=slice_results[\"BalancedErrorRate Parity\"],\n",
    "            name=slice_name,\n",
    "            mode=\"markers\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig = go.Figure(data=plots)\n",
    "fig.update_layout(\n",
    "    title=\"Balanced Error Rate Parity by Pathology and Group\",\n",
    "    title_x=0.5,\n",
    "    title_font_size=20,\n",
    "    xaxis_title=\"Pathology\",\n",
    "    yaxis_title=\"Balanced Error Rate Parity\",\n",
    ")\n",
    "fig.update_traces(\n",
    "    marker=dict(size=12, line=dict(width=2, color=\"DarkSlateGrey\")),\n",
    "    selector=dict(mode=\"markers\"),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness_config = FairnessConfig(\n",
    "    metrics=balanced_error_rate,\n",
    "    metric_name=\"BalancedErrorRate\",\n",
    "    dataset=None,  # dataset is passed from the evaluator\n",
    "    target_columns=None,  # target columns are passed from the evaluator\n",
    "    groups=[\"Patient Age\", \"Patient Gender\"],\n",
    "    group_bins={\"Patient Age\": [20, 40, 60, 80]},\n",
    "    group_base_values={\"Patient Age\": 20, \"Patient Gender\": \"M\"},\n",
    ")\n",
    "\n",
    "evaluator.evaluate(\n",
    "    dataset=nih_ds,\n",
    "    metrics=auroc,\n",
    "    target_columns=pathologies,\n",
    "    slice_spec=slice_spec,\n",
    "    remove_columns=[\"image\"],\n",
    "    fairness_config=fairness_config,\n",
    "    override_fairness_metrics=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyclops",
   "language": "python",
   "name": "cyclops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd4e001b-4921-4a4f-8c2c-0c364d082a3f",
   "metadata": {},
   "source": [
    "# Temporal modelling for risk prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a748bba4-2852-4427-a091-bb59fcdaab4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from wanglabconsts import CONST_NAME, TAB_VEC_COMB\n",
    "from mimicmortalityconsts import CONST_NAME, TAB_VEC_COMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d8db4a-b89c-44f1-bd31-6ac2c8d10799",
   "metadata": {},
   "outputs": [],
   "source": [
    "input(f\"WARNING: LOADING CONSTANTS FROM {CONST_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4681dab-9200-4063-9544-f2013bdcd2ba",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce5e9ec-e3d0-4719-a7ee-43e88dcde8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn import metrics\n",
    "\n",
    "from cyclops.processors.column_names import EVENT_NAME, TIMESTEP\n",
    "from cyclops.processors.constants import TARGETS\n",
    "from cyclops.utils.file import load_dataframe, load_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126ca230-95a8-4937-b50b-96c35393ae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.append(\"..\")\n",
    "sys.path.append(\"../..\")\n",
    "from drift_detection.baseline_models.temporal.pytorch.optimizer import Optimizer\n",
    "from drift_detection.baseline_models.temporal.pytorch.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e583ae-7a70-49d1-9e93-26b692c85d89",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9656bc84-fa96-4ee1-8359-3e8659ad6805",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_comb = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0666b8ff-7d9c-45e7-a59e-65f0dd3c2a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660c46fe-a5fc-47e0-8334-ca048e381143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whether to use the combined data (tabular + temporal)\n",
    "# or simply the temporal data\n",
    "use_comb = True\n",
    "\n",
    "batch_size = 64\n",
    "output_dim = 1\n",
    "hidden_dim = 64\n",
    "layer_dim = 2\n",
    "dropout = 0.2\n",
    "n_epochs = 256\n",
    "learning_rate = 2e-3\n",
    "weight_decay = 1e-6\n",
    "last_timestep_only = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff98f1e3-e275-4719-a456-dd45c67b2069",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65bf786-0156-4f77-9de2-909a8e206168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep(vec):\n",
    "    arr = np.squeeze(vec.data, 0)\n",
    "    arr = np.moveaxis(arr, 2, 0)\n",
    "    # arr = np.nan_to_num(arr)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f54b30-f296-4def-9bb2-d325ee2e7807",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_comb:\n",
    "    X_train_vec = load_pickle(TAB_VEC_COMB + \"comb_train_X\")\n",
    "    y_train_vec = load_pickle(TAB_VEC_COMB + \"comb_train_y\")\n",
    "    X_val_vec = load_pickle(TAB_VEC_COMB + \"comb_val_X\")\n",
    "    y_val_vec = load_pickle(TAB_VEC_COMB + \"comb_val_y\")\n",
    "    X_test_vec = load_pickle(TAB_VEC_COMB + \"comb_test_X\")\n",
    "    y_test_vec = load_pickle(TAB_VEC_COMB + \"comb_test_y\")\n",
    "else:\n",
    "    X_train_vec = load_pickle(TAB_VEC_COMB + \"temp_train_X\")\n",
    "    y_train_vec = load_pickle(TAB_VEC_COMB + \"temp_train_y\")\n",
    "    X_val_vec = load_pickle(TAB_VEC_COMB + \"temp_val_X\")\n",
    "    y_val_vec = load_pickle(TAB_VEC_COMB + \"temp_val_y\")\n",
    "    X_test_vec = load_pickle(TAB_VEC_COMB + \"temp_test_X\")\n",
    "    y_test_vec = load_pickle(TAB_VEC_COMB + \"temp_test_y\")\n",
    "\n",
    "X_train = prep(X_train_vec.data)\n",
    "y_train = prep(y_train_vec.data)\n",
    "X_val = prep(X_val_vec.data)\n",
    "y_val = prep(y_val_vec.data)\n",
    "X_test = prep(X_test_vec.data)\n",
    "y_test = prep(y_test_vec.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04361b4b-408f-4643-81d7-a86e52b29fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec.get_index(EVENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d041a8-142a-41de-bf27-1b7e353a4b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500b3307-0a5b-42e0-be22-f5f3b989e2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_train == 1).sum() / y_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a745850c-e9d6-417a-b81c-8919a246ff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3676e60d-4fe0-4b84-8067-523adbd5ed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4578e0-ca27-4c6a-a38b-a87e4457f476",
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_val == 1).sum() / y_val.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e76157c-afe4-4b8f-b132-e94ce9b90779",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_val, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b492d92-48d1-4a44-a6f1-842330ed79d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abad0373-12d5-45ca-8502-ba6d437aa99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_test == 1).sum() / y_test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ea4d4b-27bf-447e-896d-0c195ce9b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1152bd98-00bf-45f2-af83-6ff5d64be909",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isnan(X_train).sum() == 0\n",
    "assert np.isnan(y_train).sum() == 0\n",
    "assert np.isnan(X_val).sum() == 0\n",
    "assert np.isnan(y_val).sum() == 0\n",
    "assert np.isnan(X_test).sum() == 0\n",
    "assert np.isnan(y_test).sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1df8e7a-a65e-46b9-9881-8eea1d10b4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_data(X_train, y_train)\n",
    "train_loader = train_dataset.to_loader(batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = get_data(X_val, y_val)\n",
    "val_loader = val_dataset.to_loader(batch_size)\n",
    "\n",
    "test_dataset = get_data(X_test, y_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b513c70d-8f5a-4620-8d0c-0f221684ca66",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_train.shape[2]\n",
    "timesteps = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4823c346-db3c-40f6-aa03-a7cad54aee17",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2b413b-2442-4289-a178-7e09cc7675df",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de703fc0-006e-49d1-a0df-fb99cdf7acb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"device\": device,\n",
    "    \"input_dim\": n_features,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"layer_dim\": layer_dim,\n",
    "    \"output_dim\": output_dim,\n",
    "    \"dropout_prob\": dropout,\n",
    "    \"last_timestep_only\": last_timestep_only,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b823a8-b6cd-4312-8f8d-03184cfefa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_temporal_model(\"lstm\", model_params).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388af42e-49ac-48c5-a285-8ce66a714518",
   "metadata": {},
   "source": [
    "## Training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5ba463-b493-46f6-8ec9-90774ae35b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "reweight_positive = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "reweight_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bdb2aa-8cb2-4632-b6bd-753033903716",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "optimizer = optim.Adagrad(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=weight_decay\n",
    ")\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=128, gamma=0.5)\n",
    "activation = nn.Sigmoid()\n",
    "opt = Optimizer(\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    activation=activation,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    reweight_positive=\"mini-batch\",\n",
    "    # reweight_positive=reweight_positive,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcaebba-37d7-4972-9262-c495f52d876e",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23618166-deb0-4422-918b-eb600c342e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.train(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    batch_size=batch_size,\n",
    "    n_epochs=n_epochs,\n",
    "    n_features=n_features,\n",
    "    timesteps=timesteps,\n",
    ")\n",
    "opt.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a11dbaa-02e3-4415-84ee-abc159a5337a",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f74137-9a38-40c6-92ee-1e6f4e02290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_labels, y_pred_values, y_pred_labels = opt.evaluate(\n",
    "    test_loader, batch_size=1, n_features=n_features, timesteps=timesteps\n",
    ")\n",
    "\n",
    "# WHY PASS y_test_labels back when it's literally just y_test?\n",
    "\n",
    "y_pred_values = y_pred_values[y_test_labels != -1]\n",
    "y_pred_labels = y_pred_labels[y_test_labels != -1]\n",
    "y_test_labels = y_test_labels[y_test_labels != -1]\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_test_labels, y_pred_labels)\n",
    "print(confusion_matrix)\n",
    "\n",
    "pred_metrics = print_metrics_binary(y_test_labels, y_pred_values, y_pred_labels)\n",
    "prec = (pred_metrics[\"prec0\"] + pred_metrics[\"prec1\"]) / 2\n",
    "rec = (pred_metrics[\"rec0\"] + pred_metrics[\"rec1\"]) / 2\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612d8bf4-79c5-449f-ad60-f20217377827",
   "metadata": {},
   "source": [
    "## Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449a9b82-1081-4140-814f-a5ce083662ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(confusion_matrix, class_names):\n",
    "    confusion_matrix = (\n",
    "        confusion_matrix.astype(\"float\") / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
    "    )\n",
    "\n",
    "    layout = {\n",
    "        \"title\": \"Confusion Matrix\",\n",
    "        \"xaxis\": {\"title\": \"Predicted value\"},\n",
    "        \"yaxis\": {\"title\": \"Real value\"},\n",
    "    }\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=go.Heatmap(\n",
    "            z=confusion_matrix,\n",
    "            x=class_names,\n",
    "            y=class_names,\n",
    "            hoverongaps=False,\n",
    "            colorscale=\"Greens\",\n",
    "        ),\n",
    "        layout=layout,\n",
    "    )\n",
    "    fig.update_layout(height=512, width=1024)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "plot_confusion_matrix(\n",
    "    confusion_matrix, [\"low risk of mortality\", \"high risk of mortality\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43cfde9-3c6d-4de9-817e-811376f5cb3f",
   "metadata": {},
   "source": [
    "## Compute AUROC across timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679e86a5-8db4-4e44-bf50-babfb186427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_labels, y_pred_values, y_pred_labels = opt.evaluate(\n",
    "    test_loader, batch_size=1, n_features=n_features, timesteps=timesteps, flatten=False\n",
    ")\n",
    "\n",
    "num_timesteps = y_pred_labels.shape[1]\n",
    "auroc_timesteps = []\n",
    "for i in range(num_timesteps):\n",
    "    labels = y_test_labels[:, i]\n",
    "    pred_vals = y_pred_values[:, i]\n",
    "    preds = y_pred_labels[:, i]\n",
    "    pred_vals = pred_vals[labels != -1]\n",
    "    preds = preds[labels != -1]\n",
    "    labels = labels[labels != -1]\n",
    "    pred_metrics = print_metrics_binary(labels, pred_vals, preds, verbose=False)\n",
    "    auroc_timesteps.append(pred_metrics[\"auroc\"])\n",
    "\n",
    "\n",
    "prediction_hours = list(range(24, 168, 24))\n",
    "fig = go.Figure(\n",
    "    data=[go.Bar(x=prediction_hours, y=auroc_timesteps, name=\"model confidence\")]\n",
    ")\n",
    "\n",
    "fig.update_xaxes(tickvals=prediction_hours)\n",
    "fig.update_yaxes(range=[min(auroc_timesteps) - 0.05, max(auroc_timesteps) + 0.05])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"AUROC split by no. of hours after admission\",\n",
    "    autosize=False,\n",
    "    xaxis_title=\"No. of hours after admission\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aea19ab-7dc3-4f9e-b073-17f788537b81",
   "metadata": {},
   "source": [
    "## WIP: Compute accuracy across lead times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed54c9c-4e81-4bce-9fe7-09a18296c3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE_DATA_PATH = \"/mnt/nfs/project/delirium/drift_exp/risk_of_mortality\"\n",
    "\n",
    "# combined_events = load_dataframe(os.path.join(BASE_DATA_PATH, \"combined_events\"))\n",
    "# timestep_end_timestamps = load_dataframe(os.path.join(BASE_DATA_PATH, \"aggmeta_end_ts\"))\n",
    "\n",
    "# mortality_events = combined_events.loc[combined_events[\"event_name\"] == \"death\"]\n",
    "\n",
    "# y_test_labels, y_pred_values, y_pred_labels = opt.evaluate(\n",
    "#     test_loader, batch_size=1, n_features=n_features, timesteps=timesteps, flatten=False\n",
    "# )\n",
    "# train_val_test_ids = load_dataframe(os.path.join(BASE_DATA_PATH, \"train_val_test_ids\"))\n",
    "# test_ids = train_val_test_ids[\"test\"].dropna()\n",
    "\n",
    "# num_timesteps = y_pred_labels.shape[1]\n",
    "# acc_timesteps = []\n",
    "# for timestep in range(num_timesteps):\n",
    "#     labels = y_test_labels[:, timestep]\n",
    "#     pred_vals = y_pred_values[:, timestep]\n",
    "#     preds = y_pred_labels[:, timestep]\n",
    "\n",
    "#     is_correct_timestep = []\n",
    "#     for enc_id in test_ids:\n",
    "#         timestep_end_timestamp = timestep_end_timestamps.loc[enc_id, timestep]\n",
    "#         mortality_timestamp = mortality_events.loc[mortality_events[\"encounter_id\"] == enc_id][\"discharge_timestamp\"]\n",
    "#         lead_time = mortality_timestamp - timestep_end_timestamp\n",
    "#         print(timestep_end_timestamp, mortality_timestamp)\n",
    "#         if (lead_time > pd.to_timedelta(0, unit=\"h\")).all():\n",
    "#             label_ = labels[test_ids.index(enc_id)]\n",
    "#             pred_ = preds[test_ids.index(enc_id)]\n",
    "\n",
    "#             if label_ == 1:\n",
    "#                 if label_ == pred_:\n",
    "#                     is_correct_timestep.append(1)\n",
    "#                 else:\n",
    "#                     is_correct_timestep.append(0)\n",
    "\n",
    "#     acc_timesteps.append(sum(is_correct_timestep) / len(is_correct_timestep))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8825f3a-a941-456b-b418-db620c224eb0",
   "metadata": {},
   "source": [
    "## Visualize model outputs and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6fbfab-57bc-4f07-9645-740b588d2ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_risk_mortality(predictions, labels=None):\n",
    "    prediction_hours = list(range(24, 168, 24))\n",
    "    is_mortality = labels == 1\n",
    "    after_discharge = labels == -1\n",
    "    label_h = -0.2\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Scatter(\n",
    "                mode=\"markers\",\n",
    "                x=prediction_hours,\n",
    "                y=[label_h for x in prediction_hours],\n",
    "                line=dict(color=\"Black\"),\n",
    "                name=\"low risk of mortality label\",\n",
    "                marker=dict(color=\"Green\", size=20, line=dict(color=\"Black\", width=2)),\n",
    "            ),\n",
    "            go.Scatter(\n",
    "                mode=\"markers\",\n",
    "                x=[prediction_hours[i] for i, v in enumerate(is_mortality) if v],\n",
    "                y=[label_h for _, v in enumerate(is_mortality) if v],\n",
    "                line=dict(color=\"Red\"),\n",
    "                name=\"high risk of mortality label\",\n",
    "                marker=dict(color=\"Red\", size=20, line=dict(color=\"Black\", width=2)),\n",
    "            ),\n",
    "            go.Scatter(\n",
    "                mode=\"markers\",\n",
    "                x=[prediction_hours[i] for i, v in enumerate(after_discharge) if v],\n",
    "                y=[label_h for _, v in enumerate(after_discharge) if v],\n",
    "                line=dict(color=\"Grey\"),\n",
    "                name=\"post discharge label\",\n",
    "                marker=dict(color=\"Grey\", size=20, line=dict(color=\"Black\", width=2)),\n",
    "            ),\n",
    "            go.Bar(\n",
    "                x=prediction_hours,\n",
    "                y=predictions,\n",
    "                marker_color=\"Red\",\n",
    "                name=\"model confidence\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    fig.update_yaxes(range=[label_h, 1])\n",
    "    fig.update_xaxes(tickvals=prediction_hours)\n",
    "    fig.update_xaxes(showline=True, linewidth=2, linecolor=\"black\")\n",
    "\n",
    "    fig.add_hline(y=0.5)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Model output visualization\",\n",
    "        autosize=False,\n",
    "        xaxis_title=\"No. of hours after admission\",\n",
    "        yaxis_title=\"Model confidence\",\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "mortality_cases = [idx for idx, v in enumerate(y_test_labels)]\n",
    "sample_idx = random.choice(mortality_cases)\n",
    "fig = plot_risk_mortality(\n",
    "    y_pred_values[sample_idx].squeeze(), y_test_labels[sample_idx]\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e182f4-e943-4e8f-ac45-8c445ed064c5",
   "metadata": {},
   "source": [
    "## Journal of some experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb21dd9-83a7-4b49-b328-655bf02a3c8b",
   "metadata": {},
   "source": [
    "\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Split</th>\n",
    "            <th>Model</th>\n",
    "            <th>AUROC</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td rowspan=4>Random</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>LSTM</td>\n",
    "            <td><b>0.8005</b></td>\n",
    "        </tr>\n",
    "          <tr style=\"border-bottom:1px solid black\">\n",
    "            <td colspan=\"100%\"></td>\n",
    "          </tr>\n",
    "          <tr> ... </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyclops_env",
   "language": "python",
   "name": "cyclops_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

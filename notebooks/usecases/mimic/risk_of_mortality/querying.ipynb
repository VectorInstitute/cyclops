{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8187b80-aa12-4c9b-97b2-83f83691d84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from cyclops.processors.aggregate import Aggregator\n",
    "from cyclops.processors.cleaning import (\n",
    "    normalize_categories,\n",
    "    normalize_names,\n",
    "    normalize_values,\n",
    ")\n",
    "from cyclops.processors.column_names import (\n",
    "    ADMIT_TIMESTAMP,\n",
    "    AGE,\n",
    "    CARE_UNIT,\n",
    "    DIAGNOSIS_CODE,\n",
    "    DIAGNOSIS_TRAJECTORY,\n",
    "    ENCOUNTER_ID,\n",
    "    EVENT_CATEGORY,\n",
    "    EVENT_NAME,\n",
    "    EVENT_TIMESTAMP,\n",
    "    EVENT_VALUE,\n",
    "    EVENT_VALUE_UNIT,\n",
    "    HOSPITAL_ID,\n",
    "    SEX,\n",
    "    SUBJECT_ID,\n",
    "    TIMESTEP,\n",
    "    YEAR,\n",
    ")\n",
    "from cyclops.processors.constants import (\n",
    "    BINARY,\n",
    "    BY,\n",
    "    CATEGORICAL_INDICATOR,\n",
    "    FEATURE_INDICATOR_ATTR,\n",
    "    FEATURE_MAPPING_ATTR,\n",
    "    FEATURE_TYPE_ATTR,\n",
    "    FEATURE_TYPES,\n",
    "    FEATURES,\n",
    "    MEAN,\n",
    "    MIN_MAX,\n",
    "    MISSING_CATEGORY,\n",
    "    NUMERIC,\n",
    "    ORDINAL,\n",
    "    STANDARD,\n",
    "    STRING,\n",
    "    TARGETS,\n",
    ")\n",
    "from cyclops.query import mimic\n",
    "from cyclops.query import process as qp\n",
    "from cyclops.utils.file import (\n",
    "    join,\n",
    "    load_dataframe,\n",
    "    process_dir_save_path,\n",
    "    save_consequtive_dataframes,\n",
    "    save_dataframe,\n",
    "    yield_dataframes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e81b3cd-e787-4569-96a2-546ed9bc64ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTCOME_DEATH = \"outcome_death\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3412ae-a3a2-49b1-99d7-f13014cb3d35",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Patient encounters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7883ba-5319-4035-91fb-0128fb36821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encounters_interface = mimic.patient_encounters(died_binarize_col=OUTCOME_DEATH)\n",
    "\n",
    "encounters_query = encounters_interface.query\n",
    "encounters_query = qp.Drop(\n",
    "    [\"insurance\", \"language\", \"marital_status\", \"hospital_expire_flag\"]\n",
    ")(encounters_query)\n",
    "\n",
    "encounters_interface = mimic.get_interface(encounters_query)\n",
    "encounters = encounters_interface.run()\n",
    "encounters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97d4889-d8ac-4648-b60c-3cdd18854567",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataframe(encounters, \"encounters.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a176f2de-f264-4253-ab11-da9017a4153c",
   "metadata": {},
   "source": [
    "## Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de68c082-17d8-46bc-b9ce-4b19b0a97fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_interface = mimic.events()\n",
    "\n",
    "events_query = events_interface.query\n",
    "events_query = qp.Drop([\"warning\", \"itemid\", \"storetime\"])(events_query)\n",
    "events_interface = mimic.get_interface(events_query)\n",
    "\n",
    "events_interface.save_in_grouped_batches(\"./test_batches2\", ENCOUNTER_ID, int(1e7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef7ac17-447d-4d67-a4b2-4b10f5051f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_consequtive_dataframes(\"./test_batches2\", \"./0raw2\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b41b661-f9d7-4a64-af4a-b0a03978ffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_count = 0\n",
    "generator = yield_dataframes(\"./test_batches2\")\n",
    "save_dir = \"./1cleaned\"\n",
    "save_dir = process_dir_save_path(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c812a329-ace3-4759-a008-a9a079853fa6",
   "metadata": {},
   "source": [
    "# RUNS IN BATCHES - RUN AFTER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacbe79d-0ae0-4c86-a046-26ad98234809",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = next(generator)\n",
    "events = events.drop([\"stay_id\"], axis=1)\n",
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3a947c-57eb-4c8f-9091-7c18b6353108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from pandas.errors import PerformanceWarning\n",
    "\n",
    "\n",
    "def add_years_approximate(\n",
    "    timestamp_series: pd.Series, years_series: pd.Series\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "\n",
    "    Approximates are typically either exact or incorrect by one day, e.g., on leap days.\n",
    "\n",
    "    \"\"\"\n",
    "    # Add to the years column\n",
    "    year = timestamp_series.dt.year + years_series\n",
    "\n",
    "    # Handle the other columns\n",
    "    month = timestamp_series.dt.month\n",
    "    day = timestamp_series.dt.day\n",
    "    hour = timestamp_series.dt.hour\n",
    "    minute = timestamp_series.dt.minute\n",
    "\n",
    "    # Create new timestamp column\n",
    "    data = pd.DataFrame(\n",
    "        {\"year\": year, \"month\": month, \"day\": day, \"hour\": hour, \"minute\": minute}\n",
    "    )\n",
    "\n",
    "    # Subtract 1 from potentially invalid leap days to avoid issues\n",
    "    leap_days = (month == 2) & (day == 29)\n",
    "    data[\"day\"][leap_days] -= 1\n",
    "\n",
    "    return pd.to_datetime(data)\n",
    "\n",
    "\n",
    "def add_years_exact(timestamp_series: pd.Series, years_series: pd.Series) -> pd.Series:\n",
    "    warnings.warn(\n",
    "        \"Computing the exact addition cannot be vectorized and is very slow. Consider using the quick, approximate calculation.\",\n",
    "        PerformanceWarning,\n",
    "    )\n",
    "    return timestamp_series + years_series.apply(lambda x: pd.DateOffset(years=x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcb5a0b-f0fc-4d7d-971a-c657d427be74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse deidentified dating\n",
    "events = pd.merge(\n",
    "    encounters[[ENCOUNTER_ID, \"anchor_year_difference\"]], events, on=ENCOUNTER_ID\n",
    ")\n",
    "events[EVENT_TIMESTAMP] = add_years_approximate(\n",
    "    events[EVENT_TIMESTAMP], events[\"anchor_year_difference\"]\n",
    ")\n",
    "events = events.drop(\"anchor_year_difference\", axis=1)\n",
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7e4baf-d3d8-4863-97bc-af18fc035806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the target as a timeseries event\n",
    "target_events = encounters[encounters[OUTCOME_DEATH] == True]\n",
    "target_events = target_events[[ENCOUNTER_ID, \"deathtime\"]]\n",
    "target_events = target_events.rename({\"deathtime\": EVENT_TIMESTAMP}, axis=1)\n",
    "target_events[EVENT_NAME] = OUTCOME_DEATH\n",
    "target_events[EVENT_CATEGORY] = TARGETS\n",
    "target_events[EVENT_VALUE] = 1\n",
    "target_events.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e6aca3-2a88-4bab-8a84-973bcdc36419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include target\n",
    "events = pd.concat([events, target_events])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4a818d-7ed4-48a6-9530-b232eb91b420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "events[EVENT_NAME] = normalize_names(events[EVENT_NAME])\n",
    "events[EVENT_CATEGORY] = normalize_categories(events[EVENT_CATEGORY])\n",
    "# events[EVENT_VALUE] = normalize_values(events[EVENT_VALUE])\n",
    "\n",
    "# Concatenate event name and category since some names are the same in\n",
    "# different categories, e.g., 'flow' for categories 'heartware' and 'ecmo'\n",
    "events[EVENT_NAME] = events[EVENT_CATEGORY] + \" - \" + events[EVENT_NAME]\n",
    "events.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dc2a25-f959-48f4-ad3b-4b95f940a8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataframe(events, join(save_dir, \"batch_\" + f\"{save_count:04d}\"))\n",
    "save_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e74031-8932-4d8d-af20-def726a87af3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyclops",
   "language": "python",
   "name": "cyclops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

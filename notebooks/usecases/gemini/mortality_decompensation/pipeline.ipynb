{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5117a0d-9d1f-495e-93d5-edb057cf4c0a",
   "metadata": {},
   "source": [
    "## Data pipeline for mortality decompensation prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bb2625-e38f-428a-bcfd-6299b405d0f4",
   "metadata": {},
   "source": [
    "## Imports and Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "international-relief",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from typing import List, Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from cyclops.plotter import plot_timeline, set_bars_color, setup_plot\n",
    "from cyclops.processors.aggregate import Aggregator, tabular_as_aggregated\n",
    "from cyclops.processors.cleaning import (\n",
    "    combine_events,\n",
    "    convert_to_events,\n",
    "    normalize_events,\n",
    ")\n",
    "from cyclops.processors.column_names import (\n",
    "    ADMIT_TIMESTAMP,\n",
    "    AGE,\n",
    "    DIAGNOSIS_CODE,\n",
    "    DISCHARGE_DISPOSITION,\n",
    "    DISCHARGE_TIMESTAMP,\n",
    "    ENCOUNTER_ID,\n",
    "    EVENT_CATEGORY,\n",
    "    EVENT_NAME,\n",
    "    EVENT_TIMESTAMP,\n",
    "    EVENT_VALUE,\n",
    "    HOSPITAL_ID,\n",
    "    RESTRICT_TIMESTAMP,\n",
    "    SEX,\n",
    "    TIMESTEP,\n",
    "    TRIAGE_LEVEL,\n",
    ")\n",
    "from cyclops.processors.constants import (\n",
    "    ALL,\n",
    "    BINARY,\n",
    "    CATEGORICAL_INDICATOR,\n",
    "    FEATURE_INDICATOR_ATTR,\n",
    "    FEATURE_MAPPING_ATTR,\n",
    "    FEATURE_TYPE_ATTR,\n",
    "    FEATURE_TYPES,\n",
    "    FEATURES,\n",
    "    FIRST,\n",
    "    LAST,\n",
    "    MEAN,\n",
    "    MIN_MAX,\n",
    "    MISSING_CATEGORY,\n",
    "    NUMERIC,\n",
    "    ORDINAL,\n",
    "    SMH,\n",
    "    STANDARD,\n",
    "    STRING,\n",
    "    TARGETS,\n",
    ")\n",
    "from cyclops.processors.feature.feature import TabularFeatures, TemporalFeatures\n",
    "from cyclops.processors.feature.vectorize import intersect_vectorized, split_vectorized\n",
    "from cyclops.processors.statics import compute_statics\n",
    "from cyclops.processors.string_ops import replace_if_string_match, to_lower\n",
    "from cyclops.processors.util import (\n",
    "    create_indicator_variables,\n",
    "    gather_columns,\n",
    "    pivot_aggregated_events_to_features,\n",
    ")\n",
    "from cyclops.query import gemini\n",
    "from cyclops.utils.file import load_dataframe, save_dataframe, yield_dataframes\n",
    "from notebooks.usecases.gemini.mortality_decompensation.constants import (\n",
    "    ENCOUNTERS_FILE,\n",
    "    QUERIED_DIR,\n",
    "    WINDOW_DURATION,\n",
    "    TIMESTEP_SIZE,\n",
    "    MORTALITY,\n",
    "    LOS,\n",
    "    YEARS,\n",
    "    PREDICT_OFFSET,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8091448-5301-4631-a7d4-150667441e77",
   "metadata": {},
   "source": [
    "## Query cohort and labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9efab5-8eb8-45fc-a53d-e5bfcc72ad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "encounters_interface = gemini.patient_encounters(\n",
    "    er_admin_table=gemini.get_table(gemini.ER_ADMIN),\n",
    "    years=YEARS,\n",
    "    died=True,\n",
    "    died_binarize_col=MORTALITY,\n",
    ")\n",
    "encounters = encounters_interface.run()\n",
    "save_dataframe(encounters, ENCOUNTERS_FILE)\n",
    "\n",
    "labs_interface = gemini.events(\n",
    "    years=YEARS,\n",
    "    event_category=\"lab\"\n",
    ")\n",
    "labs_interface.save_in_grouped_batches(QUERIED_DIR, ENCOUNTER_ID, int(1e7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75532f57-cc7a-4200-bcba-4bfc60e9a195",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1dabb13-1c7a-4394-a3da-6a4bbb3745bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 09:25:22,744 \u001b[1;37mINFO\u001b[0m cyclops.utils.file - Loading DataFrame from /mnt/nfs/home/krishnanam/cyclops/notebooks/usecases/gemini/mortality_decompensation/./data/encounters.parquet\n"
     ]
    }
   ],
   "source": [
    "encounters = load_dataframe(ENCOUNTERS_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b91df5c-c266-45af-8541-3d1f291a93e2",
   "metadata": {},
   "source": [
    "## Map triage level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d81be7a6-9a4c-4bd0-8f8a-406c2fcbba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap(triage_level):\n",
    "    map_ = {\n",
    "        \"1\": \"RESUSCITATION\",\n",
    "        \"2\": \"EMERGENCY\",\n",
    "        \"3\": \"URGENT\",\n",
    "        \"4\": \"SEMI-URGENT\",\n",
    "        \"5\": \"NON-URGENT\",\n",
    "    }\n",
    "    return map_.get(triage_level, \"UNKNOWN\")\n",
    "\n",
    "\n",
    "encounters[TRIAGE_LEVEL] = encounters[TRIAGE_LEVEL].apply(remap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0af1b6-1e8b-4554-944f-f13209d282cc",
   "metadata": {},
   "source": [
    "## Query imaging and transfusions, map them such that they can be treated as events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3131da1-d7e8-4564-b1ff-d6e9e2251d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 09:25:41,462 \u001b[1;37mINFO\u001b[0m cyclops.orm     - Query returned successfully!\n",
      "2022-09-29 09:25:41,463 \u001b[1;37mINFO\u001b[0m cyclops.utils.profile - Finished executing function run_query in 9.167026 s\n",
      "2022-09-29 09:25:46,311 \u001b[1;37mINFO\u001b[0m cyclops.orm     - Query returned successfully!\n",
      "2022-09-29 09:25:46,312 \u001b[1;37mINFO\u001b[0m cyclops.utils.profile - Finished executing function run_query in 0.523020 s\n"
     ]
    }
   ],
   "source": [
    "imaging_interface = gemini.imaging(years=YEARS)\n",
    "imaging = imaging_interface.run()\n",
    "imaging = pd.merge(\n",
    "    encounters, imaging, on=ENCOUNTER_ID, how=\"inner\"\n",
    ")\n",
    "\n",
    "imaging = imaging.rename(\n",
    "    columns={\n",
    "        \"imaging_test_description\": EVENT_NAME,\n",
    "        \"performed_date_time\": EVENT_TIMESTAMP,\n",
    "    }\n",
    ")\n",
    "imaging[EVENT_CATEGORY] = \"imaging\"\n",
    "imaging[EVENT_VALUE] = 1\n",
    "\n",
    "\n",
    "transfusions_interface = gemini.blood_transfusions(years=YEARS)\n",
    "transfusions = transfusions_interface.run()\n",
    "transfusions = pd.merge(\n",
    "    encounters, transfusions, on=ENCOUNTER_ID, how=\"inner\"\n",
    ")\n",
    "\n",
    "transfusions = transfusions.rename(\n",
    "    columns={\"issue_date_time\": EVENT_TIMESTAMP}\n",
    ")\n",
    "transfusions[EVENT_NAME] = transfusions[\"rbc_mapped\"]\n",
    "transfusions[EVENT_NAME] = transfusions[EVENT_NAME].apply(\n",
    "    lambda x: \"rbc\" if x else \"non-rbc\"\n",
    ")\n",
    "transfusions[EVENT_VALUE] = 1\n",
    "transfusions[EVENT_CATEGORY] = \"transfusions\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564db1ba-9f9d-4b39-a57a-90a357afab8f",
   "metadata": {},
   "source": [
    "##  Query interventions, map them such that they can be treated as events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f34a21c-49ec-48a9-bfac-0cae8dce5f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 09:25:57,025 \u001b[1;37mINFO\u001b[0m cyclops.orm     - Query returned successfully!\n",
      "2022-09-29 09:25:57,027 \u001b[1;37mINFO\u001b[0m cyclops.utils.profile - Finished executing function run_query in 1.097104 s\n",
      "/tmp/ipykernel_2034666/3907763393.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  interventions[\"intervention_episode_start_time\"].loc[\n"
     ]
    }
   ],
   "source": [
    "interventions_interface = gemini.interventions(years=YEARS)\n",
    "interventions = interventions_interface.run()\n",
    "interventions = pd.merge(\n",
    "    encounters, interventions, on=ENCOUNTER_ID, how=\"inner\"\n",
    ")\n",
    "\n",
    "interventions[EVENT_VALUE] = 1\n",
    "interventions[EVENT_CATEGORY] = \"interventions\"\n",
    "\n",
    "binary_mapped_cols = [\n",
    "    \"endoscopy_mapped\",\n",
    "    \"gi_endoscopy_mapped\",\n",
    "    \"bronch_endoscopy_mapped\",\n",
    "    \"dialysis_mapped\",\n",
    "    \"inv_mech_vent_mapped\",\n",
    "    \"surgery_mapped\",\n",
    "]\n",
    "interventions[\"intervention_episode_start_time\"].loc[\n",
    "    interventions[\"intervention_episode_start_time\"].isna()\n",
    "] = \"12:00:00\"\n",
    "interventions[EVENT_TIMESTAMP] = pd.to_datetime(\n",
    "    interventions[\"intervention_episode_start_date\"].astype(str)\n",
    "    + \" \"\n",
    "    + interventions[\"intervention_episode_start_time\"].astype(str)\n",
    ")\n",
    "interventions[EVENT_TIMESTAMP] = interventions[EVENT_TIMESTAMP].astype(\n",
    "    \"datetime64[ns]\"\n",
    ")\n",
    "interventions[\"unmapped_intervention\"] = ~(\n",
    "    interventions[\"endoscopy_mapped\"]\n",
    "    | interventions[\"gi_endoscopy_mapped\"]\n",
    "    | interventions[\"bronch_endoscopy_mapped\"]\n",
    "    | interventions[\"dialysis_mapped\"]\n",
    "    | interventions[\"inv_mech_vent_mapped\"]\n",
    "    | interventions[\"surgery_mapped\"]\n",
    ")\n",
    "interventions[EVENT_NAME] = interventions[\n",
    "    binary_mapped_cols + [\"unmapped_intervention\"]\n",
    "].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7303e205-6491-442d-92a2-abc9a5c2a15d",
   "metadata": {},
   "source": [
    "## Filter out encounters that had less than TIMESTEP_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63fc8075-57e8-49ac-b6f8-124d5b3591e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encounters[LOS] = (\n",
    "    encounters[DISCHARGE_TIMESTAMP] - encounters[ADMIT_TIMESTAMP]\n",
    ")\n",
    "encounters = encounters.loc[\n",
    "    encounters[LOS] >= pd.to_timedelta(TIMESTEP_SIZE, unit=\"h\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72566d9f-db66-47f2-8820-fdd8904aafe1",
   "metadata": {},
   "source": [
    "## Get encounters that ended in mortality outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88f04573-71c9-4f25-9a31-21df233e8e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "encounters_mortality = encounters.loc[\n",
    "    encounters[MORTALITY] == True\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1569cdd0-1d93-4aba-a6fa-082282d95eb6",
   "metadata": {},
   "source": [
    "## Get encounters which result in death within timeframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2b8036a-a108-49a9-9a0e-9cf7b818e6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "encounters_mortality_within_risk_timeframe = encounters_mortality.loc[\n",
    "    encounters_mortality[LOS]\n",
    "    <= pd.to_timedelta(PREDICT_OFFSET + WINDOW_DURATION, unit=\"h\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c6498e-f2a6-4383-89bd-6c9b5b4ee144",
   "metadata": {},
   "source": [
    "## Create death events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90081c16-ac41-4b60-ab48-7ff747630e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mortality_events = convert_to_events(\n",
    "    encounters_mortality_within_risk_timeframe,\n",
    "    event_name=f\"death\",\n",
    "    event_category=\"general\",\n",
    "    timestamp_col=DISCHARGE_TIMESTAMP,\n",
    ")\n",
    "mortality_events = pd.merge(\n",
    "    mortality_events, encounters_mortality, on=ENCOUNTER_ID, how=\"inner\"\n",
    ")\n",
    "mortality_events = mortality_events[\n",
    "    [\n",
    "        ENCOUNTER_ID,\n",
    "        EVENT_NAME,\n",
    "        EVENT_TIMESTAMP,\n",
    "        ADMIT_TIMESTAMP,\n",
    "        EVENT_VALUE,\n",
    "        EVENT_CATEGORY,\n",
    "    ]\n",
    "]\n",
    "mortality_events[EVENT_VALUE] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e2653f-b1de-4e63-8531-b92677534041",
   "metadata": {},
   "source": [
    "## Get admission/discharge events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5de93b44-b260-44d5-869f-80752cc913c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "admit_events = convert_to_events(\n",
    "    encounters,\n",
    "    event_name=\"admission\",\n",
    "    event_category=\"general\",\n",
    "    timestamp_col=ADMIT_TIMESTAMP,\n",
    ")\n",
    "disch_events = convert_to_events(\n",
    "    encounters,\n",
    "    event_name=\"discharge\",\n",
    "    event_category=\"general\",\n",
    "    timestamp_col=DISCHARGE_TIMESTAMP,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba224d47-931e-4ea1-bd18-66a5d21440ad",
   "metadata": {},
   "source": [
    "## Define aggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa233d3b-9b71-456c-b674-a39dcbcdfe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator = Aggregator(\n",
    "    aggfuncs={EVENT_VALUE: MEAN},\n",
    "    timestamp_col=EVENT_TIMESTAMP,\n",
    "    time_by=ENCOUNTER_ID,\n",
    "    agg_by=[ENCOUNTER_ID, EVENT_NAME],\n",
    "    timestep_size=TIMESTEP_SIZE,\n",
    "    window_duration=WINDOW_DURATION,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc72bcf-067c-4f49-8148-8f878ff8a5b2",
   "metadata": {},
   "source": [
    "## Process labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2c3c1be-5dab-4cef-9991-1f8cc2013f87",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not convert 20 @CKD to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KFeU18-1-py3.9/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1587\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1586\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1587\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cython_operation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1588\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maggregate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_count\u001b[49m\n\u001b[1;32m   1589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1590\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m   1591\u001b[0m     \u001b[38;5;66;03m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;66;03m# and non-applicable functions\u001b[39;00m\n\u001b[1;32m   1593\u001b[0m     \u001b[38;5;66;03m# try to python agg\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;66;03m# TODO: shouldn't min_count matter?\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KFeU18-1-py3.9/lib/python3.9/site-packages/pandas/core/groupby/ops.py:939\u001b[0m, in \u001b[0;36mBaseGrouper._cython_operation\u001b[0;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[1;32m    938\u001b[0m ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngroups\n\u001b[0;32m--> 939\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcy_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcython_operation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomp_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m    \u001b[49m\u001b[43mngroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mngroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KFeU18-1-py3.9/lib/python3.9/site-packages/pandas/core/groupby/ops.py:626\u001b[0m, in \u001b[0;36mWrappedCythonOp.cython_operation\u001b[0;34m(self, values, axis, min_count, comp_ids, ngroups, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ea_wrap_cython_operation(\n\u001b[1;32m    619\u001b[0m         values,\n\u001b[1;32m    620\u001b[0m         min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    624\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cython_op_ndim_compat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m    \u001b[49m\u001b[43mngroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mngroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomp_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomp_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KFeU18-1-py3.9/lib/python3.9/site-packages/pandas/core/groupby/ops.py:451\u001b[0m, in \u001b[0;36mWrappedCythonOp._cython_op_ndim_compat\u001b[0;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m     result_mask \u001b[38;5;241m=\u001b[39m result_mask[\u001b[38;5;28;01mNone\u001b[39;00m, :]\n\u001b[0;32m--> 451\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_cython_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mngroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mngroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomp_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomp_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresult_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KFeU18-1-py3.9/lib/python3.9/site-packages/pandas/core/groupby/ops.py:516\u001b[0m, in \u001b[0;36mWrappedCythonOp._call_cython_op\u001b[0;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m out_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_shape(ngroups, values)\n\u001b[0;32m--> 516\u001b[0m func, values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_cython_func_and_vals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_numeric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    517\u001b[0m out_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_out_dtype(values\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KFeU18-1-py3.9/lib/python3.9/site-packages/pandas/core/groupby/ops.py:199\u001b[0m, in \u001b[0;36mWrappedCythonOp.get_cython_func_and_vals\u001b[0;34m(self, values, is_numeric)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func, values\n\u001b[0;32m--> 199\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_cython_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_numeric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KFeU18-1-py3.9/lib/python3.9/site-packages/pandas/core/groupby/ops.py:164\u001b[0m, in \u001b[0;36mWrappedCythonOp._get_cython_function\u001b[0;34m(cls, kind, how, dtype, is_numeric)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39m__signatures__:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# raise NotImplementedError here rather than TypeError later\u001b[39;00m\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction is not implemented for this dtype: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[how->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,dtype->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    167\u001b[0m     )\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: function is not implemented for this dtype: [how->mean,dtype->object]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KFeU18-1-py3.9/lib/python3.9/site-packages/pandas/core/nanops.py:1622\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1621\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1622\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1624\u001b[0m     \u001b[38;5;66;03m# e.g. \"1+1j\" or \"foo\"\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '20 @CKD'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KFeU18-1-py3.9/lib/python3.9/site-packages/pandas/core/nanops.py:1626\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1625\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1626\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcomplex\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1628\u001b[0m     \u001b[38;5;66;03m# e.g. \"foo\"\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: complex() arg is a malformed string",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 15\u001b[0m\n\u001b[1;32m      7\u001b[0m events \u001b[38;5;241m=\u001b[39m events\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m tmp_features \u001b[38;5;241m=\u001b[39m TemporalFeatures(\n\u001b[1;32m      9\u001b[0m     events,\n\u001b[1;32m     10\u001b[0m     features\u001b[38;5;241m=\u001b[39mEVENT_VALUE,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     aggregator\u001b[38;5;241m=\u001b[39maggregator,\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 15\u001b[0m aggregated \u001b[38;5;241m=\u001b[39m \u001b[43mtmp_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m save_dataframe(\n\u001b[1;32m     18\u001b[0m     aggregated,\n\u001b[1;32m     19\u001b[0m     join(usecase_params\u001b[38;5;241m.\u001b[39mAGGREGATED_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_count \u001b[38;5;241m+\u001b[39m skip_n\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m04d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m events\n",
      "File \u001b[0;32m~/cyclops/cyclops/processors/feature/feature.py:882\u001b[0m, in \u001b[0;36mTemporalFeatures.aggregate\u001b[0;34m(self, **aggregate_kwargs)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(nonexistent) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    879\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following columns are not features: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(nonexistent)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    880\u001b[0m     )\n\u001b[0;32m--> 882\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43maggregate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cyclops/cyclops/utils/profile.py:32\u001b[0m, in \u001b[0;36mtime_function.<locals>.wrapper_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper_func\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     31\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 32\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     time_taken \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     34\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished executing function \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m s\u001b[39m\u001b[38;5;124m\"\u001b[39m, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, time_taken)\n",
      "File \u001b[0;32m~/cyclops/cyclops/processors/aggregate.py:580\u001b[0m, in \u001b[0;36mAggregator.__call__\u001b[0;34m(self, data, window_start_time, window_stop_time, include_timestep_start)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;66;03m# Restrict the data according to the start/stop\u001b[39;00m\n\u001b[1;32m    578\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restrict_by_timestamp(data)\n\u001b[0;32m--> 580\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_timestep_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_timestep_start\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cyclops/cyclops/processors/aggregate.py:496\u001b[0m, in \u001b[0;36mAggregator._aggregate\u001b[0;34m(self, data, include_timestep_start)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_meta_for \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_inter_imputer:\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;66;03m# EFFICIENT - Can perform if no imputation or metadata calculation is done\u001b[39;00m\n\u001b[1;32m    495\u001b[0m     grouped \u001b[38;5;241m=\u001b[39m data_with_timesteps\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_by \u001b[38;5;241m+\u001b[39m [TIMESTEP], sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 496\u001b[0m     aggregated \u001b[38;5;241m=\u001b[39m \u001b[43mgrouped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggfuncs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m     \u001b[38;5;66;03m# INEFFICIENT - Perform with a custom function to allow addded functionality\u001b[39;00m\n\u001b[1;32m    499\u001b[0m     grouped \u001b[38;5;241m=\u001b[39m data_with_timesteps\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_by, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KFeU18-1-py3.9/lib/python3.9/site-packages/pandas/core/groupby/generic.py:869\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    866\u001b[0m func \u001b[38;5;241m=\u001b[39m maybe_mangle_lambdas(func)\n\u001b[1;32m    868\u001b[0m op \u001b[38;5;241m=\u001b[39m GroupByApply(\u001b[38;5;28mself\u001b[39m, func, args, kwargs)\n\u001b[0;32m--> 869\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dict_like(func) \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KFeU18-1-py3.9/lib/python3.9/site-packages/pandas/core/apply.py:168\u001b[0m, in \u001b[0;36mApply.agg\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(arg):\n\u001b[0;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(arg):\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_list_like()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KFeU18-1-py3.9/lib/python3.9/site-packages/pandas/core/apply.py:481\u001b[0m, in \u001b[0;36mApply.agg_dict_like\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    478\u001b[0m     results \u001b[38;5;241m=\u001b[39m {key: colg\u001b[38;5;241m.\u001b[39magg(how) \u001b[38;5;28;01mfor\u001b[39;00m key, how \u001b[38;5;129;01min\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;66;03m# key used for column selection and output\u001b[39;00m\n\u001b[0;32m--> 481\u001b[0m     results \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    482\u001b[0m         key: obj\u001b[38;5;241m.\u001b[39m_gotitem(key, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39magg(how) \u001b[38;5;28;01mfor\u001b[39;00m key, how \u001b[38;5;129;01min\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    483\u001b[0m     }\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# set the final keys\u001b[39;00m\n\u001b[1;32m    486\u001b[0m keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(arg\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KFeU18-1-py3.9/lib/python3.9/site-packages/pandas/core/apply.py:482\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    478\u001b[0m     results \u001b[38;5;241m=\u001b[39m {key: colg\u001b[38;5;241m.\u001b[39magg(how) \u001b[38;5;28;01mfor\u001b[39;00m key, how \u001b[38;5;129;01min\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;66;03m# key used for column selection and output\u001b[39;00m\n\u001b[1;32m    481\u001b[0m     results \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m--> 482\u001b[0m         key: \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gotitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, how \u001b[38;5;129;01min\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    483\u001b[0m     }\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# set the final keys\u001b[39;00m\n\u001b[1;32m    486\u001b[0m keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(arg\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KFeU18-1-py3.9/lib/python3.9/site-packages/pandas/core/groupby/generic.py:281\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m cyfunc \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mget_cython_func(func)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cyfunc \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs:\n\u001b[0;32m--> 281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcyfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39mnkeys \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_agg_general(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KFeU18-1-py3.9/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1965\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[0;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[1;32m   1963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(sliding_mean, engine_kwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1964\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1965\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cython_agg_general\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1966\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1967\u001b[0m \u001b[43m        \u001b[49m\u001b[43malt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only_bool\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only_bool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1969\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1970\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KFeU18-1-py3.9/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1601\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[0;34m(self, how, alt, numeric_only, min_count)\u001b[0m\n\u001b[1;32m   1597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m   1599\u001b[0m \u001b[38;5;66;03m# TypeError -> we may have an exception in trying to aggregate\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m \u001b[38;5;66;03m#  continue and exclude the block\u001b[39;00m\n\u001b[0;32m-> 1601\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouped_reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_failures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_ser \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(new_mgr) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[1;32m   1604\u001b[0m     warn_dropping_nuisance_columns_deprecated(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m), how)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KFeU18-1-py3.9/lib/python3.9/site-packages/pandas/core/internals/base.py:199\u001b[0m, in \u001b[0;36mSingleDataManager.grouped_reduce\u001b[0;34m(self, func, ignore_failures)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03mignore_failures : bool, default False\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m    Not used; for compatibility with ArrayManager/BlockManager.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    198\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray\n\u001b[0;32m--> 199\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m index \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(res))\n\u001b[1;32m    202\u001b[0m mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_array(res, index)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KFeU18-1-py3.9/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1595\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1587\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39m_cython_operation(\n\u001b[1;32m   1588\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m, values, how, axis\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, min_count\u001b[38;5;241m=\u001b[39mmin_count\n\u001b[1;32m   1589\u001b[0m     )\n\u001b[1;32m   1590\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m   1591\u001b[0m     \u001b[38;5;66;03m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;66;03m# and non-applicable functions\u001b[39;00m\n\u001b[1;32m   1593\u001b[0m     \u001b[38;5;66;03m# try to python agg\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;66;03m# TODO: shouldn't min_count matter?\u001b[39;00m\n\u001b[0;32m-> 1595\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_agg_py_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KFeU18-1-py3.9/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1549\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[0;34m(self, values, ndim, alt)\u001b[0m\n\u001b[1;32m   1544\u001b[0m     ser \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1546\u001b[0m \u001b[38;5;66;03m# We do not get here with UDFs, so we know that our dtype\u001b[39;00m\n\u001b[1;32m   1547\u001b[0m \u001b[38;5;66;03m#  should always be preserved by the implemented aggregations\u001b[39;00m\n\u001b[1;32m   1548\u001b[0m \u001b[38;5;66;03m# TODO: Is this exactly right; see WrappedCythonOp get_result_dtype?\u001b[39;00m\n\u001b[0;32m-> 1549\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, Categorical):\n\u001b[1;32m   1552\u001b[0m     \u001b[38;5;66;03m# Because we only get here with known dtype-preserving\u001b[39;00m\n\u001b[1;32m   1553\u001b[0m     \u001b[38;5;66;03m#  reductions, we cast back to Categorical.\u001b[39;00m\n\u001b[1;32m   1554\u001b[0m     \u001b[38;5;66;03m# TODO: if we ever get \"rank\" working, exclude it here.\u001b[39;00m\n\u001b[1;32m   1555\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(values)\u001b[38;5;241m.\u001b[39m_from_sequence(res_values, dtype\u001b[38;5;241m=\u001b[39mvalues\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KFeU18-1-py3.9/lib/python3.9/site-packages/pandas/core/groupby/ops.py:981\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[0;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[1;32m    978\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 981\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aggregate_series_pure_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m npvalues \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preserve_dtype:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KFeU18-1-py3.9/lib/python3.9/site-packages/pandas/core/groupby/ops.py:1005\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[1;32m   1004\u001b[0m     group \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39m__finalize__(obj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1005\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1006\u001b[0m     res \u001b[38;5;241m=\u001b[39m libreduction\u001b[38;5;241m.\u001b[39mextract_result(res)\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m initialized:\n\u001b[1;32m   1009\u001b[0m         \u001b[38;5;66;03m# We only do this validation on the first iteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KFeU18-1-py3.9/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1967\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(sliding_mean, engine_kwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1964\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1965\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[1;32m   1966\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m-> 1967\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only_bool\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1968\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only_bool,\n\u001b[1;32m   1969\u001b[0m     )\n\u001b[1;32m   1970\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KFeU18-1-py3.9/lib/python3.9/site-packages/pandas/core/generic.py:11124\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11106\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[1;32m  11107\u001b[0m     _num_doc,\n\u001b[1;32m  11108\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the mean of the values over the requested axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11122\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11123\u001b[0m ):\n\u001b[0;32m> 11124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KFeU18-1-py3.9/lib/python3.9/site-packages/pandas/core/generic.py:10694\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  10686\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  10687\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10688\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m lib\u001b[38;5;241m.\u001b[39mNoDefault \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mno_default,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10692\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  10693\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 10694\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  10695\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m  10696\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KFeU18-1-py3.9/lib/python3.9/site-packages/pandas/core/generic.py:10646\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  10636\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m  10637\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m  10638\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10641\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m  10642\u001b[0m     )\n\u001b[1;32m  10643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_by_level(\n\u001b[1;32m  10644\u001b[0m         name, axis\u001b[38;5;241m=\u001b[39maxis, level\u001b[38;5;241m=\u001b[39mlevel, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[1;32m  10645\u001b[0m     )\n\u001b[0;32m> 10646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  10647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[1;32m  10648\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KFeU18-1-py3.9/lib/python3.9/site-packages/pandas/core/series.py:4471\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4467\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   4468\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not implement \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4469\u001b[0m     )\n\u001b[1;32m   4470\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 4471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KFeU18-1-py3.9/lib/python3.9/site-packages/pandas/core/nanops.py:93\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 93\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# object arrays that contain strings\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(args[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KFeU18-1-py3.9/lib/python3.9/site-packages/pandas/core/nanops.py:155\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    153\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KFeU18-1-py3.9/lib/python3.9/site-packages/pandas/core/nanops.py:410\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 410\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[1;32m    413\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KFeU18-1-py3.9/lib/python3.9/site-packages/pandas/core/nanops.py:698\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    695\u001b[0m     dtype_count \u001b[38;5;241m=\u001b[39m dtype\n\u001b[1;32m    697\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[0;32m--> 698\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_sum\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    701\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/cyclops-KFeU18-1-py3.9/lib/python3.9/site-packages/pandas/core/nanops.py:1629\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1626\u001b[0m             x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcomplex\u001b[39m(x)\n\u001b[1;32m   1627\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1628\u001b[0m             \u001b[38;5;66;03m# e.g. \"foo\"\u001b[39;00m\n\u001b[0;32m-> 1629\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not convert 20 @CKD to numeric"
     ]
    }
   ],
   "source": [
    "# Aggregate\n",
    "skip_n = 0\n",
    "generator = yield_dataframes(QUERIED_DIR, skip_n=skip_n, log=False)\n",
    "\n",
    "for save_count, events in enumerate(generator):\n",
    "    # Aggregate\n",
    "    events = events.reset_index(drop=True)\n",
    "    tmp_features = TemporalFeatures(\n",
    "        events,\n",
    "        features=EVENT_VALUE,\n",
    "        by=[ENCOUNTER_ID, EVENT_NAME],\n",
    "        timestamp_col=EVENT_TIMESTAMP,\n",
    "        aggregator=aggregator,\n",
    "    )\n",
    "    aggregated = tmp_features.aggregate()\n",
    "\n",
    "    save_dataframe(\n",
    "        aggregated,\n",
    "        join(usecase_params.AGGREGATED_DIR, \"batch_\" + f\"{save_count + skip_n:04d}\"),\n",
    "    )\n",
    "    del events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527e4baa-d706-4b72-88e4-7416db744d7e",
   "metadata": {},
   "source": [
    "## Normalize all event data (names, string operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e249a41-d012-4f25-9241-66c15fad7d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging = normalize_events(imaging)\n",
    "transfusions = normalize_events(transfusions)\n",
    "intervention_events = normalize_events(interventions)\n",
    "\n",
    "mortality_events = normalize_events(mortality_events)\n",
    "admit_events = normalize_events(admit_events)\n",
    "disch_events = normalize_events(disch_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5950cea0-8178-4303-865d-ceb47ac2b30d",
   "metadata": {},
   "source": [
    "## Combine different event data, save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84080940-2a0e-45ab-987a-ef7f200a7870",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_events = combine_events(\n",
    "    [\n",
    "        intervention_events,\n",
    "        imaging_events,\n",
    "        transfusion_events,\n",
    "        lab_events,\n",
    "        mortality_events,\n",
    "        admit_events,\n",
    "        disch_events,\n",
    "    ]\n",
    ")\n",
    "save_dataframe(combined_events, os.path.join(BASE_DATA_PATH, \"combined_events\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7692cd1a-e9ec-456d-9df2-3a9cfef6eeab",
   "metadata": {},
   "source": [
    "## Load combined events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9306e6-90a0-4adb-8691-972424912f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_events = load_dataframe(os.path.join(BASE_DATA_PATH, \"combined_events\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9e10d6-b372-45e6-b0b3-8aa45593ef38",
   "metadata": {},
   "source": [
    "## Aggregate combined events, save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93e02af-1c6e-4cec-8b84-52e2cf24c4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_events = combined_events.reset_index(drop=True)\n",
    "\n",
    "temporal_features = TemporalFeatures(\n",
    "    combined_events,\n",
    "    features=EVENT_VALUE,\n",
    "    by=[ENCOUNTER_ID, EVENT_NAME],\n",
    "    timestamp_col=EVENT_TIMESTAMP,\n",
    "    aggregator=aggregator,\n",
    ")\n",
    "aggregated = temporal_features.aggregate()\n",
    "save_dataframe(aggregated, os.path.join(BASE_DATA_PATH, \"aggregated\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bbc55f-d3f2-41c6-a367-c8a817b424d8",
   "metadata": {},
   "source": [
    "## Load aggregated events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab947b7d-b489-4ce6-be32-546a8d0ae6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated = load_dataframe(os.path.join(BASE_DATA_PATH, \"aggregated\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cc4793-a22b-4611-96b3-65e2bd0d3d3c",
   "metadata": {},
   "source": [
    "## Convert aggregated to vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a50a78-9e33-4f71-b45c-a2ca21ad31c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized = aggregator.vectorize(aggregated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0277e20e-c9c7-427c-b3a4-e6120b342581",
   "metadata": {},
   "source": [
    "## Add to feature handler, with indicator variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cf2259-d1e8-4d72-acb5-d4c1ebd4cfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_features = load_dataframe(os.path.join(BASE_DATA_PATH, \"temporal_features\"))\n",
    "feature_handler.add_features(temporal_features)\n",
    "feature_handler.drop_features([\"death\"])\n",
    "\n",
    "already_indicators = [\n",
    "    \"ct\",\n",
    "    \"dialysis_mapped\",\n",
    "    \"echo\",\n",
    "    \"endoscopy_mapped\",\n",
    "    \"interventional\",\n",
    "    \"inv_mech_vent_mapped\",\n",
    "    \"mri\",\n",
    "    \"non-rbc\",\n",
    "    \"other\",\n",
    "    \"rbc\",\n",
    "    \"surgery_mapped\",\n",
    "    \"ultrasound\",\n",
    "    \"unmapped_intervention\",\n",
    "    \"x-ray\",\n",
    "]\n",
    "\n",
    "temporal_features = feature_handler.features[\"temporal\"]\n",
    "indicators = create_indicator_variables(\n",
    "    temporal_features[\n",
    "        [col for col in temporal_features if col not in already_indicators]\n",
    "    ]\n",
    ")\n",
    "feature_handler.add_features(indicators)\n",
    "feature_handler.features[\"temporal\"].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025e89d8-a325-45f5-a38e-0f0ef6abe443",
   "metadata": {},
   "source": [
    "## Compute static features, save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87c4497-03d3-4304-86d1-54b4eb5b5f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "encounters_train_val_test_static_cols = gather_columns(\n",
    "    encounters_train_val_test,\n",
    "    [\n",
    "        ENCOUNTER_ID,\n",
    "        AGE,\n",
    "        SEX,\n",
    "        HOSPITAL_ID,\n",
    "        ADMIT_TIMESTAMP,\n",
    "        DISCHARGE_TIMESTAMP,\n",
    "        TRIAGE_LEVEL,\n",
    "    ],\n",
    ")\n",
    "static_features = compute_statics(encounters_train_val_test_static_cols)\n",
    "save_dataframe(static_features, os.path.join(BASE_DATA_PATH, \"static_features\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61b6950-850c-4a83-a568-45088411911a",
   "metadata": {},
   "source": [
    "##  Load static features, add to feature handler, save all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4759c9-bfd8-42ec-adeb-c518489caae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_features = load_dataframe(os.path.join(BASE_DATA_PATH, \"static_features\"))\n",
    "feature_handler.add_features(\n",
    "    static_features, reference_cols=[HOSPITAL_ID, ADMIT_TIMESTAMP, DISCHARGE_TIMESTAMP]\n",
    ")\n",
    "feature_handler.save(BASE_DATA_PATH, \"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb028c06-7771-46db-a291-f7621471ef5e",
   "metadata": {},
   "source": [
    "## Create new feature handler, load saved features from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0836f236-1f0b-46e8-90b8-8e811adcbe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_handler1 = FeatureHandler()\n",
    "feature_handler1.load(BASE_DATA_PATH, \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443ad860-99aa-4423-b660-946d91891302",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feature_handler1.features[\"temporal\"].columns), len(\n",
    "    feature_handler1.features[\"static\"].columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49719bee-1c6e-4f23-9dd9-a49f687f5370",
   "metadata": {},
   "source": [
    "## Impute temporal features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b4b887-e9da-4d69-b13e-7649ca3a6659",
   "metadata": {},
   "source": [
    "## Add static features to temporal, (duplicate for each timestep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce62b29-67dd-4624-b973-071464e18fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with both static and temporal features.\n",
    "merged_static_temporal = temporal.combine_first(static)\n",
    "numerical_cols += [\"age\"]\n",
    "\n",
    "# Train model with just temporal features\n",
    "# merged_static_temporal = temporal\n",
    "# static"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431b63a8-58d1-41b7-9793-a8406514b6c1",
   "metadata": {},
   "source": [
    "## Create labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155c4ae8-5ed3-4ab4-8d0b-c2d5d97d7181",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_timesteps = int(AGGREGATION_WINDOW / AGGREGATION_BUCKET_SIZE)\n",
    "encounter_ids = list(merged_static_temporal.index.get_level_values(0).unique())\n",
    "num_encounters = len(encounter_ids)\n",
    "\n",
    "# All zeroes.\n",
    "labels = np.zeros((num_encounters, num_timesteps))\n",
    "\n",
    "# Set mortality within timeframe encounters to all 1s.\n",
    "labels[\n",
    "    [\n",
    "        encounter_ids.index(enc_id)\n",
    "        for enc_id in list(encounters_mortality_within_risk_timeframe[ENCOUNTER_ID])\n",
    "    ]\n",
    "] = 1\n",
    "\n",
    "# Get which timestep discharge occurs and set those and following timesteps label values to be -1.\n",
    "aggregated_discharge_events = aggregated_events.loc[\n",
    "    aggregated_events[EVENT_NAME] == \"discharge\"\n",
    "]\n",
    "aggregated_mortality_events = aggregated_events.loc[\n",
    "    aggregated_events[EVENT_NAME] == \"death\"\n",
    "]\n",
    "for enc_id in list(aggregated_discharge_events[ENCOUNTER_ID]):\n",
    "    timestep_discharge = aggregated_discharge_events.loc[\n",
    "        aggregated_discharge_events[ENCOUNTER_ID] == enc_id\n",
    "    ][\"timestep\"]\n",
    "    labels[encounter_ids.index(enc_id)][int(timestep_discharge) + 1 :] = -1\n",
    "\n",
    "# Lookahead for each timestep, and see if death occurs in risk timeframe.\n",
    "for enc_id in list(encounters_mortality_within_risk_timeframe[ENCOUNTER_ID]):\n",
    "    mortality_encounter = mortality_events.loc[mortality_events[ENCOUNTER_ID] == enc_id]\n",
    "    ts_ends = timestep_end_timestamps.loc[enc_id][\"timestep_end_timestamp\"]\n",
    "    mortality_ts = mortality_encounter[\"event_timestamp\"]\n",
    "    for ts_idx, ts_end in enumerate(ts_ends):\n",
    "        if not (\n",
    "            mortality_ts <= ts_end + pd.to_timedelta(timeframe * 24, unit=\"h\")\n",
    "        ).all():\n",
    "            labels[encounter_ids.index(enc_id)][ts_idx] = 0\n",
    "\n",
    "\n",
    "mortality_risk_targets = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da874af-fc43-4373-86b5-e3296893c27b",
   "metadata": {},
   "source": [
    "## Create train/val/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67a57ca-2e72-4f17-8452-3c3e5f4d6906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_split(\n",
    "    encounters: pd.DataFrame,\n",
    "    fractions: Optional[List] = [0.8, 0.2],\n",
    "    split_column: Optional[str] = None,\n",
    "    split_values: List = None,\n",
    "    seed: int = 3,\n",
    ") -> tuple:\n",
    "    \"\"\"Split encounters into train/test.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    encounters: pandas.DataFrame\n",
    "        Dataframe with encounter IDs.\n",
    "    fractions: list, optional\n",
    "        Fraction of samples to use for train, test sets.\n",
    "    split_column: str, optional\n",
    "        If 'split_column' is specified, then that column is used to split.\n",
    "    split_values: list, optional\n",
    "        Along with 'split_column', a list of lists can be specified for filtering.\n",
    "        e.g. [[2008], [2009, 2010]] for train/test split based on year.\n",
    "    seed: int, optional\n",
    "        Seed for random number generator.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (train IDs, test IDs)\n",
    "\n",
    "    \"\"\"\n",
    "    if split_column:\n",
    "        if split_column not in encounters.columns:\n",
    "            raise ValueError(\"Specified 'split column' not found in input dataframe\")\n",
    "        if not split_values:\n",
    "            raise ValueError(\"Specify train/test split values for the 'split column'.!\")\n",
    "        train_encounters = encounters[ENCOUNTER_ID].loc[\n",
    "            encounters[split_column].isin(split_values[0])\n",
    "        ]\n",
    "        test_encounters = encounters[ENCOUNTER_ID].loc[\n",
    "            encounters[split_column].isin(split_values[1])\n",
    "        ]\n",
    "        return train_encounters, test_encounters\n",
    "\n",
    "    encounter_ids = list(encounters[ENCOUNTER_ID].unique())\n",
    "    random.seed(seed)\n",
    "    random.shuffle(encounter_ids)\n",
    "    num_train = int(fractions[0] * len(encounter_ids))\n",
    "\n",
    "    return encounter_ids[0:num_train], encounter_ids[num_train:]\n",
    "\n",
    "\n",
    "split_type = \"hospital_id\"\n",
    "\n",
    "if split_type == \"year\":\n",
    "    encounters_train_val_test[\"year\"] = encounters_train_val_test[\n",
    "        \"admit_timestamp\"\n",
    "    ].dt.year\n",
    "    train_ids, val_test_ids = create_train_test_split(\n",
    "        encounters_train_val_test,\n",
    "        split_column=\"year\",\n",
    "        split_values=[[2015, 2016, 2017, 2018, 2019], [2020]],\n",
    "    )\n",
    "    encounters_train_val_test[HOSPITAL_ID].value_counts(), encounters_train_val_test[\n",
    "        \"year\"\n",
    "    ].value_counts()\n",
    "elif split_type == \"hospital_id\":\n",
    "    train_ids, val_test_ids = create_train_test_split(\n",
    "        encounters_train_val_test,\n",
    "        split_column=HOSPITAL_ID,\n",
    "        split_values=[[\"SBK\", \"UHNTG\", \"THPC\", \"THPM\", \"UHNTW\", \"SMH\"], [\"MSH\"]],\n",
    "    )\n",
    "elif split_type == \"random\":\n",
    "    train_ids, val_test_ids = create_train_test_split(encounters_train_val_test)\n",
    "\n",
    "\n",
    "val_ids, test_ids = create_train_test_split(\n",
    "    encounters_train_val_test.loc[\n",
    "        encounters_train_val_test[ENCOUNTER_ID].isin(val_test_ids)\n",
    "    ],\n",
    "    [0.5, 0.5],\n",
    ")\n",
    "print(\n",
    "    f\"Train set: {len(train_ids)}, Val set: {len(val_ids)}, Test set: {len(test_ids)}\"\n",
    ")\n",
    "\n",
    "X = merged_static_temporal[\n",
    "    np.in1d(temporal.index.get_level_values(0), static.index.get_level_values(0))\n",
    "]\n",
    "\n",
    "y_train, y_val, y_test = [\n",
    "    mortality_risk_targets[np.in1d(encounter_ids, ids)]\n",
    "    for ids in [train_ids, val_ids, test_ids]\n",
    "]\n",
    "X_train, X_val, X_test = [\n",
    "    X[np.in1d(X.index.get_level_values(0), ids)]\n",
    "    for ids in [train_ids, val_ids, test_ids]\n",
    "]\n",
    "\n",
    "len(X), len(X_train), len(X_val), len(X_test), len(mortality_risk_targets), len(\n",
    "    y_train\n",
    "), len(y_val), len(y_test)\n",
    "assert len(X.index.get_level_values(0).unique()) == len(mortality_risk_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f36dce7-2857-45bd-91af-69a7f4485597",
   "metadata": {},
   "source": [
    "## Save train/val/test ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a95142-e91f-43a9-a7b2-0e8a3c8b185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids_df = pd.DataFrame({\"train\": train_ids})\n",
    "val_ids_df = pd.DataFrame({\"val\": val_ids})\n",
    "test_ids_df = pd.DataFrame({\"test\": test_ids})\n",
    "train_val_test_ids = pd.concat([train_ids_df, val_ids_df, test_ids_df], axis=1)\n",
    "save_dataframe(\n",
    "    train_val_test_ids, os.path.join(BASE_DATA_PATH, split_type, \"train_val_test_ids\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bccd89-2893-45ea-b2b9-07629f4693c6",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cfd46a-5ec5-4cc0-8291-fd2261abbbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train_normalized = X_train.copy()\n",
    "X_val_normalized = X_val.copy()\n",
    "X_test_normalized = X_test.copy()\n",
    "\n",
    "for col in numerical_cols:\n",
    "    scaler = StandardScaler().fit(X_train[col].values.reshape(-1, 1))\n",
    "    X_train_normalized[col] = pd.Series(\n",
    "        np.squeeze(scaler.transform(X_train[col].values.reshape(-1, 1))),\n",
    "        index=X_train[col].index,\n",
    "    )\n",
    "    X_val_normalized[col] = pd.Series(\n",
    "        np.squeeze(scaler.transform(X_val[col].values.reshape(-1, 1))),\n",
    "        index=X_val[col].index,\n",
    "    )\n",
    "    X_test_normalized[col] = pd.Series(\n",
    "        np.squeeze(scaler.transform(X_test[col].values.reshape(-1, 1))),\n",
    "        index=X_test[col].index,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a072b711-31cc-4693-8b41-100f4dd39265",
   "metadata": {},
   "source": [
    "## Save inputs and labels as numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a168e69-a265-426f-9ab2-2a0cba495691",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(BASE_DATA_PATH, split_type), exist_ok=True)\n",
    "\n",
    "X_train_normalized.to_parquet(\n",
    "    os.path.join(BASE_DATA_PATH, split_type, \"X_train.parquet\")\n",
    ")\n",
    "X_val_normalized.to_parquet(os.path.join(BASE_DATA_PATH, split_type, \"X_val.parquet\"))\n",
    "X_test_normalized.to_parquet(os.path.join(BASE_DATA_PATH, split_type, \"X_test.parquet\"))\n",
    "\n",
    "np.save(os.path.join(BASE_DATA_PATH, split_type, \"y_train.npy\"), y_train)\n",
    "np.save(os.path.join(BASE_DATA_PATH, split_type, \"y_val.npy\"), y_val)\n",
    "np.save(os.path.join(BASE_DATA_PATH, split_type, \"y_test.npy\"), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70504f5c-eeed-43c7-aa08-e63e81cb5b85",
   "metadata": {},
   "source": [
    "## Load train/val/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d301151-c865-4525-bf86-1e0f5bdde1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized = pd.read_parquet(\n",
    "    os.path.join(BASE_DATA_PATH, split_type, \"X_train.parquet\")\n",
    ")\n",
    "X_val_normalized = pd.read_parquet(\n",
    "    os.path.join(BASE_DATA_PATH, split_type, \"X_val.parquet\")\n",
    ")\n",
    "X_test_normalized = pd.read_parquet(\n",
    "    os.path.join(BASE_DATA_PATH, split_type, \"X_test.parquet\")\n",
    ")\n",
    "\n",
    "y_train = np.load(os.path.join(BASE_DATA_PATH, split_type, \"y_train.npy\"))\n",
    "y_val = np.load(os.path.join(BASE_DATA_PATH, split_type, \"y_val.npy\"))\n",
    "y_test = np.load(os.path.join(BASE_DATA_PATH, split_type, \"y_test.npy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3219bbb-2ebb-42fb-879b-8e8f06d69861",
   "metadata": {},
   "source": [
    "## Reshape inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10d73ba-d526-45b6-97e5-8d56f3442b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_inputs(inputs, num_timesteps):\n",
    "    inputs = inputs.unstack()\n",
    "    num_encounters = inputs.shape[0]\n",
    "    inputs = inputs.values.reshape((num_encounters, num_timesteps, -1))\n",
    "\n",
    "    return inputs\n",
    "\n",
    "\n",
    "X_train_normalized_npy = reshape_inputs(X_train_normalized, num_timesteps)\n",
    "X_val_normalized_npy = reshape_inputs(X_val_normalized, num_timesteps)\n",
    "X_test_normalized_npy = reshape_inputs(X_test_normalized, num_timesteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a264bcee-1271-464a-a392-d8e369ec77e7",
   "metadata": {},
   "source": [
    "## Save inputs as npy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8df48d-7ecc-46c9-904e-82a9637368da",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(BASE_DATA_PATH, split_type, \"X_train.npy\"), X_train_normalized_npy)\n",
    "np.save(os.path.join(BASE_DATA_PATH, split_type, \"X_val.npy\"), X_val_normalized_npy)\n",
    "np.save(os.path.join(BASE_DATA_PATH, split_type, \"X_test.npy\"), X_test_normalized_npy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6812a9a8-1966-48a1-9094-66db6b4bde31",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25f4a47-a2f2-4071-8ae4-0b13957105a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encounter_id = random.choice(encounter_ids)\n",
    "encounter_id = 13772609\n",
    "\n",
    "# Show examples:\n",
    "# 12779290, 13772609 - lookahead\n",
    "# 11454928, 15795997 - no mortality\n",
    "# 15253874 - all 1s\n",
    "\n",
    "print(encounter_id)\n",
    "combined_events_encounter = combined_events.loc[\n",
    "    combined_events[\"encounter_id\"] == encounter_id\n",
    "]\n",
    "fig = plot_timeline(combined_events_encounter, return_fig=True)\n",
    "\n",
    "fig = fig.update_layout(width=2000, height=800)\n",
    "\n",
    "ts_starts = timestep_start_timestamps.loc[encounter_id][\"timestep_start_timestamp\"]\n",
    "ts_ends = timestep_end_timestamps.loc[encounter_id][\"timestep_end_timestamp\"]\n",
    "for ts_end in ts_ends:\n",
    "    fig.add_vline(ts_end)\n",
    "\n",
    "label_encounter = labels[encounter_ids.index(encounter_id)]\n",
    "\n",
    "for i in range(num_timesteps):\n",
    "    label_ts = label_encounter[i]\n",
    "    color_map = {-1: \"grey\", 0: \"green\", 1: \"red\"}\n",
    "    fig.add_vrect(\n",
    "        x0=ts_starts[i],\n",
    "        x1=ts_ends[i],\n",
    "        fillcolor=color_map[label_ts],\n",
    "        opacity=0.25,\n",
    "        line_width=0,\n",
    "    )\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyclops",
   "language": "python",
   "name": "cyclops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

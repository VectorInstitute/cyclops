{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ignored-hostel",
   "metadata": {},
   "source": [
    "### This notebook loads extracted data, looks through the different fields, trains some baselines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-memorial",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-discount",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-necessity",
   "metadata": {},
   "source": [
    "## Load data, print keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-antigua",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/mnt/nfs/project/delirium/all_hourly_data.h5\"\n",
    "# DATA_PATH = \"/mnt/nfs/project/delirium/_extract/all_hourly_data.h5\"\n",
    "\n",
    "SITE = \"SMH\"\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "with pd.HDFStore(DATA_PATH, \"r\") as hdf:\n",
    "    hdf_keys= list(hdf.keys())\n",
    "    print(hdf_keys)\n",
    "    \n",
    "    dfs={}\n",
    "    print('Reading Patient Data ...')\n",
    "    dfs['statics'] = pd.read_hdf(DATA_PATH, key='patients')\n",
    "    dfs[f'labs_{SITE}'] = pd.read_hdf(DATA_PATH, key=f'vitals_labs_{SITE}')\n",
    "    dfs[f'outcomes_{SITE}'] = pd.read_hdf(DATA_PATH, key=f'interventions_{SITE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-plane",
   "metadata": {},
   "source": [
    "## Patient Statics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-investigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs['statics'].count())\n",
    "dfs['statics']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-provincial",
   "metadata": {},
   "source": [
    "## Labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-workstation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs[f'labs_{SITE}'].count())\n",
    "dfs[f'labs_{SITE}']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-yorkshire",
   "metadata": {},
   "source": [
    "## Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-distance",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs[f'outcomes_{SITE}'].count())\n",
    "dfs[f'outcomes_{SITE}']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sought-spain",
   "metadata": {},
   "source": [
    "## Train linear regression models (delirium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-theorem",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "HOSPITAL_ID = {\n",
    "    \"THPM\": 0,\n",
    "    \"SBK\": 1,\n",
    "    \"UHNTG\": 2,\n",
    "    \"SMH\": 3,\n",
    "    \"UHNTW\": 4,\n",
    "    \"THPC\": 5,\n",
    "    \"PMH\": 6,\n",
    "    \"MSH\": 7,\n",
    "}\n",
    "features = [\n",
    "    \"sex\",\n",
    "    \"age\",\n",
    "    \"icd10_A00_B99\",\n",
    "    \"icd10_C00_D49\",\n",
    "    \"icd10_D50_D89\",\n",
    "    \"icd10_E00_E89\",\n",
    "    \"icd10_F01_F99\",\n",
    "    \"icd10_G00_G99\",\n",
    "    \"icd10_H00_H59\",\n",
    "    \"icd10_H60_H95\",\n",
    "    \"icd10_I00_I99\",\n",
    "    \"icd10_J00_J99\",\n",
    "    \"icd10_K00_K95\",\n",
    "    \"icd10_L00_L99\",\n",
    "    \"icd10_M00_M99\",\n",
    "    \"icd10_N00_N99\",\n",
    "    \"icd10_O00_O99\",\n",
    "    \"icd10_Q00_Q99\",\n",
    "    \"icd10_R00_R99\",\n",
    "    \"icd10_S00_T88\",\n",
    "    \"icd10_U07_U08\",\n",
    "    \"icd10_Z00_Z99\"\n",
    "]\n",
    "normalize_features = [\"sex\", \"age\"]\n",
    "predict = \"del_present\"\n",
    "\n",
    "\n",
    "def split_dataset(df, t, v, split_col):\n",
    "    train = df.loc[df[split_col].isin(t)]\n",
    "    val = df.loc[df[split_col].isin(v)]\n",
    "    return train, val\n",
    "\n",
    "\n",
    "def normalize(df, features, mean=None, std=None):\n",
    "    if mean is None or std is None:\n",
    "        mean, std = df[features].mean(), df[features].std()\n",
    "    df[features] = (df[features] - mean) / std\n",
    "    return df, mean, std\n",
    "\n",
    "\n",
    "dataset = dfs['statics']\n",
    "# Take out only delirium cohort.\n",
    "dataset = dataset.loc[dataset['gemini_cohort'] == True]\n",
    "dataset = dataset.loc[dataset['del_present'] != 3]\n",
    "print(dataset.count())\n",
    "\n",
    "\n",
    "\n",
    "hospitals = dataset['hospital_id'].unique()\n",
    "\n",
    "for hos in hospitals:\n",
    "    train_hospitals = [h for h in hospitals if h != hos]\n",
    "    val_hospitals = [hos]\n",
    "\n",
    "\n",
    "    train_dataset, val_dataset = split_dataset(dataset, train_hospitals, val_hospitals, 'hospital_id')\n",
    "    # Normalize some of the features (not the ones that are one-hot encoded).\n",
    "    train_dataset, mean, std = normalize(train_dataset, normalize_features)\n",
    "\n",
    "\n",
    "    train_dataset = train_dataset[features].join(train_dataset[[predict]])\n",
    "    val_dataset = val_dataset[features].join(val_dataset[[predict]])\n",
    "    train_dataset = train_dataset.dropna()\n",
    "    val_dataset = val_dataset.dropna()\n",
    "    # print(train_dataset.count(), val_dataset.count())\n",
    "\n",
    "    train_inputs = train_dataset[features].to_numpy()\n",
    "    train_labels = train_dataset[[predict]].to_numpy().squeeze().astype(np.int32)\n",
    "    val_inputs = normalize(val_dataset[features], normalize_features, mean, std)[0].to_numpy()\n",
    "    # val_inputs = val_dataset[features].to_numpy()\n",
    "    val_labels = val_dataset[[predict]].to_numpy().squeeze().astype(np.int32)\n",
    "\n",
    "    clf = LogisticRegression(max_iter=2000, penalty=\"l1\", solver=\"liblinear\").fit(train_inputs, train_labels)\n",
    "    preds = clf.predict(val_inputs)\n",
    "    acc = accuracy_score(val_labels, preds)\n",
    "    f1 = f1_score(val_labels, preds, average='weighted')\n",
    "    prec = precision_score(val_labels, preds, average='weighted')\n",
    "    rec = recall_score(val_labels, preds, average='weighted')\n",
    "    roc = roc_auc_score(val_labels, preds, average='weighted')\n",
    "\n",
    "    print(f\"{hos} Acc: {acc}, f1-score: {f1}, Precision: {prec}, Recall: {rec}, ROC: {roc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vector_delirium",
   "language": "python",
   "name": "vector_delirium"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

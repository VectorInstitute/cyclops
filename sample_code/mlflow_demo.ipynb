{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bottom-there",
   "metadata": {},
   "source": [
    "### This notebook illustrates an example of viewing information from logged experiments on mlflow. It also shows how to load a model from and perform prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-poster",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-yield",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "import config.config as config\n",
    "import tasks.predict as predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-house",
   "metadata": {},
   "source": [
    "## Define functions to get model parameters and logged metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-atlantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters_list(data):\n",
    "    params  = data['params']\n",
    "    return [params['model'], params['dataset']]\n",
    "\n",
    "\n",
    "def get_metrics_list(data):\n",
    "    if ('metrics' in data.keys()) and data['metrics']:\n",
    "        metrics = data['metrics']\n",
    "        return [metrics['accuracy'], metrics['f1_score']]\n",
    "    else:\n",
    "        return ['-', '-']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-importance",
   "metadata": {},
   "source": [
    "## List all existing experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-diana",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_experiments = mlflow.list_experiments()\n",
    "exp_data = []\n",
    "for exp in all_experiments:\n",
    "    row = [exp.name, exp.artifact_location, exp.lifecycle_stage]\n",
    "    exp_data.append(row)\n",
    "exp_frame = pd.DataFrame(exp_data, columns = ['Name', 'Artifacts', 'Status'])\n",
    "print(exp_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-timing",
   "metadata": {},
   "source": [
    "## For model training experiment - display last 100 runs with a subset of parameters and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-recording",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp = mlflow.get_experiment_by_name('Default')\n",
    "runs = mlflow.list_run_infos(exp.experiment_id, max_results=100)\n",
    "data = []\n",
    "for r in runs:\n",
    "    run_data = mlflow.get_run(r.run_id).to_dictionary()['data']\n",
    "    row = get_parameters_list(run_data) + get_metrics_list(run_data)\n",
    "    data.append(row)\n",
    "frame = pd.DataFrame(data, columns=['Model', 'Dataset', 'Accuracy', 'F1 Score'])\n",
    "print('------------------- Model Training Runs ----------------------')\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-verification",
   "metadata": {},
   "source": [
    "## Show training metrics for the latest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-success",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "runs = mlflow.list_run_infos(exp.experiment_id, max_results=100)\n",
    "current = runs[0]\n",
    "losses = client.get_metric_history(current.run_id, 'epoch_loss')\n",
    "y = [l.value for l in losses]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "x = list(range(len(losses)))\n",
    "\n",
    "plt.plot(x, y, '-', linewidth=3)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-nature",
   "metadata": {},
   "source": [
    "## Load environment variable overrides and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-terrorism",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "cfg = config.read_config('../config/gemini.cfg')\n",
    "cfg.model_path = './model.pt'\n",
    "cfg.result_output = './temp_result.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-spine",
   "metadata": {},
   "source": [
    "## Run inference and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-landscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict.main(cfg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b2520a8-d4ad-4941-8ea7-71fdd631225f",
   "metadata": {},
   "source": [
    "# NIHCXR Clinical Drift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275fdb05",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8aa3302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cyclops.monitor import (\n",
    "    Detector,\n",
    "    Experimenter,\n",
    "    Reductor,\n",
    "    ClinicalShiftApplicator,\n",
    "    TSTester\n",
    ")\n",
    "from cyclops.datasets.slicing import SlicingConfig\n",
    "from cyclops.monitor.plotter import plot_drift_samples_pval\n",
    "from cyclops.monitor.utils import Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df16752",
   "metadata": {},
   "source": [
    "## Query Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77e7dccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset, Image\n",
    "import numpy as np\n",
    "\n",
    "from cyclops.monitor.utils import nihcxr_preprocess\n",
    "import PIL\n",
    "from torchxrayvision.models import DenseNet\n",
    "from monai.transforms import AddChanneld, Compose, Lambdad, Resized, ToDeviced, EnsureChannelFirstd\n",
    "from torchvision.transforms import PILToTensor\n",
    "import torch\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "from functools import partial\n",
    "from torchxrayvision.datasets import XRayCenterCrop, XRayResizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e7d1448",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c314eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Compose(\n",
    "    [\n",
    "        AddChanneld(keys=(\"features\",), allow_missing_keys=True),\n",
    "        Resized(keys=(\"features\",), spatial_size=(1, 224, 224), allow_missing_keys=True),\n",
    "        Lambdad(keys=(\"features\",), func=lambda x: ((2 * (x / 255.0)) - 1.0) * 1024, allow_missing_keys=True),\n",
    "        ToDeviced(keys=(\"features\",), device=device, allow_missing_keys=True),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "def apply_transforms(examples: Dict[str, List], transforms: callable) -> dict:\n",
    "    \"\"\"Apply transforms to examples.\"\"\"\n",
    "\n",
    "    # examples is a dict of lists; convert to list of dicts.\n",
    "    # doing a conversion from PIL to tensor is necessary here when working\n",
    "    # with the Image feature type.\n",
    "    value_len = len(list(examples.values())[0])\n",
    "    examples = [\n",
    "        {\n",
    "            k: PILToTensor()(v[i]) if isinstance(v[i], PIL.Image.Image) else v[i]\n",
    "            for k, v in examples.items()\n",
    "        }\n",
    "        for i in range(value_len)\n",
    "    ]\n",
    "\n",
    "    # apply the transforms to each example\n",
    "    examples = [transforms(example) for example in examples]\n",
    "\n",
    "    # convert back to a dict of lists\n",
    "    examples = {k: [d[k] for d in examples] for k in examples[0]}\n",
    "\n",
    "    return examples\n",
    "\n",
    "nihcxr_dir = \"/home/akore/NIHCXR\"\n",
    "df = pd.read_csv(os.path.join(nihcxr_dir, \"Data_Entry_2017.csv\"))\n",
    "df = nihcxr_preprocess(df, nihcxr_dir)\n",
    "nih_ds = Dataset.from_pandas(df, preserve_index=False)\n",
    "nih_ds = nih_ds.cast_column(\"features\", Image(decode=False))\n",
    "\n",
    "nih_ds = nih_ds.select(np.random.choice(nih_ds.shape[0], \n",
    "                                                     5000, replace=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcc72bb",
   "metadata": {},
   "source": [
    "## Split Source/Target Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "364418e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=6):   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter (num_proc=6):   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "source_slice = SlicingConfig(feature_values=[{\"Patient Gender\": {\"value\": \"M\"}}])\n",
    "target_slice = SlicingConfig(feature_values=[{\"Patient Gender\": {\"value\": \"F\"}}])\n",
    "shifter = ClinicalShiftApplicator(\"custom\", source=source_slice, target=target_slice)\n",
    "\n",
    "source_ds, target_ds = shifter.apply_shift(nih_ds, num_proc=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fec1db76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/2120 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_ds = target_ds.add_column(\"timestamp\", pd.date_range(\n",
    "    start=\"1/1/2019\", end=\"12/25/2019\", periods=target_ds.num_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35bc3eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ds = source_ds.with_transform(\n",
    "    partial(apply_transforms, transforms=transforms),\n",
    "    columns=[\"features\"],\n",
    "    output_all_columns=True\n",
    ")\n",
    "source_ds = source_ds.cast_column(\"features\", Image(decode=True))\n",
    "\n",
    "target_ds = target_ds.with_transform(\n",
    "    partial(apply_transforms, transforms=transforms),\n",
    "    columns=[\"features\"],\n",
    "    output_all_columns=True\n",
    ")\n",
    "target_ds = target_ds.cast_column(\"features\", Image(decode=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06f808d",
   "metadata": {},
   "source": [
    "## Initalize Detector (Reductor+Tester) and Run Sensitivity Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a3523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseNet(weights=\"densenet121-res224-all\")\n",
    "\n",
    "reductor = Reductor(\n",
    "    dr_method=\"bbse-soft\",\n",
    "    model=model,\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "tester = TSTester(\n",
    "    tester_method=\"mmd\",\n",
    ")\n",
    "\n",
    "detector = Detector(\n",
    "    \"balanced_sensitivity_test\",\n",
    "    reductor=reductor,\n",
    "    tester=tester,\n",
    "    device='cuda',\n",
    "    source_sample_size=100,\n",
    "    target_sample_size=[10, 50, 100],\n",
    "    num_runs=5\n",
    ")\n",
    "\n",
    "detector.detect_shift(source_ds, target_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe42397",
   "metadata": {},
   "source": [
    "## Initalize Detector (Reductor+Tester) and Run Rolling Window Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e4b383",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseNet(weights=\"densenet121-res224-all\")\n",
    "\n",
    "reductor = Reductor(\n",
    "    dr_method=\"bbse-soft\",\n",
    "    model=model,\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "tester = TSTester(\n",
    "    tester_method=\"mmd\",\n",
    ")\n",
    "\n",
    "detector = Detector(\n",
    "    \"rolling_window_drift\",\n",
    "    reductor=reductor,\n",
    "    tester=tester,\n",
    "    device='cuda',\n",
    "    source_sample_size=1000,\n",
    "    target_sample_size=50,\n",
    "    timestamp_column=\"timestamp\",\n",
    "    window_size=\"1M\"\n",
    ")\n",
    "\n",
    "detector.detect_shift(source_ds, target_ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "a3020bd91ee2a3fe37ba2e4a754058255d6b04fc00c4b4bebbda2c828f5bd9d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

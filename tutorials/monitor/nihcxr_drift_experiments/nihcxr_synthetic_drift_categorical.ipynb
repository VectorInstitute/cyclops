{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b2520a8-d4ad-4941-8ea7-71fdd631225f",
   "metadata": {},
   "source": [
    "# NIHCXR Synthetic Drift - Categorical Shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275fdb05",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa3302d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cyclops.monitor import (\n",
    "    Detector,\n",
    "    Experimenter,\n",
    "    Reductor,\n",
    "    SyntheticShiftApplicator,\n",
    "    TSTester,\n",
    ")\n",
    "from cyclops.monitor.plotter import plot_drift_samples_pval\n",
    "from cyclops.monitor.utils import Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df16752",
   "metadata": {},
   "source": [
    "## Query Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e7dccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import torch\n",
    "from datasets import Dataset, Image\n",
    "from monai.transforms import (\n",
    "    AddChanneld,\n",
    "    Compose,\n",
    "    EnsureChannelFirstd,\n",
    "    Lambdad,\n",
    "    Resized,\n",
    "    ToDeviced,\n",
    ")\n",
    "from torchvision.transforms import PILToTensor\n",
    "from torchxrayvision.datasets import XRayCenterCrop, XRayResizer\n",
    "from torchxrayvision.models import DenseNet\n",
    "\n",
    "from cyclops.monitor.utils import nihcxr_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7d1448",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c314eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Compose(\n",
    "    [\n",
    "        #         TorchVisiond(keys=(\"image\",), name=\"PILToTensor\"), doesn't work\n",
    "        AddChanneld(keys=(\"features\",), allow_missing_keys=True),\n",
    "        Resized(\n",
    "            keys=(\"features\",), spatial_size=(1, 224, 224), allow_missing_keys=True\n",
    "        ),\n",
    "        Lambdad(\n",
    "            keys=(\"features\",),\n",
    "            func=lambda x: ((2 * (x / 255.0)) - 1.0) * 1024,\n",
    "            allow_missing_keys=True,\n",
    "        ),\n",
    "        #         XRayCenterCrop(), XRayResizer(224, engine=\"cv2\"),\n",
    "        #         XRayResizer(224, engine=\"cv2\"),\n",
    "        ToDeviced(keys=(\"features\",), device=device, allow_missing_keys=True),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "def apply_transforms(examples: Dict[str, List], transforms: callable) -> dict:\n",
    "    \"\"\"Apply transforms to examples.\"\"\"\n",
    "\n",
    "    # examples is a dict of lists; convert to list of dicts.\n",
    "    # doing a conversion from PIL to tensor is necessary here when working\n",
    "    # with the Image feature type.\n",
    "    value_len = len(list(examples.values())[0])\n",
    "    examples = [\n",
    "        {\n",
    "            k: PILToTensor()(v[i]) if isinstance(v[i], PIL.Image.Image) else v[i]\n",
    "            for k, v in examples.items()\n",
    "        }\n",
    "        for i in range(value_len)\n",
    "    ]\n",
    "\n",
    "    # apply the transforms to each example\n",
    "    examples = [transforms(example) for example in examples]\n",
    "\n",
    "    # convert back to a dict of lists\n",
    "    examples = {k: [d[k] for d in examples] for k in examples[0]}\n",
    "\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec473d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "nihcxr_dir = \"/home/akore/NIHCXR\"\n",
    "df = pd.read_csv(os.path.join(nihcxr_dir, \"Data_Entry_2017.csv\"))\n",
    "df = nihcxr_preprocess(df, nihcxr_dir)\n",
    "nih_ds = Dataset.from_pandas(df, preserve_index=False)\n",
    "nih_ds = nih_ds.cast_column(\"features\", Image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662f38fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sample from huggingface arrow dataset\n",
    "nih_ds = nih_ds.select(np.random.choice(nih_ds.shape[0], 1000, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24502b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "nih_ds = nih_ds.with_transform(\n",
    "    partial(apply_transforms, transforms=transforms),\n",
    "    columns=[\"features\"],\n",
    "    output_all_columns=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f207456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get transforms used in nih_ds\n",
    "\n",
    "# tr = nih_ds.format['format_kwargs']['transform'].keywords['transforms'].transforms\n",
    "# comp.transforms += (EnsureChannelFirstd(keys=(\"image\",)),)\n",
    "# comp.transforms = comp.transforms[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6d321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseNet(weights=\"densenet121-res224-all\")\n",
    "reductor = Reductor(dr_method=\"bbse-soft\", model=model, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06f808d",
   "metadata": {},
   "source": [
    "## Initalize Reductor, Tester & Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40ab2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = reductor.transform(nih_ds, batch_size=32, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e350f886",
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = TSTester(\n",
    "    tester_method=\"mmd\",\n",
    ")\n",
    "\n",
    "detector = Detector(reductor=reductor, tester=tester, device=\"cuda\")\n",
    "\n",
    "detector.fit(nih_ds, batch_size=32, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9302e3",
   "metadata": {},
   "source": [
    "## Setup Baseline Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c6c946",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_experiment = Experimenter(\n",
    "    \"sensitivity_test\",\n",
    "    detector=detector,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40cf9e1",
   "metadata": {},
   "source": [
    "## Setup Drift Experiments (Categorical Shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce636179",
   "metadata": {},
   "outputs": [],
   "source": [
    "shiftapplicators = []\n",
    "shift_type = [\"categorical_shift\"] * 3\n",
    "cat_col = [\"gender\", \"view\", \"age\"]\n",
    "target_categories = [\"M\", \"PA\", \"18-35\"]\n",
    "\n",
    "for s_type, col, target in zip(shift_type, cat_col, target_categories):\n",
    "    shiftapplicators.append(\n",
    "        SyntheticShiftApplicator(\n",
    "            shift_type=s_type,\n",
    "            categorical_column=col,\n",
    "            target_category=target,\n",
    "        )\n",
    "    )\n",
    "\n",
    "experiments = []\n",
    "for shiftapplicator in shiftapplicators:\n",
    "    drift_experiment = Experimenter(\n",
    "        \"sensitivity_test\",\n",
    "        detector=detector,\n",
    "        shiftapplicator=shiftapplicator,\n",
    "    )\n",
    "    experiments.append(drift_experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3f38c1",
   "metadata": {},
   "source": [
    "## Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-supervisor",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = baseline_experiment.run(nih_ds)\n",
    "drift_results = []\n",
    "for experiment in experiments:\n",
    "    drift_results.append(experiment.run(nih_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e961b85c",
   "metadata": {},
   "source": [
    "## Gather Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee367e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "results_dict.update({\"baseline\": baseline_results})\n",
    "for itr, result in enumerate(drift_results):\n",
    "    results_dict.update({f\"{cat_col[itr]}: {target_categories[itr]}\": result})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03342cc7",
   "metadata": {},
   "source": [
    "## Plot Experimental Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f96bc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_drift_samples_pval(results_dict, 0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "a3020bd91ee2a3fe37ba2e4a754058255d6b04fc00c4b4bebbda2c828f5bd9d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

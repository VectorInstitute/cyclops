# Vector-Delirium

## Table of Contents
1. [Setup](#setup)
2. [Configuration Files](#config)
3. [Running as Pipeline](#pipeline)
4. [Pipeline Components](#components)
    * [Data Extraction](#data)
    * [Model Training](#training)
    * [Prediction](#prediction)
    * [Analysis](#analysis)
    * [Sample Notebooks](#notebooks)


## Setup: <a name="setup"></a>

To install prerequisites run:
`conda create --name <env> --file requirements.txt`

Add the following two environment variables to your profile in order to run full pipeline: 
```
export PGPASSWORD=<your-gemini-db-password>
export LUIGI_CONFIG_PATH="$HOME/vector-delirium/config/gemini_luigi.cfg"
export PYTHONPATH="${PYTHONPATH}:$HOME/vector-delirium/"
```

To do that edit .profile to add these three lines. The run it for changes to take effect:
`source .profile`

## Configuration Files: <a name="config"></a>
There is one configuration file config/gemini.cfg that contains all the parameters for individual tasks (data extraction, model training and prediction, analysis). The config parser is in config/config.py.

Refer to config/gemini.cfg for basic configuration parameters. (Additional one are described in config/config.py).  If extracting from the database, update your username in config file:
`username = <your-gemini-db-username>`

Luigi batch processing is used to run the whole flow (data extract, predict, analyze) as a pipeline. Luigi parameters are apecified in config/gemini_luigi.cfg

## Running as Pipeline: <a name="pipeline"></a>
Pipeline containing data extraction, prediction and analysis steps can be run by executing the following command:

To run the simulation, run:

`luigi --module pipeline_simulation Simulation --date-from 2018-01-01 --date-to 2020-06-01 --local-scheduler`

Simulation runs ML pipeline for each month in the specified interval (date-from to date-to)

To run pipeline once for specific time period, run:

`luigi --module pipeline Analysis --date-from 2018-08-01 --date-to 2018-10-01 --local-scheduler`

## Pipeline Tasks: <a name="components"></a>
In addition to Luigi pipeline, each of the components of the pipeline can be run on it's own from command line or from Jupyter notebook.
To run each task from the command line:
`python main.py --<action> <optional parameter overwrites>`

actions: extract, train, predict, analyze

### Data Extraction:  <a name="data"></a>
Examples of running data extraction from command line:
1) To extract all available records from the database and save to csv (or change parameters in the config/gemini.cfg):

`python main.py --extract -r -w --output_folder '../' --pop_size 0`

2) To extract 20,000 records, save to file, split into train, test and val sets by hospital_id column:

`python main.py --extract -r --pop_size 20000 -w --output_full_path='../temp.csv' --split_column hospital_id --test_split 3 --val_split 7 `

### Model Training:  <a name="training"></a>
To train a model:

`python main.py --train --input '../data.csv'`

### Prediction:  <a name="prediction"></a>
Run prediction:

`python main.py --predict --input '../sample.csv' --result_output '../result.csv'`

### Analysis:  <a name="analysis"></a>
To run dataset drift analysis, update config/gemini.cfg configuration with preferred options. Run:

`python main.py --analyze`

To run performance analysis (result files should be first generated by running prediction step):

`python main.py --analyze --type performance --reference '../ref_results.csv' --test '../test_results.csv`

## Sample Notebooks:  <a name="notebooks"></a>
MlFlow - TODO

Analysis - TODO

Training - TODO





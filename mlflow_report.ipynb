{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fiscal-enemy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "def get_parameters_list(data):\n",
    "    params  = data['params']\n",
    "    return [params['model'], params['dataset']]\n",
    "\n",
    "\n",
    "def get_metrics_list(data):\n",
    "    if ('metrics' in data.keys()) and data['metrics']:\n",
    "        metrics = data['metrics']\n",
    "        return [metrics['accuracy'], metrics['f1_score']]\n",
    "    else:\n",
    "        return ['-', '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "controversial-sarah",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Name                                          Artifacts  Status\n",
      "0  DatasetAnalysis  file:///mnt/nfs/home/koshkinam/vector-delirium...  active\n",
      "1          Default  file:///mnt/nfs/home/koshkinam/vector-delirium...  active\n",
      "2  ModelComparison  file:///mnt/nfs/home/koshkinam/vector-delirium...  active\n"
     ]
    }
   ],
   "source": [
    "# List all existing experiments\n",
    "all_experiments = mlflow.list_experiments()\n",
    "exp_data = []\n",
    "for exp in all_experiments:\n",
    "    row = [exp.name, exp.artifact_location, exp.lifecycle_stage]\n",
    "    exp_data.append(row)\n",
    "exp_frame = pd.DataFrame(exp_data, columns = ['Name', 'Artifacts', 'Status'])\n",
    "print(exp_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "sublime-fiber",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------- Model Training Runs ----------------------\n",
      "       Start time Model   Dataset  Accuracy  F1 Score\n",
      "0   1635434580535   mlp    gemini         -         -\n",
      "1   1634918781255   mlp    gemini   0.67013  0.282486\n",
      "2   1634915740928   mlp    gemini  0.728733  0.350343\n",
      "3   1634915064631   mlp    gemini  0.728415  0.349581\n",
      "4   1634914831011   mlp    gemini  0.728097   0.35129\n",
      "5   1634914772549   mlp    gemini         -         -\n",
      "6   1634850932565   mlp    gemini   0.69493       0.0\n",
      "7   1634850843801   mlp    gemini  0.667506       0.0\n",
      "8   1634850407660   mlp    gemini         -         -\n",
      "9   1634849799501   mlp    gemini         -         -\n",
      "10  1634849591931   mlp    gemini         -         -\n",
      "11  1634849438673   mlp    gemini         -         -\n",
      "12  1634849231167   mlp    gemini         -         -\n",
      "13  1634848865744   mlp    gemini         -         -\n",
      "14  1634848406375   mlp    gemini         -         -\n",
      "15  1634848303526   mlp    gemini         -         -\n",
      "16  1634848185530   mlp    gemini         -         -\n",
      "17  1634846942311   mlp  fakedata    0.9845  0.984224\n",
      "18  1634846203988   mlp  fakedata         -         -\n",
      "19  1634845741648   mlp  fakedata         -         -\n",
      "20  1634845692384   mlp  fakedata         -         -\n",
      "21  1634845502178   mlp  fakedata         -         -\n",
      "22  1634845017135   mlp  fakedata         -         -\n"
     ]
    }
   ],
   "source": [
    "# For model training experiment - display last 100 runs with a subset of parameters and metrics\n",
    "runs = mlflow.list_run_infos('0', max_results=100)\n",
    "data = []\n",
    "for r in runs:\n",
    "    run_data = mlflow.get_run(r.run_id).to_dictionary()['data']\n",
    "    row = [r.start_time] + get_parameters_list(run_data) + get_metrics_list(run_data)\n",
    "    data.append(row)\n",
    "frame = pd.DataFrame(data, columns=['Start time', 'Model', 'Dataset', 'Accuracy', 'F1 Score'])\n",
    "print('------------------- Model Training Runs ----------------------')\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-school",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MK Env",
   "language": "python",
   "name": "mkenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

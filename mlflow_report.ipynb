{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "piano-yield",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "def get_parameters_list(data):\n",
    "    params  = data['params']\n",
    "    return [params['model'], params['dataset']]\n",
    "\n",
    "\n",
    "def get_metrics_list(data):\n",
    "    if ('metrics' in data.keys()) and data['metrics']:\n",
    "        metrics = data['metrics']\n",
    "        return [metrics['accuracy'], metrics['f1_score']]\n",
    "    else:\n",
    "        return ['-', '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "manual-diana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Name                                          Artifacts  Status\n",
      "0  DatasetAnalysis  file:///mnt/nfs/home/koshkinam/vector-delirium...  active\n",
      "1          Default  file:///mnt/nfs/home/koshkinam/vector-delirium...  active\n",
      "2  ModelComparison  file:///mnt/nfs/home/koshkinam/vector-delirium...  active\n",
      "3       Prediction  file:///mnt/nfs/home/koshkinam/vector-delirium...  active\n"
     ]
    }
   ],
   "source": [
    "# List all existing experiments\n",
    "all_experiments = mlflow.list_experiments()\n",
    "exp_data = []\n",
    "for exp in all_experiments:\n",
    "    row = [exp.name, exp.artifact_location, exp.lifecycle_stage]\n",
    "    exp_data.append(row)\n",
    "exp_frame = pd.DataFrame(exp_data, columns = ['Name', 'Artifacts', 'Status'])\n",
    "print(exp_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "copyrighted-recording",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------- Model Training Runs ----------------------\n",
      "       Start time Model   Dataset  Accuracy  F1 Score\n",
      "0   1636470609315   mlp    gemini  0.678135  0.367164\n",
      "1   1636470486136   mlp    gemini         -         -\n",
      "2   1636469705972   mlp    gemini         -         -\n",
      "3   1636469214940   mlp    gemini         -         -\n",
      "4   1636418442900   mlp    gemini         -         -\n",
      "5   1636418378341   mlp    gemini         -         -\n",
      "6   1636418336218   mlp    gemini         -         -\n",
      "7   1636418191401   mlp    gemini         -         -\n",
      "8   1636417898437   mlp    gemini         -         -\n",
      "9   1636417627586   mlp    gemini         -         -\n",
      "10  1636416934942   mlp    gemini         -         -\n",
      "11  1635434580535   mlp    gemini         -         -\n",
      "12  1634918781255   mlp    gemini   0.67013  0.282486\n",
      "13  1634915740928   mlp    gemini  0.728733  0.350343\n",
      "14  1634915064631   mlp    gemini  0.728415  0.349581\n",
      "15  1634914831011   mlp    gemini  0.728097   0.35129\n",
      "16  1634914772549   mlp    gemini         -         -\n",
      "17  1634850932565   mlp    gemini   0.69493       0.0\n",
      "18  1634850843801   mlp    gemini  0.667506       0.0\n",
      "19  1634850407660   mlp    gemini         -         -\n",
      "20  1634849799501   mlp    gemini         -         -\n",
      "21  1634849591931   mlp    gemini         -         -\n",
      "22  1634849438673   mlp    gemini         -         -\n",
      "23  1634849231167   mlp    gemini         -         -\n",
      "24  1634848865744   mlp    gemini         -         -\n",
      "25  1634848406375   mlp    gemini         -         -\n",
      "26  1634848303526   mlp    gemini         -         -\n",
      "27  1634848185530   mlp    gemini         -         -\n",
      "28  1634846942311   mlp  fakedata    0.9845  0.984224\n",
      "29  1634846203988   mlp  fakedata         -         -\n",
      "30  1634845741648   mlp  fakedata         -         -\n",
      "31  1634845692384   mlp  fakedata         -         -\n",
      "32  1634845502178   mlp  fakedata         -         -\n",
      "33  1634845017135   mlp  fakedata         -         -\n"
     ]
    }
   ],
   "source": [
    "# For model training experiment - display last 100 runs with a subset of parameters and metrics\n",
    "runs = mlflow.list_run_infos('0', max_results=100)\n",
    "data = []\n",
    "for r in runs:\n",
    "    run_data = mlflow.get_run(r.run_id).to_dictionary()['data']\n",
    "    row = [r.start_time] + get_parameters_list(run_data) + get_metrics_list(run_data)\n",
    "    data.append(row)\n",
    "frame = pd.DataFrame(data, columns=['Start time', 'Model', 'Dataset', 'Accuracy', 'F1 Score'])\n",
    "print('------------------- Model Training Runs ----------------------')\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "political-hormone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------- Dataset Analysis ----------------------\n",
      "                                                Input Slice Ref Slice  \\\n",
      "0   /mnt/nfs/project/delirium/data/all_before_2018...  year    [2015]   \n",
      "1                                  ../gemini_data.csv  year    [2015]   \n",
      "2                                  ../gemini_data.csv  year    [2015]   \n",
      "3                                  ../gemini_data.csv  year    [2015]   \n",
      "4                                  ../gemini_data.csv  year    [2015]   \n",
      "5                                  ../gemini_data.csv  year    [2015]   \n",
      "6                                  ../gemini_data.csv  year    [2015]   \n",
      "7                                  ../gemini_data.csv  year    [2015]   \n",
      "8                                  ../gemini_data.csv  year    [2015]   \n",
      "9                                  ../gemini_data.csv  year    [2015]   \n",
      "10                                 ../gemini_data.csv  year    [2015]   \n",
      "11                                 ../gemini_data.csv  year    [2015]   \n",
      "\n",
      "   Eval Slice Drift  Feat Drift_Feat  \n",
      "0      [2016]    No  28.0        9.0  \n",
      "1      [2016]    No  29.0        3.0  \n",
      "2      [2016]    No  29.0        3.0  \n",
      "3      [2016]     -     -          -  \n",
      "4      [2016]     -     -          -  \n",
      "5      [2016]     -     -          -  \n",
      "6      [2016]     -     -          -  \n",
      "7      [2016]     -     -          -  \n",
      "8      [2016]     -     -          -  \n",
      "9      [2016]     -     -          -  \n",
      "10     [2016]     -     -          -  \n",
      "11     [2016]     -     -          -  \n"
     ]
    }
   ],
   "source": [
    "# Display dataset drift analysis runs\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "def get_dataset_metrics_list(data):\n",
    "     if ('metrics' in data.keys()) and data['metrics']:\n",
    "        metrics = data['metrics']\n",
    "        #timestamp = data['params']['timestamp']\n",
    "        drift = 'No' if metrics['dataset_drift']==0 else 'Yes'\n",
    "        return [drift, metrics['n_features'], metrics['n_drifted_features']]\n",
    "     else:\n",
    "        return ['-', '-', '-']\n",
    "\n",
    "exp = mlflow.get_experiment_by_name('DatasetAnalysis')\n",
    "runs = mlflow.list_run_infos(exp.experiment_id, max_results=100)\n",
    "table = []\n",
    "for r in runs:\n",
    "    exp_run = mlflow.get_run(r.run_id).to_dictionary()\n",
    "    path = exp_run['info']['artifact_uri'][6:]\n",
    "    config_file = os.path.join(path, 'config.json')\n",
    "    if not os.path.isfile(config_file):\n",
    "        continue\n",
    "    with open(config_file) as f:\n",
    "        data = json.load(f)\n",
    "        row = [data['input'], data['slice'], data['data_ref'], data['data_eval']]\n",
    "        row = row + get_dataset_metrics_list(exp_run['data'])\n",
    "        table.append(row)\n",
    "frame = pd.DataFrame(table, columns=['Input', 'Slice', 'Ref Slice', 'Eval Slice', 'Drift', 'Feat', 'Drift_Feat'])\n",
    "print('------------------- Dataset Analysis ----------------------')\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "labeled-theta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------- Model Peformance Comparison  ----------------------\n",
      "                  Reference                       Eval   Ref Acc  Eval Acc  \\\n",
      "0       ../results_2017.csv        ../results_2018.csv  0.679243  0.505018   \n",
      "1       ../results_2018.csv        ../results_2019.csv  0.665316   0.49462   \n",
      "2  ../gemini_val_result.csv  ../gemini_test_result.csv  0.683117  0.484435   \n",
      "3  ../gemini_val_result.csv  ../gemini_test_result.csv         -         -   \n",
      "4  ../gemini_val_result.csv  ../gemini_test_result.csv         -         -   \n",
      "5  ../gemini_val_result.csv  ../gemini_test_result.csv         -         -   \n",
      "6  ../gemini_val_result.csv  ../gemini_test_result.csv         -         -   \n",
      "\n",
      "  Ref F1 Score  Eval F1 Score  \n",
      "0     0.665316       0.494620  \n",
      "1     0.665316       0.494620  \n",
      "2     0.673246       0.468552  \n",
      "3            -            NaN  \n",
      "4            -            NaN  \n",
      "5            -            NaN  \n",
      "6            -            NaN  \n"
     ]
    }
   ],
   "source": [
    "# Display model comparison analysis runs\n",
    "\n",
    "def get_model_metrics_list(data):\n",
    "    if ('metrics' in data.keys()) and data['metrics']:\n",
    "        metrics = data['metrics']\n",
    "        return [metrics['ref_accuracy'], metrics['ref_f1'], metrics['test_accuracy'], metrics['test_f1']]\n",
    "    else:\n",
    "        return ['-', '-', '-']\n",
    "\n",
    "exp = mlflow.get_experiment_by_name('ModelComparison')\n",
    "runs = mlflow.list_run_infos(exp.experiment_id, max_results=100)\n",
    "table = []\n",
    "for r in runs:\n",
    "    exp_run = mlflow.get_run(r.run_id).to_dictionary()\n",
    "    path = exp_run['info']['artifact_uri'][6:]\n",
    "    config_file = os.path.join(path, 'config.json')\n",
    "    if not os.path.isfile(config_file):\n",
    "        continue\n",
    "    with open(config_file) as f:\n",
    "        data = json.load(f)\n",
    "        row = [data['reference'], data['test']]\n",
    "        row = row + get_model_metrics_list(exp_run['data'])\n",
    "        table.append(row)\n",
    "frame = pd.DataFrame(table, columns=['Reference', 'Eval', 'Ref Acc', 'Eval Acc', 'Ref F1 Score', 'Eval F1 Score'])\n",
    "print('------------------- Model Peformance Comparison  ----------------------')\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "animal-longer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'config_file': None, 'user': 'koshkinam', 'password': 'Masha1978', 'port': 5432, 'host': 'db.gemini-hpc.ca', 'database': 'delirium_v3_0_0', 'output': '/mnt/nfs/project/delirium/data/', 'w': False, 'r': False, 'input': '/mnt/nfs/project/delirium/data/all_before_2018.csv', 'features': ['hospital_id', 'sex', 'age', 'mort_hosp', 'readmission_7', 'readmission_28', 'palliative', 'los_er', 'icd10_A00_B99', 'icd10_C00_D49', 'icd10_D50_D89', 'icd10_E00_E89', 'icd10_F01_F99', 'icd10_G00_G99', 'icd10_H00_H59', 'icd10_H60_H95', 'icd10_I00_I99', 'icd10_J00_J99', 'icd10_K00_K95', 'icd10_L00_L99', 'icd10_M00_M99', 'icd10_N00_N99', 'icd10_O00_O99', 'icd10_Q00_Q99', 'icd10_R00_R99', 'icd10_S00_T88', 'icd10_U07_U08', 'icd10_Z00_Z99', 'icd10_nan'], 'target': ['los'], 'pop_size': 0, 'filter_year': 2018, 'filter_date_from': '', 'filter_date_to': '', 'split_column': 'year', 'test': '0', 'val': '2018', 'train': []}\n"
     ]
    }
   ],
   "source": [
    "import datapipeline.config as conf\n",
    "import process_data\n",
    "from datetime import datetime\n",
    "\n",
    "def setup(date_from, date_to):\n",
    "    config = conf.read_config('../delirium.conf')\n",
    "    config.w = True\n",
    "    config.r = True\n",
    "    config.input = None\n",
    "    config.output =  '/mnt/nfs/project/delirium/data/'\n",
    "    config.filter_date_from = datetime.strptime(date_from, '%Y%m%d')\n",
    "    config.filter_date_to = datetime.strptime(date_to, '%Y%m%d')\n",
    "    config.split_column = ''\n",
    "    return config\n",
    "\n",
    "config = setup('20170101', '20171231')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "temporal-cooler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://{config.user}:{config.password}@{config.host}:{config.port}/{config.database}\n",
      "  patient_id   genc_id hospital_id  sex  age  mort_hosp discharge_date_time  \\\n",
      "0             11142603         SMH    1   85          0 2017-05-12 12:00:00   \n",
      "1             11143029         SMH    1   66          0 2017-02-17 18:13:00   \n",
      "2             11152407         SMH    1   84          0 2017-06-23 19:22:00   \n",
      "3             11153607         SMH    0   30          0 2017-03-22 18:20:00   \n",
      "4             11179938         SMH    1   73          0 2017-06-12 18:15:00   \n",
      "\n",
      "      admit_date_time mr_diagnosis    year       los  readmission_7  \\\n",
      "0 2017-05-09 03:27:00         K922  2017.0  3.356250              0   \n",
      "1 2017-02-15 00:43:00         I500  2017.0  2.729167              0   \n",
      "2 2017-06-17 00:43:00         R296  2017.0  6.777083              0   \n",
      "3 2017-03-16 18:41:00         T658  2017.0  5.985417              0   \n",
      "4 2017-06-08 06:01:00         I633  2017.0  4.509722              0   \n",
      "\n",
      "   readmission_28  palliative     los_er admit_via_ambulance  \\\n",
      "0               1           0   5.583334                   G   \n",
      "1               0           0  10.616667                   N   \n",
      "2               0           0  14.516666                   N   \n",
      "3               0           0  14.866667                   G   \n",
      "4               0           0  19.933332                   G   \n",
      "\n",
      "   er_admit_date_time er_discharge_date_time triage_level  \n",
      "0 2017-05-08 23:40:00    2017-05-09 05:15:00            2  \n",
      "1 2017-02-14 20:56:00    2017-02-15 07:33:00            4  \n",
      "2 2017-06-16 13:37:00    2017-06-17 04:08:00            3  \n",
      "3 2017-03-16 10:34:00    2017-03-17 01:26:00            2  \n",
      "4 2017-06-07 22:53:00    2017-06-08 18:49:00            1  \n"
     ]
    }
   ],
   "source": [
    "_, fp = process_data.pipeline(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "blind-making",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/nfs/project/delirium/data/admin_data_2021-Nov-11_13-37-54.csv\n"
     ]
    }
   ],
   "source": [
    "print(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "universal-nirvana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'config_file': None, 'user': 'koshkinam', 'password': 'Masha1978', 'port': 5432, 'host': 'db.gemini-hpc.ca', 'database': 'delirium_v3_0_0', 'output': '../', 'w': False, 'r': False, 'input': '../gemini_data.csv', 'features': ['hospital_id', 'sex', 'age', 'mort_hosp', 'readmission_7', 'readmission_28', 'palliative', 'los_er', 'icd10_A00_B99', 'icd10_C00_D49', 'icd10_D50_D89', 'icd10_E00_E89', 'icd10_F01_F99', 'icd10_G00_G99', 'icd10_H00_H59', 'icd10_H60_H95', 'icd10_I00_I99', 'icd10_J00_J99', 'icd10_K00_K95', 'icd10_L00_L99', 'icd10_M00_M99', 'icd10_N00_N99', 'icd10_O00_O99', 'icd10_Q00_Q99', 'icd10_R00_R99', 'icd10_S00_T88', 'icd10_U07_U08', 'icd10_Z00_Z99', 'icd10_nan'], 'target': ['los'], 'pop_size': 10000, 'filter_year': 0, 'filter_date_from': '', 'filter_date_to': '', 'split_column': 'year', 'test': '2015', 'val': '2014', 'train': []}\n"
     ]
    }
   ],
   "source": [
    "import predict\n",
    "args = predict.prepare_args()\n",
    "args.input=fp\n",
    "args.output = '../results_2017.csv'\n",
    "\n",
    "predict.main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "average-typing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------- Prediction Runs ----------------------\n",
      "       Start time  Accuracy F1 Score\n",
      "0   1636655879972  0.686496  0.36008\n",
      "1   1636655675204         -        -\n",
      "2   1636655523155         -        -\n",
      "3   1636655509416  0.677172   0.3558\n",
      "4   1636654365228  0.677172   0.3558\n",
      "5   1636654076196  0.677172   0.3558\n",
      "6   1636653820861  0.677172   0.3558\n",
      "7   1636653059262  0.677172   0.3558\n",
      "8   1636652984160         -        -\n",
      "9   1636651461303  0.677172   0.3558\n",
      "10  1636651075742         -        -\n",
      "11  1636650882207         -        -\n",
      "12  1636650775411         -        -\n",
      "13  1636650651927         -        -\n",
      "14  1636650554974         -        -\n",
      "15  1636650361188         -        -\n",
      "16  1636650231133         -        -\n",
      "17  1636650186765         -        -\n",
      "18  1636650088458         -        -\n",
      "19  1636649892598         -        -\n",
      "20  1636649745337         -        -\n",
      "21  1636649737253         -        -\n",
      "22  1636649642056         -        -\n",
      "23  1636649346380         -        -\n",
      "24  1636647020902         -        -\n",
      "25  1636646951748         -        -\n",
      "26  1636646938638         -        -\n",
      "27  1636646864633         -        -\n",
      "28  1636494560523         -        -\n",
      "29  1636493688877         -        -\n",
      "30  1636493612253         -        -\n",
      "31  1636493594212         -        -\n",
      "32  1636493526146         -        -\n",
      "33  1636484073004         -        -\n",
      "34  1636483950940         -        -\n",
      "35  1636483888771         -        -\n",
      "36  1636483870972         -        -\n",
      "37  1636483813112         -        -\n"
     ]
    }
   ],
   "source": [
    "def get_parameters_list(data):\n",
    "    params  = data['params']\n",
    "    return [params['model'], params['dataset']]\n",
    "\n",
    "\n",
    "def get_metrics_list(data):\n",
    "    if ('metrics' in data.keys()) and data['metrics']:\n",
    "        metrics = data['metrics']\n",
    "        return [metrics['accuracy'], metrics['f1_score']]\n",
    "    else:\n",
    "        return ['-', '-']\n",
    "\n",
    "exp = mlflow.get_experiment_by_name('Prediction')\n",
    "runs = mlflow.list_run_infos(exp.experiment_id, max_results=100)\n",
    "data = []\n",
    "for r in runs:\n",
    "    run_data = mlflow.get_run(r.run_id).to_dictionary()['data']\n",
    "    row = [r.start_time] + get_metrics_list(run_data)\n",
    "    data.append(row)\n",
    "frame = pd.DataFrame(data, columns=['Start time', 'Accuracy', 'F1 Score'])\n",
    "print('------------------- Prediction Runs ----------------------')\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "joined-education",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'config_file': None, 'user': 'koshkinam', 'password': 'Masha1978', 'port': 5432, 'host': 'db.gemini-hpc.ca', 'database': 'delirium_v3_0_0', 'output': '/mnt/nfs/project/delirium/data/', 'w': False, 'r': False, 'input': '/mnt/nfs/project/delirium/data/all_before_2018.csv', 'features': ['hospital_id', 'sex', 'age', 'mort_hosp', 'readmission_7', 'readmission_28', 'palliative', 'los_er', 'icd10_A00_B99', 'icd10_C00_D49', 'icd10_D50_D89', 'icd10_E00_E89', 'icd10_F01_F99', 'icd10_G00_G99', 'icd10_H00_H59', 'icd10_H60_H95', 'icd10_I00_I99', 'icd10_J00_J99', 'icd10_K00_K95', 'icd10_L00_L99', 'icd10_M00_M99', 'icd10_N00_N99', 'icd10_O00_O99', 'icd10_Q00_Q99', 'icd10_R00_R99', 'icd10_S00_T88', 'icd10_U07_U08', 'icd10_Z00_Z99', 'icd10_nan'], 'target': ['los'], 'pop_size': 0, 'filter_year': 2018, 'filter_date_from': '', 'filter_date_to': '', 'split_column': 'year', 'test': '0', 'val': '2018', 'train': []}\n",
      "postgresql://{config.user}:{config.password}@{config.host}:{config.port}/{config.database}\n",
      "  patient_id   genc_id hospital_id  sex  age  mort_hosp discharge_date_time  \\\n",
      "0             11103215         SMH    0   52          0 2018-06-21 16:45:00   \n",
      "1             11112366         SMH    1   23          0 2018-10-02 19:48:00   \n",
      "2             11118568         SMH    0   56          0 2018-02-06 19:45:00   \n",
      "3             11163156         SMH    1   64          0 2018-10-16 12:55:00   \n",
      "4             11175072         SMH    0   44          0 2018-05-16 17:50:00   \n",
      "\n",
      "      admit_date_time mr_diagnosis    year       los  readmission_7  \\\n",
      "0 2018-06-19 02:26:00          C64  2018.0  2.596528              0   \n",
      "1 2018-09-29 19:24:00         R509  2018.0  3.016667              0   \n",
      "2 2018-01-30 15:39:00         I639  2018.0  7.170833              0   \n",
      "3 2018-10-13 20:27:00         A099  2018.0  2.686111              0   \n",
      "4 2018-05-13 20:50:00        L0311  2018.0  2.875000              0   \n",
      "\n",
      "   readmission_28  palliative     los_er admit_via_ambulance  \\\n",
      "0               0           0  13.700000                   N   \n",
      "1               0           0   7.050000                   N   \n",
      "2               0           0   6.916666                   N   \n",
      "3               0           0   9.900000                   N   \n",
      "4               0           0   9.366667                   N   \n",
      "\n",
      "   er_admit_date_time er_discharge_date_time triage_level  \n",
      "0 2018-06-18 16:42:00    2018-06-19 06:24:00            3  \n",
      "1 2018-09-29 14:47:00    2018-09-29 21:50:00            2  \n",
      "2 2018-01-30 11:10:00    2018-01-30 18:05:00            2  \n",
      "3 2018-10-13 12:39:00    2018-10-13 22:33:00            2  \n",
      "4 2018-05-13 17:26:00    2018-05-14 02:48:00            4  \n",
      "{'config_file': None, 'user': 'koshkinam', 'password': 'Masha1978', 'port': 5432, 'host': 'db.gemini-hpc.ca', 'database': 'delirium_v3_0_0', 'output': '../', 'w': False, 'r': False, 'input': '../gemini_data.csv', 'features': ['hospital_id', 'sex', 'age', 'mort_hosp', 'readmission_7', 'readmission_28', 'palliative', 'los_er', 'icd10_A00_B99', 'icd10_C00_D49', 'icd10_D50_D89', 'icd10_E00_E89', 'icd10_F01_F99', 'icd10_G00_G99', 'icd10_H00_H59', 'icd10_H60_H95', 'icd10_I00_I99', 'icd10_J00_J99', 'icd10_K00_K95', 'icd10_L00_L99', 'icd10_M00_M99', 'icd10_N00_N99', 'icd10_O00_O99', 'icd10_Q00_Q99', 'icd10_R00_R99', 'icd10_S00_T88', 'icd10_U07_U08', 'icd10_Z00_Z99', 'icd10_nan'], 'target': ['los'], 'pop_size': 10000, 'filter_year': 0, 'filter_date_from': '', 'filter_date_to': '', 'split_column': 'year', 'test': '2015', 'val': '2014', 'train': []}\n"
     ]
    }
   ],
   "source": [
    "config = setup('20180101', '20181231')\n",
    "_, fp = process_data.pipeline(config)\n",
    "args = predict.prepare_args()\n",
    "args.input=fp\n",
    "args.output = '../results_2018.csv'\n",
    "\n",
    "predict.main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "floppy-performer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import analysis\n",
    "report_config = analysis.read_config()\n",
    "report_config.type = 'performance'\n",
    "report_config.reference = '../results_2017.csv'\n",
    "report_config.test = '../results_2018.csv'\n",
    "analysis.main(report_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "experimental-scholar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['age', 'los_er', 'hospital_id', 'sex', 'mort_hosp', 'readmission_7', 'readmission_28', 'palliative', 'icd10_A00_B99', 'icd10_C00_D49', 'icd10_D50_D89', 'icd10_E00_E89', 'icd10_F01_F99', 'icd10_G00_G99', 'icd10_H00_H59', 'icd10_H60_H95', 'icd10_I00_I99', 'icd10_J00_J99', 'icd10_K00_K95', 'icd10_L00_L99', 'icd10_M00_M99', 'icd10_N00_N99', 'icd10_O00_O99', 'icd10_Q00_Q99', 'icd10_R00_R99', 'icd10_S00_T88', 'icd10_Z00_Z99', 'los', 'n_features', 'n_drifted_features', 'share_drifted_features', 'dataset_drift'])\n"
     ]
    }
   ],
   "source": [
    "report_config = analysis.read_config()\n",
    "report_config.type = 'dataset'\n",
    "report_config.input = '/mnt/nfs/project/delirium/data/all_before_2018.csv'\n",
    "data_eval=[2018]\n",
    "data_ref=[2017]\n",
    "analysis.main(report_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-apollo",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MK Env",
   "language": "python",
   "name": "mkenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2deeb4f4-93a0-4f77-b652-b7cc68199411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 76;\n",
       "                var nbb_unformatted_code = \"import sys\\nimport random\\nimport pandas as pd\\nimport numpy as np\\nfrom temporal_model_utils import *\\nimport torch.nn as nn\\nimport torch.optim as optim\\nfrom optimizer import Optimizer\\nfrom sklearn.model_selection import train_test_split\\nimport matplotlib as mpl\\nimport matplotlib.pyplot as plt\\n\\nsys.path.append(\\\"../../../..\\\")\\nfrom cyclops.feature_handler import FeatureHandler\\n\\n%load_ext autoreload\\n%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"import sys\\nimport random\\nimport pandas as pd\\nimport numpy as np\\nfrom temporal_model_utils import *\\nimport torch.nn as nn\\nimport torch.optim as optim\\nfrom optimizer import Optimizer\\nfrom sklearn.model_selection import train_test_split\\nimport matplotlib as mpl\\nimport matplotlib.pyplot as plt\\n\\nsys.path.append(\\\"../../../..\\\")\\nfrom cyclops.feature_handler import FeatureHandler\\n\\n%load_ext autoreload\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from temporal_model_utils import *\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from optimizer import Optimizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"../../../..\")\n",
    "from cyclops.feature_handler import FeatureHandler\n",
    "\n",
    "%load_ext autoreload\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c93c5382-6901-4af1-828f-d831dd0a7c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-01 02:28:45,749 \u001b[1;37mINFO\u001b[0m cyclops.feature_handler - Loading features from file...\n",
      "2022-06-01 02:28:45,751 \u001b[1;37mINFO\u001b[0m cyclops.feature_handler - Found file to load for static features...\n",
      "2022-06-01 02:28:45,751 \u001b[1;37mINFO\u001b[0m cyclops.feature_handler - Successfully loaded static features from file...\n",
      "2022-06-01 02:28:45,806 \u001b[1;37mINFO\u001b[0m cyclops.feature_handler - Found file to load for temporal features...\n",
      "2022-06-01 02:28:45,935 \u001b[1;37mINFO\u001b[0m cyclops.feature_handler - Successfully loaded temporal features from file...\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 77;\n",
       "                var nbb_unformatted_code = \"DIR=\\\"/mnt/nfs/project/delirium/drift_exp/MAY-31-2022/\\\"\\nfeature_handler = FeatureHandler()\\nfeature_handler.load(DIR, \\\"test_features\\\")\";\n",
       "                var nbb_formatted_code = \"DIR = \\\"/mnt/nfs/project/delirium/drift_exp/MAY-31-2022/\\\"\\nfeature_handler = FeatureHandler()\\nfeature_handler.load(DIR, \\\"test_features\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DIR=\"/mnt/nfs/project/delirium/drift_exp/MAY-31-2022/\"\n",
    "feature_handler = FeatureHandler()\n",
    "feature_handler.load(DIR, \"test_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "93471285-8ee3-48ed-8021-574cb76dfc16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encounter_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11100097</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11100164</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11100176</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11100375</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11100461</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999304</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999522</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999628</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999635</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999666</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5064 rows × 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [11100097, 11100164, 11100176, 11100375, 11100461, 11100746, 11100782, 11100856, 11101148, 11101350, 11101419, 11102127, 11102386, 11102646, 11102667, 11103117, 11103285, 11103407, 11103415, 11103510, 11103570, 11103722, 11103856, 11104052, 11104116, 11104525, 11104582, 11104623, 11104720, 11104741, 11104985, 11105119, 11105390, 11105701, 11106263, 11106403, 11106436, 11106653, 11106673, 11107168, 11107663, 11107683, 11107746, 11107884, 11108013, 11108331, 11108560, 11108611, 11109081, 11109343, 11109418, 11109489, 11109676, 11109889, 11109896, 11109929, 11109990, 11110028, 11110414, 11110684, 11110794, 11110820, 11110861, 11111412, 11111462, 11111747, 11112142, 11112483, 11112932, 11113068, 11113218, 11113241, 11113366, 11113383, 11113650, 11113802, 11113913, 11114219, 11114264, 11114276, 11114588, 11114851, 11115012, 11115072, 11115104, 11115579, 11115627, 11115855, 11115921, 11115994, 11116053, 11116196, 11116504, 11117030, 11117205, 11117366, 11117386, 11117413, 11117476, 11117709, ...]\n",
       "\n",
       "[5064 rows x 0 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 78;\n",
       "                var nbb_unformatted_code = \"ref_static = feature_handler.reference['static']\\nref_static\";\n",
       "                var nbb_formatted_code = \"ref_static = feature_handler.reference[\\\"static\\\"]\\nref_static\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ref_static = feature_handler.reference['static']\n",
    "ref_static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "12066550-01d2-4869-a96b-2ab9c37171ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encounters: 5064\n",
      "Static Features: 25\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 79;\n",
       "                var nbb_unformatted_code = \"static = feature_handler.features['static']\\nprint(\\\"Encounters:\\\",static.shape[0])\\nprint(\\\"Static Features:\\\",static.shape[1])\";\n",
       "                var nbb_formatted_code = \"static = feature_handler.features[\\\"static\\\"]\\nprint(\\\"Encounters:\\\", static.shape[0])\\nprint(\\\"Static Features:\\\", static.shape[1])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "static = feature_handler.features['static']\n",
    "print(\"Encounters:\",static.shape[0])\n",
    "print(\"Static Features:\",static.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fec963d0-2cf6-4f18-b90e-cc6f7ff0f104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A00_B99</th>\n",
       "      <th>C00_D49</th>\n",
       "      <th>D50_D89</th>\n",
       "      <th>E00_E89</th>\n",
       "      <th>F01_F99</th>\n",
       "      <th>G00_G99</th>\n",
       "      <th>H00_H59</th>\n",
       "      <th>H60_H95</th>\n",
       "      <th>I00_I99</th>\n",
       "      <th>J00_J99</th>\n",
       "      <th>...</th>\n",
       "      <th>P00_P96</th>\n",
       "      <th>Q00_Q99</th>\n",
       "      <th>R00_R99</th>\n",
       "      <th>S00_T88</th>\n",
       "      <th>V00_Y99</th>\n",
       "      <th>Z00_Z99</th>\n",
       "      <th>length_of_stay_in_er</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>mortality</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encounter_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11100097</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.816668</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11100164</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.650000</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11100176</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.350000</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11100375</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.366667</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11100461</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.733334</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999304</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.400000</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999522</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.716667</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999628</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.583333</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999635</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.116667</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999666</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.400000</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5064 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              A00_B99  C00_D49  D50_D89  E00_E89  F01_F99  G00_G99  H00_H59  \\\n",
       "encounter_id                                                                  \n",
       "11100097            0        0        0        0        0        0        0   \n",
       "11100164            0        0        0        0        0        1        0   \n",
       "11100176            0        0        0        1        1        0        0   \n",
       "11100375            0        0        0        1        0        0        0   \n",
       "11100461            0        0        0        0        0        0        0   \n",
       "...               ...      ...      ...      ...      ...      ...      ...   \n",
       "11999304            1        0        0        0        0        0        0   \n",
       "11999522            0        0        0        0        0        0        0   \n",
       "11999628            0        1        0        0        1        0        0   \n",
       "11999635            0        0        1        1        0        0        0   \n",
       "11999666            1        0        0        0        0        0        0   \n",
       "\n",
       "              H60_H95  I00_I99  J00_J99  ...  P00_P96  Q00_Q99  R00_R99  \\\n",
       "encounter_id                             ...                              \n",
       "11100097            0        0        0  ...        0        0        0   \n",
       "11100164            0        1        0  ...        0        0        0   \n",
       "11100176            0        1        1  ...        0        0        1   \n",
       "11100375            0        1        0  ...        0        0        0   \n",
       "11100461            0        1        0  ...        0        0        0   \n",
       "...               ...      ...      ...  ...      ...      ...      ...   \n",
       "11999304            0        0        0  ...        0        0        0   \n",
       "11999522            0        1        1  ...        0        0        0   \n",
       "11999628            0        1        0  ...        0        0        1   \n",
       "11999635            0        0        0  ...        0        0        1   \n",
       "11999666            0        0        0  ...        0        0        0   \n",
       "\n",
       "              S00_T88  V00_Y99  Z00_Z99  length_of_stay_in_er  age  sex  \\\n",
       "encounter_id                                                              \n",
       "11100097            0        0        0             16.816668   65    1   \n",
       "11100164            1        1        1              3.650000   59    1   \n",
       "11100176            0        0        0              8.350000   63    1   \n",
       "11100375            0        1        0             13.366667   28    1   \n",
       "11100461            0        0        0             12.733334   60    1   \n",
       "...               ...      ...      ...                   ...  ...  ...   \n",
       "11999304            0        0        0             16.400000   37    1   \n",
       "11999522            1        1        1             24.716667   84    0   \n",
       "11999628            0        0        1             13.583333   92    0   \n",
       "11999635            0        0        1             25.116667   75    0   \n",
       "11999666            0        0        0             24.400000   70    1   \n",
       "\n",
       "              mortality  \n",
       "encounter_id             \n",
       "11100097              0  \n",
       "11100164              0  \n",
       "11100176              0  \n",
       "11100375              0  \n",
       "11100461              0  \n",
       "...                 ...  \n",
       "11999304              0  \n",
       "11999522              1  \n",
       "11999628              1  \n",
       "11999635              0  \n",
       "11999666              0  \n",
       "\n",
       "[5064 rows x 25 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 80;\n",
       "                var nbb_unformatted_code = \"static\";\n",
       "                var nbb_formatted_code = \"static\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0762c68f-d914-4c6b-8061-036b4bc2fb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "static['mortality'] = np.where(\n",
    "        static[\"discharge_disposition\"].isin([7, 66, 72, 73]), 1, 0\n",
    "    )\n",
    "\n",
    "m1 = (static['length_of_stay_in_er']>=0) & (static['length_of_stay_in_er']<7)\n",
    "m2 = (static['length_of_stay_in_er']>=7) & (static['length_of_stay_in_er']<14)\n",
    "m3 = (static['length_of_stay_in_er']>=14) & (static['length_of_stay_in_er']<30)\n",
    "\n",
    "vals = [1, 2, 3]\n",
    "default = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "52579432-ad0a-4564-9cad-bb0690b19bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 363;\n",
       "                var nbb_unformatted_code = \"fig, ax = plt.subplots(figsize=(14, 4))\\nplt.hist(static[\\\"mortality\\\"], bins=2, alpha=0.5, width=0.5, label=\\\"mortality\\\")\\nfig.legend(loc=\\\"upper right\\\")\\nplt.show()\";\n",
       "                var nbb_formatted_code = \"fig, ax = plt.subplots(figsize=(14, 4))\\nplt.hist(static[\\\"mortality\\\"], bins=2, alpha=0.5, width=0.5, label=\\\"mortality\\\")\\nfig.legend(loc=\\\"upper right\\\")\\nplt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 4))\n",
    "plt.hist(static[\"mortality\"], bins=2, alpha=0.5, width=0.5, label=\"mortality\")\n",
    "fig.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f8a26261-06a0-4659-85a7-3362bb636213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encounter_id</th>\n",
       "      <th>timestep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">11100097</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">11917974</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36904 rows × 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [(11100097, 0), (11100097, 1), (11100097, 2), (11100097, 3), (11100097, 4), (11100097, 5), (11100097, 6), (11100097, 7), (11100164, 0), (11100164, 1), (11100164, 2), (11100164, 3), (11100164, 4), (11100164, 5), (11100164, 6), (11100164, 7), (11100176, 0), (11100176, 1), (11100176, 2), (11100176, 3), (11100176, 4), (11100176, 5), (11100176, 6), (11100176, 7), (11100375, 0), (11100375, 1), (11100375, 2), (11100375, 3), (11100375, 4), (11100375, 5), (11100375, 6), (11100375, 7), (11100461, 0), (11100461, 1), (11100461, 2), (11100461, 3), (11100461, 4), (11100461, 5), (11100461, 6), (11100461, 7), (11100746, 0), (11100746, 1), (11100746, 2), (11100746, 3), (11100746, 4), (11100746, 5), (11100746, 6), (11100746, 7), (11100782, 0), (11100782, 1), (11100782, 2), (11100782, 3), (11100782, 4), (11100782, 5), (11100782, 6), (11100782, 7), (11100856, 0), (11100856, 1), (11100856, 2), (11100856, 3), (11100856, 4), (11100856, 5), (11100856, 6), (11100856, 7), (11101148, 0), (11101148, 1), (11101148, 2), (11101148, 3), (11101148, 4), (11101148, 5), (11101148, 6), (11101148, 7), (11101350, 0), (11101350, 1), (11101350, 2), (11101350, 3), (11101350, 4), (11101350, 5), (11101350, 6), (11101350, 7), (11101419, 0), (11101419, 1), (11101419, 2), (11101419, 3), (11101419, 4), (11101419, 5), (11101419, 6), (11101419, 7), (11102127, 0), (11102127, 1), (11102127, 2), (11102127, 3), (11102127, 4), (11102127, 5), (11102127, 6), (11102127, 7), (11102386, 0), (11102386, 1), (11102386, 2), (11102386, 3), ...]\n",
       "\n",
       "[36904 rows x 0 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 83;\n",
       "                var nbb_unformatted_code = \"ref_temporal = feature_handler.reference['temporal']\\nref_temporal\";\n",
       "                var nbb_formatted_code = \"ref_temporal = feature_handler.reference[\\\"temporal\\\"]\\nref_temporal\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ref_temporal = feature_handler.reference['temporal']\n",
    "ref_temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d0128912-139c-4cef-9e86-cd787d9fc85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encounters: 4613\n",
      "Timesteps: 8\n",
      "Temporal Features: 12\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 84;\n",
       "                var nbb_unformatted_code = \"temporal = feature_handler.features['temporal']\\nsamples=len(temporal.index.unique(level=0))\\ntimesteps=len(temporal.index.unique(level=1))\\nfeatures=temporal.shape[1]\\nprint(\\\"Encounters:\\\",samples)\\nprint(\\\"Timesteps:\\\",timesteps)\\nprint(\\\"Temporal Features:\\\",features)\";\n",
       "                var nbb_formatted_code = \"temporal = feature_handler.features[\\\"temporal\\\"]\\nsamples = len(temporal.index.unique(level=0))\\ntimesteps = len(temporal.index.unique(level=1))\\nfeatures = temporal.shape[1]\\nprint(\\\"Encounters:\\\", samples)\\nprint(\\\"Timesteps:\\\", timesteps)\\nprint(\\\"Temporal Features:\\\", features)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temporal = feature_handler.features['temporal']\n",
    "samples=len(temporal.index.unique(level=0))\n",
    "timesteps=len(temporal.index.unique(level=1))\n",
    "features=temporal.shape[1]\n",
    "print(\"Encounters:\",samples)\n",
    "print(\"Timesteps:\",timesteps)\n",
    "print(\"Temporal Features:\",features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "deb9b875-8343-4557-aee3-83f0f28e303c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>bicarbonate</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>hematocrit</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>lymphocyte</th>\n",
       "      <th>mean cell volume</th>\n",
       "      <th>neutrophils</th>\n",
       "      <th>platelet count</th>\n",
       "      <th>potassium</th>\n",
       "      <th>sodium</th>\n",
       "      <th>white blood cell count</th>\n",
       "      <th>oxygen_delivery</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encounter_id</th>\n",
       "      <th>timestep</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">11100097</th>\n",
       "      <th>0</th>\n",
       "      <td>21.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.467</td>\n",
       "      <td>152.0</td>\n",
       "      <td>1.97</td>\n",
       "      <td>98.7</td>\n",
       "      <td>12.31</td>\n",
       "      <td>305.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>128.0</td>\n",
       "      <td>15.74</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.446</td>\n",
       "      <td>141.0</td>\n",
       "      <td>1.29</td>\n",
       "      <td>100.7</td>\n",
       "      <td>7.35</td>\n",
       "      <td>244.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>133.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">11917974</th>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36904 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "features               bicarbonate  creatinine  hematocrit  hemoglobin  \\\n",
       "encounter_id timestep                                                    \n",
       "11100097     0                21.0        46.0       0.467       152.0   \n",
       "             1                 NaN         NaN         NaN         NaN   \n",
       "             2                25.0        39.0       0.446       141.0   \n",
       "             3                 NaN         NaN         NaN         NaN   \n",
       "             4                 NaN         NaN         NaN         NaN   \n",
       "...                            ...         ...         ...         ...   \n",
       "11917974     3                 NaN         NaN         NaN         NaN   \n",
       "             4                 NaN         NaN         NaN         NaN   \n",
       "             5                 NaN         NaN         NaN         NaN   \n",
       "             6                 NaN         NaN         NaN         NaN   \n",
       "             7                 NaN         NaN         NaN         NaN   \n",
       "\n",
       "features               lymphocyte  mean cell volume  neutrophils  \\\n",
       "encounter_id timestep                                              \n",
       "11100097     0               1.97              98.7        12.31   \n",
       "             1                NaN               NaN          NaN   \n",
       "             2               1.29             100.7         7.35   \n",
       "             3                NaN               NaN          NaN   \n",
       "             4                NaN               NaN          NaN   \n",
       "...                           ...               ...          ...   \n",
       "11917974     3                NaN               NaN          NaN   \n",
       "             4                NaN               NaN          NaN   \n",
       "             5                NaN               NaN          NaN   \n",
       "             6                NaN               NaN          NaN   \n",
       "             7                NaN               NaN          NaN   \n",
       "\n",
       "features               platelet count  potassium  sodium  \\\n",
       "encounter_id timestep                                      \n",
       "11100097     0                  305.0        5.5   128.0   \n",
       "             1                    NaN        NaN     NaN   \n",
       "             2                  244.0        4.2   133.0   \n",
       "             3                    NaN        NaN     NaN   \n",
       "             4                    NaN        NaN     NaN   \n",
       "...                               ...        ...     ...   \n",
       "11917974     3                    NaN        NaN     NaN   \n",
       "             4                    NaN        NaN     NaN   \n",
       "             5                    NaN        NaN     NaN   \n",
       "             6                    NaN        NaN     NaN   \n",
       "             7                    NaN        NaN     NaN   \n",
       "\n",
       "features               white blood cell count  oxygen_delivery  \n",
       "encounter_id timestep                                           \n",
       "11100097     0                          15.74              NaN  \n",
       "             1                            NaN              NaN  \n",
       "             2                           9.69              NaN  \n",
       "             3                            NaN              NaN  \n",
       "             4                            NaN              NaN  \n",
       "...                                       ...              ...  \n",
       "11917974     3                            NaN              1.0  \n",
       "             4                            NaN              1.0  \n",
       "             5                            NaN              1.0  \n",
       "             6                            NaN              1.0  \n",
       "             7                            NaN              1.0  \n",
       "\n",
       "[36904 rows x 12 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 85;\n",
       "                var nbb_unformatted_code = \"temporal = temporal.rename_axis(\\\"features\\\", axis=\\\"columns\\\")\\ntemporal\";\n",
       "                var nbb_formatted_code = \"temporal = temporal.rename_axis(\\\"features\\\", axis=\\\"columns\\\")\\ntemporal\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temporal = temporal.rename_axis(\"features\", axis=\"columns\")\n",
    "temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4eec4276-3cd3-4742-8eb1-9ce11902c5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 86;\n",
       "                var nbb_unformatted_code = \"import datetime\\nimport numpy as np\\nimport matplotlib.pyplot as plt \\nimport torch\\nfrom datetime import datetime\\n\\nclass Optimizer:\\n    \\\"\\\"\\\"Optimizer Class.\\n\\n    Attributes\\n    ----------\\n    model: torch.nn.Module\\n        Pytorch model to optimize (e.g. RNNModel, LSTMModel, GRUModel)\\n    loss_fn: function\\n        Loss function \\n    optimizer: torch.optim\\n        Optimization algorithm (e.g. Adam)\\n\\n    \\\"\\\"\\\"\\n    def __init__(self, model, loss_fn, optimizer,activation):\\n        self.model = model\\n        self.loss_fn = loss_fn\\n        self.optimizer = optimizer\\n        self.activation = activation\\n        self.train_losses = []\\n        self.val_losses = []\\n        self.device = model.device\\n    \\n    def train_step(self, x, y):\\n        # Sets model to train mode\\n        self.model.train(True)\\n\\n        # Makes predictions\\n        yhat = self.model(x)\\n        \\n        # Computes loss\\n        loss = self.loss_fn(y, yhat)\\n\\n        # Computes gradients\\n        loss.backward()\\n\\n        #self.model.float()\\n        # Updates parameters and zeroes gradients\\n        self.optimizer.step()\\n        self.optimizer.zero_grad()\\n\\n        # Returns the loss\\n        return loss.item()\\n\\n    def train(self, train_loader, val_loader, batch_size=64, n_epochs=50, n_features=1):  \\n        \\\"\\\"\\\"Train pytorch model.\\n\\n        Parameters\\n        ----------\\n        train_loader: DataLoader\\n            Dataset object containing training set.\\n        val_loader: DataLoader\\n            Dataset object containing validation set.\\n        batch_size: int\\n            Number of samples to train before updating model parameters.\\n        n_epochs: int\\n            Number of complete passes through the training set.\\n        n_features: int \\n            Number of features.\\n\\n        \\\"\\\"\\\" \\n        model_path = f'{self.model}_{datetime.now().strftime(\\\"%Y-%m-%d %H:%M:%S\\\")}'\\n\\n        for epoch in range(1, n_epochs + 1):\\n            batch_losses = []\\n            for x_batch, y_batch in train_loader:\\n                x_batch = x_batch.view([batch_size, -1, n_features]).to(self.device)\\n                y_batch = y_batch.to(self.device)\\n                loss = self.train_step(x_batch, y_batch)\\n                batch_losses.append(loss)\\n            training_loss = np.mean(batch_losses)\\n            self.train_losses.append(training_loss)\\n\\n            with torch.no_grad():\\n                batch_val_losses = []\\n                for x_val, y_val in val_loader:\\n                    x_val = x_val.view([batch_size, -1, n_features]).to(self.device)\\n                    y_val = y_val.to(self.device)\\n                    self.model.eval()\\n                    yhat = self.model(x_val)\\n                    val_loss = self.loss_fn(y_val, yhat).item()\\n                    batch_val_losses.append(val_loss)\\n                validation_loss = np.mean(batch_val_losses)\\n                self.val_losses.append(validation_loss)\\n\\n            if (epoch <= 10) | (epoch % 50 == 0):\\n                print(\\n                    f\\\"[{epoch}/{n_epochs}] Training loss: {training_loss:.4f}\\\\t Validation loss: {validation_loss:.4f}\\\"\\n                )\\n\\n        torch.save(self.model.state_dict(), model_path)\\n\\n    def evaluate(self, test_loader, batch_size=1, n_features=1):\\n        \\\"\\\"\\\"Evaluate pytorch model.\\n\\n        Parameters\\n        ----------\\n        test_loader: DataLoader\\n            Dataset object containing test set.\\n        batch_size: int\\n            Number of samples to evaluate at a time.\\n\\n        \\\"\\\"\\\"\\n        with torch.no_grad():\\n            predictions = []\\n            values = []\\n            tags = []\\n            acc = 0\\n            for x_test, y_test in test_loader:\\n                x_test = x_test.view([batch_size, -1, n_features]).to(self.device)\\n                y_test = y_test.to(self.device)\\n                self.model.eval()\\n                yhat = self.model(x_test)\\n                ## if binary apply sigmoid, if class apply softmax\\n                y_pred_tags = torch.round(self.activation(yhat)).cpu().detach().numpy()\\n                acc += self.binary_acc(yhat, y_test)\\n                predictions.append(yhat.cpu().detach().numpy())\\n                values.append(y_test.cpu().detach().numpy())\\n                tags.append(y_pred_tags)\\n            print('Accuracy: {} %'.format(acc)) \\n            \\n        return predictions, values, tags\\n    \\n    def binary_acc(self,y_pred, y_test):\\n        y_pred_tag = torch.round(torch.sigmoid(y_pred))\\n\\n        correct_results_sum = (y_pred_tag == y_test).sum().float()\\n        acc = correct_results_sum/y_test.shape[0]\\n        return acc\\n    \\n    def plot_losses(self):\\n        plt.plot(self.train_losses, label=\\\"Training loss\\\")\\n        plt.plot(self.val_losses, label=\\\"Validation loss\\\")\\n        plt.legend()\\n        plt.title(\\\"Losses\\\")\\n        plt.show()\\n        plt.close()\";\n",
       "                var nbb_formatted_code = \"import datetime\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport torch\\nfrom datetime import datetime\\n\\n\\nclass Optimizer:\\n    \\\"\\\"\\\"Optimizer Class.\\n\\n    Attributes\\n    ----------\\n    model: torch.nn.Module\\n        Pytorch model to optimize (e.g. RNNModel, LSTMModel, GRUModel)\\n    loss_fn: function\\n        Loss function\\n    optimizer: torch.optim\\n        Optimization algorithm (e.g. Adam)\\n\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, model, loss_fn, optimizer, activation):\\n        self.model = model\\n        self.loss_fn = loss_fn\\n        self.optimizer = optimizer\\n        self.activation = activation\\n        self.train_losses = []\\n        self.val_losses = []\\n        self.device = model.device\\n\\n    def train_step(self, x, y):\\n        # Sets model to train mode\\n        self.model.train(True)\\n\\n        # Makes predictions\\n        yhat = self.model(x)\\n\\n        # Computes loss\\n        loss = self.loss_fn(y, yhat)\\n\\n        # Computes gradients\\n        loss.backward()\\n\\n        # self.model.float()\\n        # Updates parameters and zeroes gradients\\n        self.optimizer.step()\\n        self.optimizer.zero_grad()\\n\\n        # Returns the loss\\n        return loss.item()\\n\\n    def train(self, train_loader, val_loader, batch_size=64, n_epochs=50, n_features=1):\\n        \\\"\\\"\\\"Train pytorch model.\\n\\n        Parameters\\n        ----------\\n        train_loader: DataLoader\\n            Dataset object containing training set.\\n        val_loader: DataLoader\\n            Dataset object containing validation set.\\n        batch_size: int\\n            Number of samples to train before updating model parameters.\\n        n_epochs: int\\n            Number of complete passes through the training set.\\n        n_features: int\\n            Number of features.\\n\\n        \\\"\\\"\\\"\\n        model_path = f'{self.model}_{datetime.now().strftime(\\\"%Y-%m-%d %H:%M:%S\\\")}'\\n\\n        for epoch in range(1, n_epochs + 1):\\n            batch_losses = []\\n            for x_batch, y_batch in train_loader:\\n                x_batch = x_batch.view([batch_size, -1, n_features]).to(self.device)\\n                y_batch = y_batch.to(self.device)\\n                loss = self.train_step(x_batch, y_batch)\\n                batch_losses.append(loss)\\n            training_loss = np.mean(batch_losses)\\n            self.train_losses.append(training_loss)\\n\\n            with torch.no_grad():\\n                batch_val_losses = []\\n                for x_val, y_val in val_loader:\\n                    x_val = x_val.view([batch_size, -1, n_features]).to(self.device)\\n                    y_val = y_val.to(self.device)\\n                    self.model.eval()\\n                    yhat = self.model(x_val)\\n                    val_loss = self.loss_fn(y_val, yhat).item()\\n                    batch_val_losses.append(val_loss)\\n                validation_loss = np.mean(batch_val_losses)\\n                self.val_losses.append(validation_loss)\\n\\n            if (epoch <= 10) | (epoch % 50 == 0):\\n                print(\\n                    f\\\"[{epoch}/{n_epochs}] Training loss: {training_loss:.4f}\\\\t Validation loss: {validation_loss:.4f}\\\"\\n                )\\n\\n        torch.save(self.model.state_dict(), model_path)\\n\\n    def evaluate(self, test_loader, batch_size=1, n_features=1):\\n        \\\"\\\"\\\"Evaluate pytorch model.\\n\\n        Parameters\\n        ----------\\n        test_loader: DataLoader\\n            Dataset object containing test set.\\n        batch_size: int\\n            Number of samples to evaluate at a time.\\n\\n        \\\"\\\"\\\"\\n        with torch.no_grad():\\n            predictions = []\\n            values = []\\n            tags = []\\n            acc = 0\\n            for x_test, y_test in test_loader:\\n                x_test = x_test.view([batch_size, -1, n_features]).to(self.device)\\n                y_test = y_test.to(self.device)\\n                self.model.eval()\\n                yhat = self.model(x_test)\\n                ## if binary apply sigmoid, if class apply softmax\\n                y_pred_tags = torch.round(self.activation(yhat)).cpu().detach().numpy()\\n                acc += self.binary_acc(yhat, y_test)\\n                predictions.append(yhat.cpu().detach().numpy())\\n                values.append(y_test.cpu().detach().numpy())\\n                tags.append(y_pred_tags)\\n            print(\\\"Accuracy: {} %\\\".format(acc))\\n\\n        return predictions, values, tags\\n\\n    def binary_acc(self, y_pred, y_test):\\n        y_pred_tag = torch.round(torch.sigmoid(y_pred))\\n\\n        correct_results_sum = (y_pred_tag == y_test).sum().float()\\n        acc = correct_results_sum / y_test.shape[0]\\n        return acc\\n\\n    def plot_losses(self):\\n        plt.plot(self.train_losses, label=\\\"Training loss\\\")\\n        plt.plot(self.val_losses, label=\\\"Validation loss\\\")\\n        plt.legend()\\n        plt.title(\\\"Losses\\\")\\n        plt.show()\\n        plt.close()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "class Optimizer:\n",
    "    \"\"\"Optimizer Class.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    model: torch.nn.Module\n",
    "        Pytorch model to optimize (e.g. RNNModel, LSTMModel, GRUModel)\n",
    "    loss_fn: function\n",
    "        Loss function \n",
    "    optimizer: torch.optim\n",
    "        Optimization algorithm (e.g. Adam)\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, model, loss_fn, optimizer,activation):\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.activation = activation\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.device = model.device\n",
    "    \n",
    "    def train_step(self, x, y):\n",
    "        # Sets model to train mode\n",
    "        self.model.train(True)\n",
    "\n",
    "        # Makes predictions\n",
    "        yhat = self.model(x)\n",
    "        \n",
    "        # Computes loss\n",
    "        loss = self.loss_fn(y, yhat)\n",
    "\n",
    "        # Computes gradients\n",
    "        loss.backward()\n",
    "\n",
    "        #self.model.float()\n",
    "        # Updates parameters and zeroes gradients\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        # Returns the loss\n",
    "        return loss.item()\n",
    "\n",
    "    def train(self, train_loader, val_loader, batch_size=64, n_epochs=50, n_features=1):  \n",
    "        \"\"\"Train pytorch model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_loader: DataLoader\n",
    "            Dataset object containing training set.\n",
    "        val_loader: DataLoader\n",
    "            Dataset object containing validation set.\n",
    "        batch_size: int\n",
    "            Number of samples to train before updating model parameters.\n",
    "        n_epochs: int\n",
    "            Number of complete passes through the training set.\n",
    "        n_features: int \n",
    "            Number of features.\n",
    "\n",
    "        \"\"\" \n",
    "        model_path = f'{self.model}_{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}'\n",
    "\n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            batch_losses = []\n",
    "            for x_batch, y_batch in train_loader:\n",
    "                x_batch = x_batch.view([batch_size, -1, n_features]).to(self.device)\n",
    "                y_batch = y_batch.to(self.device)\n",
    "                loss = self.train_step(x_batch, y_batch)\n",
    "                batch_losses.append(loss)\n",
    "            training_loss = np.mean(batch_losses)\n",
    "            self.train_losses.append(training_loss)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                batch_val_losses = []\n",
    "                for x_val, y_val in val_loader:\n",
    "                    x_val = x_val.view([batch_size, -1, n_features]).to(self.device)\n",
    "                    y_val = y_val.to(self.device)\n",
    "                    self.model.eval()\n",
    "                    yhat = self.model(x_val)\n",
    "                    val_loss = self.loss_fn(y_val, yhat).item()\n",
    "                    batch_val_losses.append(val_loss)\n",
    "                validation_loss = np.mean(batch_val_losses)\n",
    "                self.val_losses.append(validation_loss)\n",
    "\n",
    "            if (epoch <= 10) | (epoch % 50 == 0):\n",
    "                print(\n",
    "                    f\"[{epoch}/{n_epochs}] Training loss: {training_loss:.4f}\\t Validation loss: {validation_loss:.4f}\"\n",
    "                )\n",
    "\n",
    "        torch.save(self.model.state_dict(), model_path)\n",
    "\n",
    "    def evaluate(self, test_loader, batch_size=1, n_features=1):\n",
    "        \"\"\"Evaluate pytorch model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        test_loader: DataLoader\n",
    "            Dataset object containing test set.\n",
    "        batch_size: int\n",
    "            Number of samples to evaluate at a time.\n",
    "\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            predictions = []\n",
    "            values = []\n",
    "            tags = []\n",
    "            acc = 0\n",
    "            for x_test, y_test in test_loader:\n",
    "                x_test = x_test.view([batch_size, -1, n_features]).to(self.device)\n",
    "                y_test = y_test.to(self.device)\n",
    "                self.model.eval()\n",
    "                yhat = self.model(x_test)\n",
    "                ## if binary apply sigmoid, if class apply softmax\n",
    "                y_pred_tags = torch.round(self.activation(yhat)).cpu().detach().numpy()\n",
    "                acc += self.binary_acc(yhat, y_test)\n",
    "                predictions.append(yhat.cpu().detach().numpy())\n",
    "                values.append(y_test.cpu().detach().numpy())\n",
    "                tags.append(y_pred_tags)\n",
    "            print('Accuracy: {} %'.format(acc)) \n",
    "            \n",
    "        return predictions, values, tags\n",
    "    \n",
    "    def binary_acc(self,y_pred, y_test):\n",
    "        y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "        correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "        acc = correct_results_sum/y_test.shape[0]\n",
    "        return acc\n",
    "    \n",
    "    def plot_losses(self):\n",
    "        plt.plot(self.train_losses, label=\"Training loss\")\n",
    "        plt.plot(self.val_losses, label=\"Validation loss\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Losses\")\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "810aab27-5fc4-4271-98eb-16f0917eb520",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nfs/home/subasriv/cyclops/drift_detection/models/temporal/pytorch/temporal_model_utils.py:91: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  output=np.dstack((X.loc[(slice(None), i), :].values for i in sorted(set(timestep_in_values))))\n",
      "/mnt/nfs/home/subasriv/cyclops/drift_detection/models/temporal/pytorch/temporal_model_utils.py:91: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  output=np.dstack((X.loc[(slice(None), i), :].values for i in sorted(set(timestep_in_values))))\n",
      "/mnt/nfs/home/subasriv/cyclops/drift_detection/models/temporal/pytorch/temporal_model_utils.py:91: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  output=np.dstack((X.loc[(slice(None), i), :].values for i in sorted(set(timestep_in_values))))\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 87;\n",
       "                var nbb_unformatted_code = \"batch_size = 1\\ninput_dim = features*3\\noutput_dim = 1\\nhidden_dim = 128\\nlayer_dim = 1\\ndropout = 0.2\\nn_epochs = 10\\nlearning_rate = 1e-3\\nweight_decay = 1e-6\\n\\ndevice = torch.device(\\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\")\\n#device = torch.device(\\\"cpu\\\")\\n\\noutcome = \\\"mortality\\\"\\n\\nX = temporal[np.in1d(temporal.index.get_level_values(0), static.index.get_level_values(0))]\\ny = static[np.in1d(static.index.get_level_values(0), X.index.get_level_values(0))]\\ny_train, y_val = train_test_split(y, test_size=1/2)\\ny_val, y_test = train_test_split(y_val, test_size=1/2)\\nX_train = X[np.in1d(X.index.get_level_values(0), y_train.index.get_level_values(0))]\\nX_train_inputs = format_dataset(X_train, level=\\\"features\\\",imputation_method=\\\"simple\\\")\\nX_val = X[np.in1d(X.index.get_level_values(0), y_val.index.get_level_values(0))]\\nX_val_inputs = format_dataset(X_val, level=\\\"features\\\",imputation_method=\\\"simple\\\")\\nX_test = X[np.in1d(X.index.get_level_values(0), y_test.index.get_level_values(0))]\\nX_test_inputs = format_dataset(X_test, level=\\\"features\\\",imputation_method=\\\"simple\\\")\\ny_train = y_train[[outcome]].to_numpy()\\ny_val = y_val[[outcome]].to_numpy()\\ny_test = y_test[[outcome]].to_numpy()\\n\\ntrain_dataset = get_data(X_train_inputs,y_train)\\ntrain_loader = train_dataset.to_loader(batch_size) \\n\\nval_dataset = get_data(X_val_inputs,y_val)\\nval_loader = val_dataset.to_loader(batch_size)\";\n",
       "                var nbb_formatted_code = \"batch_size = 1\\ninput_dim = features * 3\\noutput_dim = 1\\nhidden_dim = 128\\nlayer_dim = 1\\ndropout = 0.2\\nn_epochs = 10\\nlearning_rate = 1e-3\\nweight_decay = 1e-6\\n\\ndevice = torch.device(\\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\")\\n# device = torch.device(\\\"cpu\\\")\\n\\noutcome = \\\"mortality\\\"\\n\\nX = temporal[\\n    np.in1d(temporal.index.get_level_values(0), static.index.get_level_values(0))\\n]\\ny = static[np.in1d(static.index.get_level_values(0), X.index.get_level_values(0))]\\ny_train, y_val = train_test_split(y, test_size=1 / 2)\\ny_val, y_test = train_test_split(y_val, test_size=1 / 2)\\nX_train = X[np.in1d(X.index.get_level_values(0), y_train.index.get_level_values(0))]\\nX_train_inputs = format_dataset(X_train, level=\\\"features\\\", imputation_method=\\\"simple\\\")\\nX_val = X[np.in1d(X.index.get_level_values(0), y_val.index.get_level_values(0))]\\nX_val_inputs = format_dataset(X_val, level=\\\"features\\\", imputation_method=\\\"simple\\\")\\nX_test = X[np.in1d(X.index.get_level_values(0), y_test.index.get_level_values(0))]\\nX_test_inputs = format_dataset(X_test, level=\\\"features\\\", imputation_method=\\\"simple\\\")\\ny_train = y_train[[outcome]].to_numpy()\\ny_val = y_val[[outcome]].to_numpy()\\ny_test = y_test[[outcome]].to_numpy()\\n\\ntrain_dataset = get_data(X_train_inputs, y_train)\\ntrain_loader = train_dataset.to_loader(batch_size)\\n\\nval_dataset = get_data(X_val_inputs, y_val)\\nval_loader = val_dataset.to_loader(batch_size)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 1\n",
    "input_dim = features*3\n",
    "output_dim = 1\n",
    "hidden_dim = 128\n",
    "layer_dim = 1\n",
    "dropout = 0.2\n",
    "n_epochs = 10\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-6\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "outcome = \"mortality\"\n",
    "\n",
    "X = temporal[np.in1d(temporal.index.get_level_values(0), static.index.get_level_values(0))]\n",
    "y = static[np.in1d(static.index.get_level_values(0), X.index.get_level_values(0))]\n",
    "y_train, y_val = train_test_split(y, test_size=1/2)\n",
    "y_val, y_test = train_test_split(y_val, test_size=1/2)\n",
    "X_train = X[np.in1d(X.index.get_level_values(0), y_train.index.get_level_values(0))]\n",
    "X_train_inputs = format_dataset(X_train, level=\"features\",imputation_method=\"simple\")\n",
    "X_val = X[np.in1d(X.index.get_level_values(0), y_val.index.get_level_values(0))]\n",
    "X_val_inputs = format_dataset(X_val, level=\"features\",imputation_method=\"simple\")\n",
    "X_test = X[np.in1d(X.index.get_level_values(0), y_test.index.get_level_values(0))]\n",
    "X_test_inputs = format_dataset(X_test, level=\"features\",imputation_method=\"simple\")\n",
    "y_train = y_train[[outcome]].to_numpy()\n",
    "y_val = y_val[[outcome]].to_numpy()\n",
    "y_test = y_test[[outcome]].to_numpy()\n",
    "\n",
    "train_dataset = get_data(X_train_inputs,y_train)\n",
    "train_loader = train_dataset.to_loader(batch_size) \n",
    "\n",
    "val_dataset = get_data(X_val_inputs,y_val)\n",
    "val_loader = val_dataset.to_loader(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3f5debd9-db36-4d80-87dd-a5c87411d9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 88;\n",
       "                var nbb_unformatted_code = \"model_params = {'device': device,\\n                'input_dim': input_dim,\\n                'hidden_dim' : hidden_dim,\\n                'layer_dim' : layer_dim,\\n                'output_dim' : output_dim,\\n                'dropout_prob' : dropout}\\n\\nmodel = get_temporal_model('lstmcell', model_params).to(device)\";\n",
       "                var nbb_formatted_code = \"model_params = {\\n    \\\"device\\\": device,\\n    \\\"input_dim\\\": input_dim,\\n    \\\"hidden_dim\\\": hidden_dim,\\n    \\\"layer_dim\\\": layer_dim,\\n    \\\"output_dim\\\": output_dim,\\n    \\\"dropout_prob\\\": dropout,\\n}\\n\\nmodel = get_temporal_model(\\\"lstmcell\\\", model_params).to(device)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_params = {'device': device,\n",
    "                'input_dim': input_dim,\n",
    "                'hidden_dim' : hidden_dim,\n",
    "                'layer_dim' : layer_dim,\n",
    "                'output_dim' : output_dim,\n",
    "                'dropout_prob' : dropout}\n",
    "\n",
    "model = get_temporal_model('lstmcell', model_params).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "be852932-a909-4496-98b4-13d9b97bdd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10] Training loss: 0.7174\t Validation loss: 0.7127\n",
      "[2/10] Training loss: 0.7033\t Validation loss: 0.6886\n",
      "[3/10] Training loss: 0.6294\t Validation loss: 0.5663\n",
      "[4/10] Training loss: 0.5355\t Validation loss: 0.5142\n",
      "[5/10] Training loss: 0.4984\t Validation loss: 0.4875\n",
      "[6/10] Training loss: 0.4769\t Validation loss: 0.4675\n",
      "[7/10] Training loss: 0.4590\t Validation loss: 0.4504\n",
      "[8/10] Training loss: 0.4437\t Validation loss: 0.4353\n",
      "[9/10] Training loss: 0.4248\t Validation loss: 0.4219\n",
      "[10/10] Training loss: 0.4137\t Validation loss: 0.4097\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAA7lElEQVR4nO3dd3hVVbrH8e+bThJIIIWSBEINLQ0CQSIIKgKCgGIBHRUd69jQGa/Ysc2MV++Iztiwj6DoMIoIKIKAID1A6AFCCJDQQgIpQPq6f+wDBgRykpy0k/fzPOeBs/de66x9lF921l57LTHGoJRSynm51HUDlFJK1SwNeqWUcnIa9Eop5eQ06JVSyslp0CullJPToFdKKSenQa+UUk5Og145PRFJE5Er67odStUVDXqllHJyGvSqURIRTxGZIiIHbK8pIuJp2xcoInNE5LiIZIvIMhFxse17QkQyRCRPRHaIyBW27S4iMklEdotIloh8LSItbPu8RGSabftxEVkrIi3r7uxVY6NBrxqrp4F+QAwQDfQFnrHt+zOQDgQBLYGnACMiEcCDQB9jTFNgKJBmK/MQMAa4DGgDHAPetu27HfADwoAA4D7gVE2dmFLn0qBXjdUtwIvGmCPGmEzgBeBW275ioDXQzhhTbIxZZqxJoUoBT6C7iLgbY9KMMbttZe4DnjbGpBtjCoHJwPUi4marLwDoZIwpNcasM8bk1tqZqkZPg141Vm2AveXe77VtA3gNSAF+EpFUEZkEYIxJASZihfgREZkhIqfLtAO+tXXNHAe2Y/1gaAl8DswHZti6if5XRNxr8uSUKk+DXjVWB7DC+bS2tm0YY/KMMX82xnQARgGPne6LN8Z8YYy51FbWAK/ayu8Hhhtj/Mu9vIwxGbbfCl4wxnQH+gMjgdtq5SyVQoNeNR7utpuiXiLiBXwJPCMiQSISCDwHTAMQkZEi0klEBMjBujIvE5EIEbncdtO2AKufvcxW/3vAKyLSzlZHkIiMtv19sIhEiogrkIvVlVOGUrVEg141FvOwgvn0ywtIBDYBm4H1wMu2YzsDC4F8YCXwjjFmMVb//N+Bo8AhIBh40lbmTWA2VndPHrAKiLftawXMxAr57cAvWN05StUK0YVHlFLKuekVvVJKOTkNeqWUcnIa9Eop5eQ06JVSysm51XUDzhUYGGjCw8PruhlKKdWgrFu37qgxJuh8++pd0IeHh5OYmFjXzVBKqQZFRPZeaJ923SillJPToFdKKSenQa+UUk6u3vXRK6VqX3FxMenp6RQUFNR1U1QFvLy8CA0Nxd3d/glQNeiVUqSnp9O0aVPCw8Ox5nJT9ZExhqysLNLT02nfvr3d5bTrRilFQUEBAQEBGvL1nIgQEBBQ6d+8NOiVUgAa8g1EVf47OU3Ql5UZ/jpvO/O3HiK3oLium6OUUvWG0wR9xvFTTFu1l3s/X0fMCz9x7TvL+cdPO1izJ5uiEl3jQan6LCsri5iYGGJiYmjVqhUhISFn3hcVFV20bGJiIg8//HCFn9G/f3+HtHXJkiWMHDnSIXXVFqe5GRvWwpuk565iw75j/JpylF9TjvKvxSm8tSgFbw9X+nUI4NJOgVzaOZDOwb76a6pS9UhAQABJSUkATJ48GV9fX/7yl7+c2V9SUoKb2/njKi4ujri4uAo/Y8WKFQ5pa0PkNEGPMXgs/RvxPa4l/qru/PmqCHJOFbNydxbLbcG/KPkIAC2beZLQKdAK/k6BBDfzquPGK6XONWHCBLy8vNiwYQMJCQmMGzeORx55hIKCApo0acInn3xCREQES5Ys4fXXX2fOnDlMnjyZffv2kZqayr59+5g4ceKZq31fX1/y8/NZsmQJkydPJjAwkC1bttC7d2+mTZuGiDBv3jwee+wxfHx8SEhIIDU1lTlz5lywjdnZ2dx5552kpqbi7e3N1KlTiYqK4pdffuGRRx4BrD71pUuXkp+fz0033URubi4lJSW8++67DBgwoFa+S+cJ+uxUWPkvWPq/0GkIJDyMX/gAhvVsxbCerQBIP3aS5SlHWbbrKIuTj/DN+gwAIlo2JaFTIAM6B9K3fQt8PJ3na1Gqsl74fivbDuQ6tM7ubZrx/DU9Kl0uPT2dFStW4OrqSm5uLsuWLcPNzY2FCxfy1FNP8d///vd3ZZKTk1m8eDF5eXlERERw//33/27M+YYNG9i6dStt2rQhISGB5cuXExcXx7333svSpUtp374948ePr7B9zz//PLGxscyaNYtFixZx2223kZSUxOuvv87bb79NQkIC+fn5eHl5MXXqVIYOHcrTTz9NaWkpJ0+erPT3UVXOk2gBHeHRrbD2I1jzPnx2DbSJhf4PQ7dR4OpGaHNvburTlpv6tKWszLDtYK7VzbPrKNNW7+Xj5XtwdxVi2zZngK2bJzLEDzdXp7mVoVSDcsMNN+Dq6gpATk4Ot99+O7t27UJEKC4+/6CLESNG4OnpiaenJ8HBwRw+fJjQ0NCzjunbt++ZbTExMaSlpeHr60uHDh3OjE8fP348U6dOvWj7fv311zM/bC6//HKysrLIzc0lISGBxx57jFtuuYXrrruO0NBQ+vTpw5133klxcTFjxowhJiamOl9NpThP0AN4t4DLHof+D8LGGdYV/sw7wL8dXPIgxN4CHj4AuLgIPUP86Bnix32XdaSguJTEtGMsS8lkecpR/m/BTv5vwU6aernRv2MAl3YO4tJOgYQHeGv/vnJqVbnyrik+Pj5n/v7ss88yePBgvv32W9LS0hg0aNB5y3h6ep75u6urKyUlJVU6pjomTZrEiBEjmDdvHgkJCcyfP5+BAweydOlS5s6dy4QJE3jssce47bbbHPq5F+JcQX+aexOIuwN63Q475sHyN+GHx2HJ36Dv3dD3HvAJPKuIl7srl3a2ruIBsk8UsTzl6JmunvlbDwMQ4t+EAZ0DSehkvVr4eNT66SnVGOXk5BASEgLAp59+6vD6IyIiSE1NJS0tjfDwcL766qsKywwYMIDp06fz7LPPsmTJEgIDA2nWrBm7d+8mMjKSyMhI1q5dS3JyMk2aNCE0NJS7776bwsJC1q9fr0HvEC4u0G2k9dq3Cpa/Bb+8agV/zM3WVX5Ax/MWbeHjwTXRbbgmug3GGNKyTtq6eTKZu/kgM9buRwR6tGlm9e93CiIuvDle7q61fJJKNQ7/8z//w+23387LL7/MiBEjHF5/kyZNeOeddxg2bBg+Pj706dOnwjKTJ0/mzjvvJCoqCm9vbz777DMApkyZwuLFi3FxcaFHjx4MHz6cGTNm8Nprr+Hu7o6vry///ve/HX4OFyLGmIoPEhkGvAm4Ah8aY/5+zv43gMG2t95AsDHG37bvduAZ276XjTGfXeyz4uLiTI0uPJK5E1b+0+raKS2GbtdAwiMQWvHwrNNKSsvYnJHDr7uOsizlKBv2HaO41ODp5kKf8BYMigjitkvC8XDTvn3VMGzfvp1u3brVdTPqXH5+Pr6+vhhjeOCBB+jcuTOPPvpoXTfrd87330tE1hljzhtkFQa9iLgCO4EhQDqwFhhvjNl2geMfAmKNMXeKSAsgEYgDDLAO6G2MOXahz6vxoD8t77B103bth1CQA237Q8LD0Hmo9ZtAJZwoLGHNnmyW7bK6enYczuPegR148mr9h6MaBg16yxtvvMFnn31GUVERsbGxfPDBB3h7e9d1s36nJoL+EmCyMWao7f2TAMaYv13g+BXA88aYBSIyHhhkjLnXtu99YIkx5ssLfV6tBf1phXmw/nNY9Q7k7IfACOj/EETdCG6eFZc/j6e+3cwXq/cx/a54EjoFVlxAqTqmQd+wVDbo7bl0DQH2l3ufbtv2OyLSDmgPLKpMWRG5R0QSRSQxMzPTjiY5kGdTuORP8PAGuO5DcPOA2Q/ClChY9g84dbzSVT47ojsdgnx47Oskjp24+OPbSilV0xzdiTwOmGmMKa1MIWPMVGNMnDEmLijovIuY1zxXd4i6Ae5dBrfOgpbd4ecX4I0e8ONTcHx/hVWc1sTDlbfGxZJ9oohJ32zCnvsgSilVU+wJ+gwgrNz7UNu28xkHlO+WqUzZ+kEEOg6GW7+1Qj/ialj9HrwVA9/cA4c221VNzxA/Hh8awfyth/lqrf0/JJRSytHsCfq1QGcRaS8iHlhhPvvcg0SkK9AcWFlu83zgKhFpLiLNgats2xqG1lEw9gN4ZCP0vReS58J7l8Ln18LuxVDBlfpdl3YgoVMAL3y/jdTM/FpqtFJKna3CoDfGlAAPYgX0duBrY8xWEXlRREaVO3QcMMOU66cwxmQDL2H9sFgLvGjb1rD4h8Gwv8KjW+CK5+HwVvh8DLw/EDbPhNLzP1Xn4iL83w0xeLq78MiMJJ0uWakLGDx4MPPnn30NOGXKFO6///4Llhk0aBCnB25cffXVHD9+/HfHTJ48mddff/2inz1r1iy2bfttEOFzzz3HwoULK9H686tP0xnb1UdvjJlnjOlijOlojHnFtu05Y8zscsdMNsZMOk/Zj40xnWyvTxzX9DrQpDkMeAwmboZR/4SSAvjvH+GtWFj1LhT+/qq9lZ8Xf78uis0ZObyxcGcdNFqp+m/8+PHMmDHjrG0zZsywa2IxgHnz5uHv71+lzz436F988UWuvPLKKtVVX+kTPVXh5gm9boM/rYbxM8AvBH6cZN24/flFa4x+OcN6tmJcnzDe+2U3K3dn1VGjlaq/rr/+eubOnXtmkZG0tDQOHDjAgAEDuP/++4mLi6NHjx48//zz5y0fHh7O0aNHAXjllVfo0qULl156KTt27DhzzAcffECfPn2Ijo5m7NixnDx5khUrVjB79mwef/xxYmJi2L17NxMmTGDmzJkA/Pzzz8TGxhIZGcmdd95JYWHhmc97/vnn6dWrF5GRkSQnJ1/0/LKzsxkzZgxRUVH069ePTZs2AfDLL7+cWWAlNjaWvLw8Dh48yMCBA4mJiaFnz54sW7asel8uzj4FQk1zcYGI4dZr/1pY8aY1JHPVu3DXz9bIHZvnrunOmj3ZPPZ1Ej88MgB/b50jR9VTP0yye9CB3VpFwvC/X3B3ixYt6Nu3Lz/88AOjR49mxowZ3HjjjYgIr7zyCi1atKC0tJQrrriCTZs2ERUVdd561q1bx4wZM0hKSqKkpIRevXrRu3dvAK677jruvvtuAJ555hk++ugjHnroIUaNGsXIkSO5/vrrz6qroKCACRMm8PPPP9OlSxduu+023n33XSZOnAhAYGAg69ev55133uH111/nww8/vOD51fV0xnpF7yhhfeCmafDgWuv9yn+dtdvbw40p42LIzCvkqW8365BLpc5RvvumfLfN119/Ta9evYiNjWXr1q1ndbOca9myZVx77bV4e3vTrFkzRo367Tbili1bGDBgAJGRkUyfPp2tW7detD07duygffv2dOnSBYDbb7+dpUuXntl/3XXXAdC7d2/S0tIuWtevv/7KrbfeCpx/OuO33nqL48eP4+bmRp8+ffjkk0+YPHkymzdvpmnTphet2x56Re9ogZ0hejxs+ByufAF8f3suICrUnz9fFcGrPybzn3Xp3BgXdpGKlKojF7nyrkmjR4/m0UcfZf369Zw8eZLevXuzZ88eXn/9ddauXUvz5s2ZMGECBQUFVap/woQJzJo1i+joaD799FOWLFlSrfaenuq4OtMc19Z0xnpFXxPi74XSIlj/6e923TOwA/06tGDy7K2kHT1R+21Tqp7y9fVl8ODB3HnnnWeu5nNzc/Hx8cHPz4/Dhw/zww8/XLSOgQMHMmvWLE6dOkVeXh7ff//9mX15eXm0bt2a4uJipk+ffmZ706ZNycvL+11dERERpKWlkZKSAsDnn3/OZZddVqVzOz2dMXDe6YyfeOIJ+vTpQ3JyMnv37qVly5bcfffd3HXXXaxfv75Kn1meBn1NCIqAjpdbq12Vnr0KjquL8I8bY3B3deGRGRsoLtUhl0qdNn78eDZu3Hgm6KOjo4mNjaVr167cfPPNJCQkXLR8r169uOmmm4iOjmb48OFnTTX80ksvER8fT0JCAl27dj2zfdy4cbz22mvExsaye/fuM9u9vLz45JNPuOGGG4iMjMTFxYX77ruvSuc1efJk1q1bR1RUFJMmTTprOuOePXsSFRWFu7s7w4cPZ8mSJWfO+6uvvjqz9mx12DVNcW2q9UnNasrO+fDFjXD9x9Bz7O92z9t8kD9NX8+Dgzvxl6ERddBApX6jk5o1LDUxqZmqik5DoHl7WPXeeXdfHdmaG+NCeXtJCqtTdcilUqrmaNDXFBcXq68+fQ1krDvvIc9f04N2Lbx59Kskck6df6FjpZSqLg36mhRzM3j4wurzryTv4+nGm+NiOZJXyNM65FLVMf3/r2Goyn8nDfqa5OUHMbfAlv/+7mnZ06LD/Hl0SBfmbDrIN+vr98Seynl5eXmRlZWlYV/PGWPIysrCy8urUuV0HH1N63uPtWThuk9h0BPnPeS+yzryy85MnvtuC3HhzWkX4FO7bVSNXmhoKOnp6dT6wj+q0ry8vAgNDa1UGR11UxumXQ+HNsHELdYKVueRcfwUw6YspVOwL1/fewnurvrLllLKfjrqpq7F3wf5h2HbrAseEuLfhL9eG8mGfcf556KU2mubUsrpadDXho6XQ0Ana6Wqi7gmug1je4Xyr0W7WJvW8KbtV0rVTxr0tcHFxbqqz1gH6RfvlnphdA9Cm3szcUYSuQU65FIpVX0a9LUlehx4Nqvwqt7X05rl8lBuAc/N2lJLjVNKOTMN+tri2RRi/wBbv4Xcgxc9tFfb5jxyRWdmJR1g1gYdcqmUqh4N+trU5y4oK4XEjys89IHBnegT3pxnZ21hf3b1Fx5QSjVeGvS1KaAjdBlqBX1J4UUPPT3LJcDEr5Io0VkulVJVpEFf2+LvhZNHYcs3FR4a1sKbl6/tybq9x3h78e4Kj1dKqfPRoK9tHQZDYIR1U9aOh9VGx4RwbWwIby3axbq9x2qhgUopZ6NBX9tErKv6g0mwf41dRV4c3YM2/l5M/GoDeTrkUilVSXYFvYgME5EdIpIiIpMucMyNIrJNRLaKyBfltpeKSJLtNdtRDW/QoseBp1+FQy1Pa+rlzpSbYsg4dornZ198QWOllDpXhUEvIq7A28BwoDswXkS6n3NMZ+BJIMEY0wOYWG73KWNMjO01CgUePtDrVtj2HeTYN3yyd7sWPHR5Z75Zn8HsjQdquIFKKWdizxV9XyDFGJNqjCkCZgCjzznmbuBtY8wxAGPMEcc20wn1vRswkPiR3UUeurwTvdr68/S3m0k/pkMulVL2sSfoQ4D95d6n27aV1wXoIiLLRWSViAwrt89LRBJt28dUr7lOpHk4RFwNiZ9A8Sm7iri5uvDmuFiMgce+2khpWf2aeVQpVT856masG9AZGASMBz4QEX/bvna2qTNvBqaISMdzC4vIPbYfBomNaj7s+HvhVLa1MImdwlp489KYHqxJy+bdJTrLpVKqYvYEfQYQVu59qG1beenAbGNMsTFmD7ATK/gxxmTY/kwFlgCx536AMWaqMSbOGBMXFBRU6ZNosMIHQHB3u4danjYmJoRR0W14Y+EuNuzTIZdKqYuzJ+jXAp1FpL2IeADjgHNHz8zCuppHRAKxunJSRaS5iHiW254AbHNM053A6aGWhzbDvpWVKCa8NKYnrZp5MfGrJPILS2qwkUqphq7CoDfGlAAPAvOB7cDXxpitIvKiiJweRTMfyBKRbcBi4HFjTBbQDUgUkY227X83xmjQlxd5I3j5w6p3K1XMr4k7U8bFsD/7JC/okEul1EXoUoL1wYLnYMU/4ZFN4B9W8fHl/OOnHby1KIW3b+7FiKjWNdRApVR9p0sJ1nd97rb+XPthpYs+dEVnYsL8efKbTRw4bt/oHaVU46JBXx/4h0HXkbD+Myiq3Ph4d1cX3hwXQ2mZ4dGvknTIpVLqdzTo64v4++DUMdj8n0oXbRfgwwuje7J6TzbvL9VZLpVSZ9Ogry/a9YeWkZUeanna2F4hjIxqzT9+2snG/ccd3z6lVIOlQV9fnB5qeWQbpC2rQnHhlTGRBDf1ZOJXSZzQIZdKKRsN+vok8gbwDoDV71epuJ+3O/+4KYa0rBO8NEdHsSqlLBr09Ym7F/SeADvmwbG0KlXRr0MAfxrUkRlr9/PD5osvQq6Uahw06OubuD8CUqWhlqdNvLIL0aF+TPpmM9knihzXNqVUg6RBX9/4hUD3UbD+31B0okpVuLu68PoN0eQXlvDmwp0ObqBSqqHRoK+P4u+DghzYOKPKVXRu2ZTxfcOYtnofKUfyHdg4pVRDo0FfH4XFQ+to66ZsNaaomHhlF7zdXfn7D9sd2DilVEOjQV8fiUD8/XB0B6QuqXI1gb6e/GlwJxZuP8KKlKOOa59SqkHRoK+vel4HPkFVHmp52h0J4YT4N+Hludt1egSlGikN+vrKzRN63wE7f4Ts1CpX4+XuyhPDu7LtYC7frE93YAOVUg2FBn19FncnuLjCmg+qVc01Ua2JbevPa/N3cLJIn5hVqrHRoK/PmrWG7mNgwzQozKtyNSLCMyO6cSSvkKlLq/7bgVKqYdKgr+/63Q+FudUaagnQu10LRkS25v1fUjmcW+CgximlGgIN+vouNA5Cels3ZcvKqlXVE8O6UlpmeH3+Dgc1TinVEGjQNwTx90HWLkhdVK1q2gZ4MyEhnJnr09l6IMdBjVNK1Xca9A1B9zHg27LaQy0BHhjcCf8m7rwydzv1bb1gpVTN0KBvCNw8rBE4u36CoynVqsqviTsTr+zCit1ZLEo+4qAGKqXqMw36hqL3HeDiDmumVruqm+Pb0iHIh1fmbae4tHr9/kqp+k+DvqFo2hJ6joWk6VCQW62q3F1deGp4N1IzT/Dlmn0OaqBSqr7SoG9I4u+BonxI+qLaVV3RLZj+HQN4Y8FOck4VO6BxSqn6yq6gF5FhIrJDRFJEZNIFjrlRRLaJyFYR+aLc9ttFZJftdbujGt4ohfSG0L6wpvpDLUWEp0d04/ipYt5ZXL1+f6VU/VZh0IuIK/A2MBzoDowXke7nHNMZeBJIMMb0ACbatrcAngfigb7A8yLS3JEn0OjE32vNfZOysNpV9Wjjx9heoXyyPI392Scd0DilVH1kzxV9XyDFGJNqjCkCZgCjzznmbuBtY8wxAGPM6eEcQ4EFxphs274FwDDHNL2R6j4amraG1e86pLq/XBWBq4vw9x+THVKfUqr+sSfoQ4D95d6n27aV1wXoIiLLRWSViAyrRFlE5B4RSRSRxMzMTPtb3xi5ukOfP8LuRZBZ/SdcW/l5cc/ADszddJB1e7Md0EClVH3jqJuxbkBnYBAwHvhARPztLWyMmWqMiTPGxAUFBTmoSU6s9x3g6umQoZYA917WgeCmnrw0Rx+iUsoZ2RP0GUBYufehtm3lpQOzjTHFxpg9wE6s4LenrKosn0CIvB6SvoRTx6tdnbeHG38ZGkHS/uN8v+lg9dunlKpX7An6tUBnEWkvIh7AOGD2OcfMwrqaR0QCsbpyUoH5wFUi0tx2E/Yq2zZVXX3vgeIT1rh6BxjbK5TurZvx6g/JFBSXOqROpVT9UGHQG2NKgAexAno78LUxZquIvCgio2yHzQeyRGQbsBh43BiTZYzJBl7C+mGxFnjRtk1VV5sYaHuJbVbL6gezq4s1Z33G8VN8uiKt2vUppeoPqW99snFxcSYxMbGum9EwbP0W/jMBxn0JXa92SJV//HQta/Zks+TxQQT4ejqkTqVUzRORdcaYuPPt0ydjG7Ku10CzEFj9nsOqfPLqbpwsLmXKwl0Oq1MpVbc06BsyVzfocxfs+QWObHdIlZ2Cfbklvi1frNlHypGqL1+olKo/NOgbul63g5uXQ+aqP+2RKzrj7eHKX+fpQ1RKOQMN+obOJwAib7DWlD11zCFVBvh68uDgTixKPsKvu446pE6lVN3RoHcG8fdBySlY/2+HVXl7/3DCWjTh5bnbKC2rXzfslVKVo0HvDFr1hPABsOYDKC1xSJVe7q48MawryYfymLluf8UFlFL1lga9s4i/F3L2w84fHFbliMjW9Grrz+s/7eREoWN+gCilap8GvbPoMhz82jr0pqyI8MzI7mTmFfL+L7sdVq9SqnZp0DsLVzfoexekLYNDWxxWba+2zRkZ1Zqpy1I5mHPKYfUqpWqPBr0zib0V3Jo49AEqgCeGdaXMwGvzqz8tslKq9mnQOxPvFhB9E2z+D5zIcli1YS28uSMhnG/WZ7A5Pcdh9SqlaocGvbOJvw9KCmD9Zw6t9oHBnWjh48HLc7fpnPVKNTAa9M4muBu0vwzWfuiwoZYAzbzcefTKzqzek82CbYcdVq9SquZp0Duj+PsgNwOS5zi02vF929Ip2Je//ZBMUUmZQ+tWStUcDXpn1GUo+Lezbso6sJvFzdWFp67uyp6jJ5i+eq/D6lVK1SwNemfk4gqXPAD7VsLCyQ4N+8ERwVzaKZA3f95Fzslih9WrlKo5GvTOqs/dEPdHWD4FFjzrsLAXEZ66uhs5p4r55yKds16phkCD3lm5uMCI/7MCf8U/Yf7TDgv77m2acUPvUD5bmcberBMOqVMpVXM06J2ZCFz9GvS9F1a9DT8+6bCw//NVEbi7uvD3H3TOeqXqOw16ZycCw1+Ffn+C1e/CD084JOxbNvPi3oEd+WHLIdam6XrvStVnGvSNgQgM/Stc8iCseR/m/QXKqj888u6B7WnVzIuX52yjTOesV6re0qBvLETgqpeh/8PWw1Tz/lztsPf2cOMvQyPYmJ7D95sOOKihSilH06BvTERgyItw6aOQ+DHMmVjtsL8uNoSeIc149YdkCopLHdNOpZRD2RX0IjJMRHaISIqITDrP/gkikikiSbbXXeX2lZbbPtuRjVdVIAJXPA8D/mzNh/P9w9UKexcX4emru3Mgp4CPft3jwIYqpRzFraIDRMQVeBsYAqQDa0VktjFm2zmHfmWMefA8VZwyxsRUu6XKcUTg8mdBXGHp/4Ipg1H/tB60qoJLOgYwpHtL3lmcwo1xYQQ19XRwg5VS1WHPFX1fIMUYk2qMKQJmAKNrtlmqxonA5U/DoCchaTp89wCUVb3r5cnhXSksKeONhTsd2EillCPYE/QhQPnVodNt2841VkQ2ichMEQkrt91LRBJFZJWIjDnfB4jIPbZjEjMzM+1uvHKAQZNg0FOw8UuYdX+Vw75DkC9/6NeOGWv2sfNwnoMbqZSqDkfdjP0eCDfGRAELgPKTobczxsQBNwNTRKTjuYWNMVONMXHGmLigoCAHNUnZbdATcPkzsOkr+OaeKk9v/MgVnfH1dOOVudsd3EClVHXYE/QZQPkr9FDbtjOMMVnGmELb2w+B3uX2Zdj+TAWWALHVaK+qKQMft27SbpkJ39xdpbBv7uPBQ5d35pedmfyyU38zU6q+sCfo1wKdRaS9iHgA44CzRs+ISOtyb0cB223bm4uIp+3vgUACcO5NXFVfDHgMrnwBtn4D//0jlFZ+dsrb+rejbQtv/jp3O6X6EJVS9UKFQW+MKQEeBOZjBfjXxpitIvKiiIyyHfawiGwVkY3Aw8AE2/ZuQKJt+2Lg7+cZraPqk0snWg9WbZsFM++sdNh7urkyaXhXdhzO4+vE/RUXUErVOKlv63/GxcWZxMTEum6GWvk2zH8Kuo6E6z8BNw+7ixpjuOG9laRlnWDJ44Px9axwFK9SqppEZJ3tfujv6JOx6vwueQCGvWotR/ifCVBSZHdREeGZkd05ml/Ee0t211wblVJ20aBXF9bvPrj6ddgxF76+FUoKKy5jExPmz+iYNnywLJUDx0/VYCOVUhXRoFcX1/duawGTnT/CV3+A4gK7iz4+NAIDTJ69lcISnQdHqbqiQa8q1ucuGDkFdv0EX91id9iHNvfmsSFd+GnbYa59ewW79EEqpeqEBr2yT9wdcM1bkLIQZoyHYvu6Y+67rCMf3BbHodwCRv7zVz5dvof6NgBAKWenQa/s1/t2GPUv2L0YvhwHRSftKjake0t+nDiA/h0DmPz9NiZ8spYjufZ3ASmlqkeDXlVOr1thzDuQ+gt8eZPdYR/c1IuPJ/ThpdE9WJWaxdApS5m/9VANN1YpBRr0qipiboZr34M9y+CLG6HohF3FRIRbLwln7sOXEtK8Cfd+vo5J/93EicKqza2jlLKPBr2qmuhxcN1U2Lscpt8Ahfl2F+0U3JRv7k/g/kEd+SpxPyPeWsaGfcdqsLFKNW4a9Krqom6E6z6AfSttYW//qBoPNxeeGNaVGXf3o7jUcP17K3lz4S5KSqu/aLlS6mwa9Kp6Iq+HsR/C/tUw7XooyK1U8fgOAcx7ZADXRLXmjYU7ueH9lezNsq8rSCllHw16VX09x8L1H0H6Wpg2ttJh79fEnSnjYnlzXAwpR/K5+s1lfJ24X4dhKuUgGvTKMXpcCzd8CgfWw7TroCCn0lWMjgnhx4kDiQz1439mbuL+aes5dsL+OXaUUuenQa8cp/souOEzOJAEn18Lp45XuooQ/yZMv6sfTw7vys/Jhxk6ZSlLdRETpapFg145VreRcOO/4eAm+HwMnKr8aBpXF+Heyzoy64EEmjVx57aP1/DC91spKNb5cpSqCg165Xhdr4abpsHhrfDv0XAyu0rV9Gjjx5yHLmVC/3A+WZ7GqH/9yrYDlev/V0pp0KuaEjEMbpoOR5LhwythyzdQVvmhk17urkwe1YNP7+jDsZPFjHl7OR8sTaVMlylUym4a9KrmdLkK/jATXN1h5h3wXgJs+65KgT8oIpgfHxnAZRFBvDJvO3/4aDUHc3See6XsoUGvalb7gXD/Chj7kbX+7Ne3wfsDYfscqOTwyQBfT6be2ptXx0aStP84Q99YypxNB2qo4Uo5Dw16VfNcXK0Hqx5YDddOheKT1rz2Uy+DHT9WKvBFhJv6tGXuwwNoH+TLg19s4LGvksgrqNwi5ko1Jhr0qva4uEL0TfDAGhjzrjXW/sub4IPLYdeCSgV++0AfZt53CY9c0ZlZSRkMf3MZa9OqdtNXKWenQa9qn6ubNQPmg4nW/PYnj8L06+GjIZDys92B7+7qwqNDuvCf+/rjIsJN76/ktfnJFOt8OUqdRerbY+ZxcXEmMTGxrpuhalNJESRNh6WvQ246hPWDwU9C+8tAxK4q8gtLePH7rXydmE5UqB9v3BRDxyDfGm64UvWHiKwzxsSdb59dV/QiMkxEdohIiohMOs/+CSKSKSJJttdd5fbdLiK7bK/bq34aymm5eVhLFT683lqI/Pg+a/z9pyMg7Ve7qvD1dON/r4/mvT/0Yl/2SUa+9SvTV+/V+XKUwo4rehFxBXYCQ4B0YC0w3hizrdwxE4A4Y8yD55RtASQCcYAB1gG9jTEXfFxSr+gVxQWw/jNY9g/IP2SN3Bn0FLS7xK7ih3ML+Mt/NrJs11Gu6BrMq9dHEejrWcONVqpuVfeKvi+QYoxJNcYUATOA0XZ+9lBggTEm2xbuC4BhdpZVjZW7F8TfC48kwdC/wZHt8Mkw+PcY2L+mwuItm3nx2R19eW5kd5alHGXYlKUsSj5c481Wqr6yJ+hDgP3l3qfbtp1rrIhsEpGZIhJWmbIico+IJIpIYmamTmClbNybwCV/gkc2wpCX4NBm64bttLGQvu6iRV1chDsvbc/3D15KoK8nd36ayANfrGfNnmztzlGNjqNG3XwPhBtjorCu2j+rTGFjzFRjTJwxJi4oKMhBTVJOw8MHEh62Av/KyZCxDj68HKbfCAc2XLRoRKumfPdgAg8M7sjSnZnc+P5Khk5Zymcr0sjVsfeqkbAn6DOAsHLvQ23bzjDGZBljCm1vPwR621tWKbt5+sKlj8LEzXD5s9aqVlMHwZc3W7NlXqiYmyuPD+3K6qeu4NWxkXi5u/L87K3Ev/Izk/67iS0ZlZ87X6mGxJ6bsW5YN2OvwArptcDNxpit5Y5pbYw5aPv7tcATxph+tpux64BetkPXY92MveCTLXozVtmtIAdWvQcr34bCHOh2DQx6Elr2qLDopvTjTF+1j+82ZlBQXEZ0qB+39GvHNVFtaOLhWguNV8qxLnYz1q5x9CJyNTAFcAU+Nsa8IiIvAonGmNki8jdgFFACZAP3G2OSbWXvBJ6yVfWKMeaTi32WBr2qtFPHYdU7sPIdKMqzVru6bBIEd62waM6pYr5dn8601ftIOZJPMy83xvYO5Zb4tnQKblrzbVfKQaod9LVJg15V2cls6+p+9XtQdMJay/ayJyCoS4VFjTGs2ZPNtNX7+HHLQYpLDf06tOCW+HYM7dEKDzd9iFzVbxr0qnE5kQUr3oI1U6GkACJvsAI/oKNdxY/mF/J14n6+WL2P9GOnCPT15KY+oYzr05awFt413HilqkaDXjVO+Zmw4k1Y8yGUFllr2sb+AToMtiZYq0BZmeGXXZlMX7WPRcmHMcDgiGBuiW/LoIhgXF3sm55BqdqgQa8at7zD1hX+hmlQcByahUD0eGtiNTuv8jOOn+KrNfv4cu1+MvMKCfFvwvi+YdzYJ4zgpl41236l7KBBrxRASSHsmGcF/u5FYMqgXQLE3ALdR1vDNytQXFrGwm2HmbZ6L8tTsnBzEYb2aMUt/dpySYcAxM5J2JRyNA16pc6VewA2fmmFfnYqePhCjzEQ8wdo28+uWTNTM/P5YvU+/rMunZxTxXQI8uGW+HZc3ysUP2/3mj8HpcrRoFfqQoyBfasgaRps+RaKT0CLjhB7i9W906xNhVUUFJcyd9NBpq3ey4Z9x/F0c+Ga6DbcEt+WmDB/vcpXtUKDXil7FOZbi5cnTYe9y0FcoOPl1g3ciKvBreIZMLceyGH66n3M2pDByaJSerRpxi3x7Rgd0wYfT7daOAnVWGnQK1VZWbsh6Qureyc3A5o0t4Zpxv4BWkdXWDyvoJhZSQeYvmovyYfy8PV049rYEG7p15aurZrVwgmoxkaDXqmqKiuF1MWwYTokz4XSQmgZaXXtRN4IPgEXLW6MYf2+Y0xftY85mw9SVFJGZIgfI6NaMyKqNaHNdVy+cgwNeqUc4dQx2DzTuoF7MAlc3CFiuHWV3/EKay3ci8g+UcQ369P5fuMBNqZbE6nFtvVnZFQbRkS2ppWfDtNUVadBr5SjHd5qXeVvmgEns8C3FUSPs0I/sHOFxfdmnWDu5oPM2XiQbQdzEYE+7VowMro1w3u2JqiproilKkeDXqmaUlIEu+Zbob/rJzClEBZvjc3vcS14Vdwfvzszn7mbDjJn0wF2Hs7HRaBfhwBGRrVhWM9WtPDxqIUTUQ2dBr1StSHvsHWFv2E6HN0B7t7Wg1gxt1gPZrlUPDHazsN5zNl4gDmbDpJ69ASuLkJCp0BGRrVmaPdWOj5fXZAGvVK1yRhrFawNn8OWb6AwF/zbWd060ePBP8yOKgzbDuYyx3alvz/7FO6uwsDOQYyMbs2V3VrS1EtDX/1Gg16pulJ0EpLnWKG/Zykg0PYSa4K1bteAX2iFVRhj2JSew5xNB5i76SAHcgrwcHNhcEQQI6PacEW3YLw9dIx+Y6dBr1R9cGwvbJwB22bBkW3WtpA4W+iPghbtK6yirMywYf8xvt94kHmbD3Ikr5Am7q5c3i2Ya6JaMygiGC93XSGrMdKgV6q+OZoC27+DbbOtoZoAraJsoT/arsVSSssMa9OymbPpAD9sPkTWiSJ8PFwZ0r0lI6PaMKBLIJ5uGvqNhQa9UvXZsTTY/r0V+ulrrG1B3X670m/Zo8JJ1kpKy1iVaoX+j1sPcfxkMU293BjaoxUjo1qT0CkQd1ddJcuZadAr1VDkZFh9+ttmw74V1lTKLTpYgd99NLSJrTD0i0vL+DXlKHM2HuSnrYfIKyyhubc7w3q2YmRUG+Lbt8BNQ9/paNAr1RDlH/kt9Pcstcbo+7W1buJ2Hw2hfSocsllYUsrSnUeZs+kAC7cd5kRRKYG+Hgzv2Zoru7ckvn0L7dN3Ehr0SjV0J7Nhxw/W7Jqpi62lEZu2hq4jrS6etv0rnIKhoLiUxclHmLPpID8nH6aguIwm7q4kdApgcNdgBkUEE+LfpJZOSDmaBr1SzqQgB3b+ZI3eSfkZSk6BdyB0HWGFfvvLwPXiY+wLiktZmZrF4uQjLEo+QvqxUwB0bdWUQRHBDI4Ione75trF04Bo0CvlrIpOwK4FsH027JwPRfng5QcRttDvMBjcLz5ZmjGG3Zn5LEo+wuLkTNamZVNSZmjm5caALkFcHhHMZRFBBPrq/Dv1WbWDXkSGAW8CrsCHxpi/X+C4scBMoI8xJlFEwoHtwA7bIauMMfdd7LM06JWqouICay3c7bOttXELcqwlErsMtfr0O10JHj4VVpNXUMyvu46yeMcRFu/IJDOvEBGICvVncEQQl3cNpmcbP1xcdOWs+qRaQS8irsBOYAiQDqwFxhtjtp1zXFNgLuABPFgu6OcYY3ra21gNeqUcoKTIuoG7/TtrHv2TWeDWBDpfaY3T7zLUrgnXysqsqRgW2bp4NqYfxxgI9PVkUEQQgyOCGdAlkGY6HUOdq27QXwJMNsYMtb1/EsAY87dzjpsCLAAeB/6iQa9UPVFaYi2NuH22NV4//zC4elgTrXW+CjoPgYBOdi2InpVfyC87M1m8I5Nfdhwht6AENxehd7vmXN41mMFdg+kc7Kvr5NaB6gb99cAwY8xdtve3AvHGmAfLHdMLeNoYM1ZElnB20G/F+o0gF3jGGLPsPJ9xD3APQNu2bXvv3bu38meplKpYWZn1UNb2761plY/utLY3D4dOQ6zgD78UPCpe+aqktIwN+4+fuaGbfCgPgBD/JgzuanXxXNIhkCYeOnyzNtRo0IuIC7AImGCMSTsn6D0BX2NMloj0BmYBPYwxuRf6PL2iV6oWHUuzbuamLITUX6wRPG5eVth3GmK72u9oV1UHc06xODmTxTuOsDzlKCeLSvFwc+GSDgHW1X5EMG0DdOnEmlKjXTci4gfsBvJtRVoB2cAoY0ziOXUtwfZD4EKfp0GvVB0pLrC6eHYtgJQFkJVibW/R4bcunnaXVjiKB6wHtdbsybaN5DlCWtZJADoG+TA4IpjLuwYTF94CDzcdvuko1Q16N6yulyuADKybsTcbY7Ze4Pgl/HZFHwRkG2NKRaQDsAyINMZkX+jzNOiVqieyU2HXQquLJ20ZlBRYN3TbD7RCv/MQq8vHDnuOnmBx8hEW7zjC6tRsikrL8PV0Y0DnQEZFt2FwV511s7ocMbzyamAK1vDKj40xr4jIi0CiMWb2Occu4begHwu8CBQDZcDzxpjvL/ZZGvRK1UPFpyDtV+tqf9dPcGyPtT2gs+1q/0rr5q5bxWPtTxSWsDzlKIt3ZLJg22GO5hfS1MuNEZGtGRMbQt/wFjp0swr0gSmllGNl7bYCf9cC6wdAaSG4+5x9te/ftsJqSkrLWLE7i1lJGfy45RAni0pp4+fF6NgQro0NoUvLprVwMs5Bg14pVXOKTlpdO7t+sl7H91nbg7pagd9piLWqltvFFzk/WVTCgm2HmbUhg6W7jlJaZujeuhnXxoYwKqYNLZtVfG+gMdOgV0rVDmPg6C7rZu6un2DvCmsCNg9f6DDot+D3C7loNUfzC5mz8QDfJh1g4/7jiEBCx0DGxIYwtIeul3s+GvRKqbpRmG89oZuywOrmydlvbQ/uYfXrdxoCYX0v2refmpnPrKQDzNqQwb7sk3i5uzCkeyvGxLRhYJcgXVDFRoNeKVX3jIHMHdaVfsoC2LsSyoqtcfth8dB+AIQPhJBe55190xjD+n3HmbUhgzmbDnDsZDEtfDwYGWXdxI0N82/UT+Rq0Cul6p/CPNizzOrf37MMDm+2trv7QNt+1o3d9gOgVfTv5tovKilj6c5Mvk3KYOG2wxSWlNEuwJsxMSGMiQ2hfWDFk7c5Gw16pVT9dzLbGsGzZ6kV/pnJ1nbPZtCuP4QPsIK/ZeRZK2vlFhTz45ZDzNqQwcrULIyBmDB/ro0NYWRUawIayfTKGvRKqYYn/8hvV/t7lkL2bmt7k+bWmP32A63wD+52ZkK2gzmnmJ10gG83ZJB8KA83F2FglyDGxIYwpFtLp553R4NeKdXw5R6wdfUstf48bpv80DvQmpun/UDrZZuJc/vBXGYlZfDdhgMcyi3Ax8OVYT1bc21sCJd0DMDVyR7K0qBXSjmfY3t/u+JPWwa5GdZ231a2G7tWV0+ZXzir0rL5bsMB5m0+SF5hCcFNPRkd04YxsSF0b93MKW7iatArpZybMdbcPKf79/csgxNHrH1+YWdCvyA0gUUHPfh2QwZLdhyhuNTQpaUvV0e2pne75kSF+OPn3TDH6GvQK6UaF2Osufb3LLWF/69wyjaXYvNwaD+Q/Nb9mX+iM19sL2Ld3mNninYI9CE6zJ/oUD+iw/zp1rpZg5hwTYNeKdW4lZXBkW3lunp+hcIca19AZwrD+rPXO4pVJZ35NdObpPQcjuQVAuDuKnRr3YzoUH+iw/yJCfOjQ6BvvZt4TYNeKaXKKyuFQ5t+69/fuxKKrBWy8G0FbePJDerNFtduLM9vw4aMfDal55BfWAJAU083Im1X/NGh/sSE+dPKr27n4tGgV0qpiykrta74962C/ath32rIsU3O5u4NIb0xofEc9ItibWlnEg+VsTH9ONsP5lJcamVoy2ae5a76/YkM9avVRdM16JVSqrJyD5QL/lVwaDOYUkCssfth8RSF9GWXZ0/WHvNlY0YuG/cfJ/XoiTNVdAzyORP80aH+dG3dFE+3munv16BXSqnqKsyHjHW/BX/6Wii0LX9t6+4hrB/5wb1JKgkjKeMESftzSNp/nKP5Vn+/h6sL3do0I+Z0t0+YP+0DfBzS369Br5RSjlZWCke2w/5VVlfP/lW/zcVv6+4hLB4TFs+hZlEkZRqS0o+zcf9xNqfncKKoFICmXm62Lh8/4tq1YHDX4Co1R4NeKaVqgx3dPbTtR2loPLuLA0hKz2Hj/uNsTD9O8sE8osP8+e/9/av00Rr0SilVF+zs7qFtPAUBPcgqMIT4N6nSR10s6N3Ot1EppZQDePpCh8usF5y/u2fbdwB4uXsTEjEcrv/Y4c3QoFdKqdri4gqtelqvPndZ23IP/hb8Ht418rEa9EopVZeatYYe11qvGqKLLSqllJOzK+hFZJiI7BCRFBGZdJHjxoqIEZG4ctuetJXbISJDHdFopZRS9quw60ZEXIG3gSFAOrBWRGYbY7adc1xT4BFgdblt3YFxQA+gDbBQRLoYY0oddwpKKaUuxp4r+r5AijEm1RhTBMwARp/nuJeAV4GCcttGAzOMMYXGmD1Aiq0+pZRStcSeoA8B9pd7n27bdoaI9ALCjDFzK1vWVv4eEUkUkcTMzEy7Gq6UUso+1b4ZKyIuwD+AP1e1DmPMVGNMnDEmLigoqLpNUkopVY49wyszgLBy70Nt205rCvQEltjWXWwFzBaRUXaUVUopVcPsuaJfC3QWkfYi4oF1c3X26Z3GmBxjTKAxJtwYEw6sAkYZYxJtx40TEU8RaQ90BtY4/CyUUkpdUIVX9MaYEhF5EJgPuAIfG2O2isiLQKIxZvZFym4Vka+BbUAJ8EBFI27WrVt3VET2VuoszhYIHK1GeWei38XZ9Ps4m34fv3GG76LdhXbUu0nNqktEEi80sU9jo9/F2fT7OJt+H79x9u9Cn4xVSiknp0GvlFJOzhmDfmpdN6Ae0e/ibPp9nE2/j9849XfhdH30SimlzuaMV/RKKaXK0aBXSikn5zRBb+9Uyo2BiISJyGIR2SYiW0XkkbpuU10TEVcR2SAic+q6LXVNRPxFZKaIJIvIdhG5pK7bVJdE5FHbv5MtIvKliHjVdZsczSmCvtxUysOB7sB42xTJjVUJ8GdjTHegH/BAI/8+wJpCe3tdN6KeeBP40RjTFYimEX8vIhICPAzEGWN6Yj0UOq5uW+V4ThH02D+VcqNgjDlojFlv+3se1j/k380a2liISCgwAviwrttS10TEDxgIfARgjCkyxhyv00bVPTegiYi4Ad7AgTpuj8M5S9DbNR1yYyQi4UAs5RaEaYSmAP8DlNVxO+qD9kAm8ImtK+tDEfGp60bVFWNMBvA6sA84COQYY36q21Y5nrMEvToPEfEF/gtMNMbk1nV76oKIjASOGGPW1XVb6gk3oBfwrjEmFjgBNNp7WiLSHOu3//ZYq+D5iMgf6rZVjucsQa/TIZ9DRNyxQn66Meabum5PHUoARolIGlaX3uUiMq1um1Sn0oF0Y8zp3/BmYgV/Y3UlsMcYk2mMKQa+AfrXcZsczlmC/qJTKTc2Yi0M8BGw3Rjzj7puT10yxjxpjAm1TaE9DlhkjHG6KzZ7GWMOAftFJMK26Qqs2WUbq31APxHxtv27uQInvDltz8Ij9d6FplKu42bVpQTgVmCziCTZtj1ljJlXd01S9chDwHTbRVEqcEcdt6fOGGNWi8hMYD3WaLUNOOF0CDoFglJKOTln6bpRSil1ARr0Sinl5DTolVLKyWnQK6WUk9OgV0opJ6dBr5RSTk6DXimlnNz/A8TxTTFQ6nMvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 89;\n",
       "                var nbb_unformatted_code = \"loss_fn = nn.BCEWithLogitsLoss()\\noptimizer = optim.Adagrad(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\\nactivation = nn.Sigmoid()\\nopt = Optimizer(model=model, loss_fn=loss_fn, optimizer=optimizer,activation=activation)\\nopt.train(train_loader, val_loader, batch_size=batch_size, n_epochs=n_epochs, n_features=input_dim)\\nopt.plot_losses()\";\n",
       "                var nbb_formatted_code = \"loss_fn = nn.BCEWithLogitsLoss()\\noptimizer = optim.Adagrad(\\n    model.parameters(), lr=learning_rate, weight_decay=weight_decay\\n)\\nactivation = nn.Sigmoid()\\nopt = Optimizer(\\n    model=model, loss_fn=loss_fn, optimizer=optimizer, activation=activation\\n)\\nopt.train(\\n    train_loader,\\n    val_loader,\\n    batch_size=batch_size,\\n    n_epochs=n_epochs,\\n    n_features=input_dim,\\n)\\nopt.plot_losses()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "activation = nn.Sigmoid()\n",
    "opt = Optimizer(model=model, loss_fn=loss_fn, optimizer=optimizer,activation=activation)\n",
    "opt.train(train_loader, val_loader, batch_size=batch_size, n_epochs=n_epochs, n_features=input_dim)\n",
    "opt.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0ad1b59f-82e9-4def-9ce7-ff16c4b5df21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.0 %\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 90;\n",
       "                var nbb_unformatted_code = \"test_dataset = get_data(X_test_inputs,y_test)\\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, drop_last=True)\\npredictions, values, tags = opt.evaluate(test_loader, batch_size=1, n_features=input_dim)\";\n",
       "                var nbb_formatted_code = \"test_dataset = get_data(X_test_inputs, y_test)\\ntest_loader = torch.utils.data.DataLoader(\\n    test_dataset, batch_size=1, shuffle=False, drop_last=True\\n)\\npredictions, values, tags = opt.evaluate(\\n    test_loader, batch_size=1, n_features=input_dim\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = get_data(X_test_inputs,y_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, drop_last=True)\n",
    "predictions, values, tags = opt.evaluate(test_loader, batch_size=1, n_features=input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "762fb61c-3a02-438a-abd2-238a70d5a807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 73;\n",
       "                var nbb_unformatted_code = \"df_result = format_predictions(predictions, values, tags, X_test)\";\n",
       "                var nbb_formatted_code = \"df_result = format_predictions(predictions, values, tags, X_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_result = format_predictions(predictions, values, tags, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "479c3872-3ef6-4364-bbb1-1d0bef1d0669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>prediction</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encounter_id</th>\n",
       "      <th>timestep</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">11100461</th>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154417</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123046</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.191126</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.194895</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.191628</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.192944</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.193739</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17.194275</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">11101148</th>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.189415</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17.188330</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.193487</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.194447</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.194704</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.193975</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.193010</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.195467</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">11101350</th>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.195084</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.193903</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.195047</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.194380</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       value  prediction  tag\n",
       "encounter_id timestep                        \n",
       "11100461     0           0.0    0.154417  1.0\n",
       "             1           0.0    0.123046  1.0\n",
       "             2           0.0   17.191126  1.0\n",
       "             3           0.0   17.194895  1.0\n",
       "             4           0.0   17.191628  1.0\n",
       "             5           0.0   17.192944  1.0\n",
       "             6           0.0   17.193739  1.0\n",
       "             7           1.0   17.194275  1.0\n",
       "11101148     0           0.0   17.189415  1.0\n",
       "             1           1.0   17.188330  1.0\n",
       "             2           0.0   17.193487  1.0\n",
       "             3           0.0   17.194447  1.0\n",
       "             4           0.0   17.194704  1.0\n",
       "             5           0.0   17.193975  1.0\n",
       "             6           0.0   17.193010  1.0\n",
       "             7           0.0   17.195467  1.0\n",
       "11101350     0           0.0   17.195084  1.0\n",
       "             1           0.0   17.193903  1.0\n",
       "             2           0.0   17.195047  1.0\n",
       "             3           0.0   17.194380  1.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 75;\n",
       "                var nbb_unformatted_code = \"df_result.head(n=20)\";\n",
       "                var nbb_formatted_code = \"df_result.head(n=20)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_result.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1223d5f-f1c3-4991-8ee8-2ac28a0d9316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyclops-KKtuQLwg-py3.9",
   "language": "python",
   "name": "cyclops-kktuqlwg-py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

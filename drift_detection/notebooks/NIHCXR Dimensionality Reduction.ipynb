{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b07357c5",
   "metadata": {},
   "source": [
    "# NIH Chest X-Ray Dataset: Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e270226",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e187074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from drift_detection.drift_detector import Reductor, TSTester, DCTester\n",
    "from torchxrayvision.datasets import XRayCenterCrop, XRayResizer\n",
    "from torchxrayvision.datasets import NIH_Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import Subset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49e0c48",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63e7c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths for NIH dataset\n",
    "IMAGE_PATH = '~/NIHCXR/images'\n",
    "CSV_PATH = '~/NIHCXR/Data_Entry_2017.csv'\n",
    "\n",
    "# load NIH dataset\n",
    "dataset = NIH_Dataset(IMAGE_PATH, CSV_PATH, \n",
    "                      views=['AP', 'PA'], unique_patients=False, \n",
    "                      transform=transforms.Compose([XRayCenterCrop(),\n",
    "                                                    XRayResizer(224, engine='cv2')]))\n",
    "\n",
    "# grab random subset of 400 image indices from dataset\n",
    "indices = np.random.randint(len(dataset), size=400) \n",
    "dataset = Subset(dataset, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd074838",
   "metadata": {},
   "source": [
    "## Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980f815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = torch.concat([torch.tensor(img['img']) for img in dataset]).unsqueeze(1)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(make_grid(imgs[np.random.randint(400, size=16)], normalize=True).permute(1,2,0), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb09a0f6",
   "metadata": {},
   "source": [
    "## TorchXRayVision Trained Autoencoder\n",
    "\n",
    "    Reduce Dimensionality of images by using the representations extracted from the bottleneck of the \n",
    "    TorchXRayVision trained autoencoder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857d5e40",
   "metadata": {},
   "source": [
    "```X_input``` shape: (400, 1, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa6822b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from drift_detection.drift_detector import Reductor\n",
    "reductor = Reductor(\"TAE_txrv_CNN\")\n",
    "X_transformed, y = reductor.transform(dataset, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16864739",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_transformed shape: \", X_transformed.shape, \"\\tlabels shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70c511a",
   "metadata": {},
   "source": [
    "## TorchXRayVision Classifier (BBSDs)\n",
    "    Reduce dimensionality of images with the TorchXRayVision Classifier; returns the softmax probability \n",
    "    distribution of multi-class prediction of 18 pathologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aacc9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reductor = Reductor(\"BBSDs_txrv_CNN\")\n",
    "X_transformed, y = reductor.transform(dataset, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28665c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_transformed shape: \", X_transformed.shape, \"\\tlabels shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc50323",
   "metadata": {},
   "source": [
    "The intersection of the model predictions and the NIH dataset labels yield 10 overlapping pathologies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2c9219",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.intersect1d(reductor.model.pathologies, dataset.dataset.pathologies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyclops",
   "language": "python",
   "name": "cyclops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

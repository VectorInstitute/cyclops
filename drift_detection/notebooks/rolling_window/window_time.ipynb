{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0204ce-4c3e-44d4-ba4e-87700c720acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from matplotlib.colors import ListedColormap\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from baseline_models.temporal.pytorch.optimizer import Optimizer\n",
    "from baseline_models.temporal.pytorch.utils import *\n",
    "from drift_detector.rolling_window import *\n",
    "from gemini.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc229b2-82b7-45f6-808a-f03b438f09ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/mnt/nfs/project/delirium/drift_exp/JULY-04-2022\"\n",
    "threshold = 0.05\n",
    "num_timesteps = 6\n",
    "stat_window = 30\n",
    "lookup_window = 30\n",
    "stride = 1\n",
    "run = 1\n",
    "shift = \"simulated_deployment\"\n",
    "hospital = [\"SBK\", \"UHNTG\", \"THPC\", \"THPM\", \"UHNTW\", \"SMH\", \"MSH\", \"PMH\"]\n",
    "outcome = \"mortality\"\n",
    "aggregation_type = \"time\"\n",
    "scale = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94627389-7636-4555-a27b-457d3980fad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_data, x, y = get_gemini_data(PATH)\n",
    "x = scale_temporal(x)\n",
    "X = reshape_inputs(x, num_timesteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3508a128-d17a-4601-b97e-18628c9bdee2",
   "metadata": {},
   "source": [
    "## Set constant reference distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb25fc74-11f8-4ff7-89dc-93b5e5164d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    (x_train, y_train),\n",
    "    (x_val, y_val),\n",
    "    (x_test, y_test),\n",
    "    feats,\n",
    "    admin_data,\n",
    ") = import_dataset_hospital(\n",
    "    admin_data, x, y, shift, outcome, hospital, run, shuffle=True\n",
    ")\n",
    "\n",
    "random.seed(1)\n",
    "\n",
    "# Normalize data\n",
    "(\n",
    "    (X_tr_normalized, y_tr),\n",
    "    (X_val_normalized, y_val),\n",
    "    (X_t_normalized, y_t),\n",
    ") = normalize_data(\n",
    "    aggregation_type,\n",
    "    admin_data,\n",
    "    num_timesteps,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_val,\n",
    "    y_val,\n",
    "    x_test,\n",
    "    y_test,\n",
    ")\n",
    "# Scale data\n",
    "if scale:\n",
    "    X_tr_normalized, X_val_normalized, X_t_normalized = scale_data(\n",
    "        numerical_cols, X_tr_normalized, X_val_normalized, X_t_normalized\n",
    "    )\n",
    "# Process data\n",
    "X_tr_final, X_val_final, X_t_final = process_data(\n",
    "    aggregation_type, num_timesteps, X_tr_normalized, X_val_normalized, X_t_normalized\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875c1032-4b87-4c8b-bc89-ffcc311259c0",
   "metadata": {},
   "source": [
    "## Create Data Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4213b586-46d5-4607-ae79-7a262e252ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = date(2019, 1, 1)\n",
    "end_date = date(2020, 8, 1)\n",
    "\n",
    "val_ids = list(X_val_normalized.index.get_level_values(0).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b62f72-3384-4686-b661-81ebdb7392fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_stream, y_test_stream, measure_dates_test = get_streams(\n",
    "    x, y, admin_data, start_date, end_date, stride=1, window=1, ids_to_exclude=val_ids\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8fcfb0-9637-4eb9-a1e1-4e4463ba537a",
   "metadata": {},
   "source": [
    "## Rolling Window Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae5be77-cd44-4e8a-9c3d-402196327952",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_technique = \"BBSDs_trained_LSTM\"\n",
    "model_path = os.path.join(os.getcwd(), \"../../saved_models/\" + shift + \"_lstm.pt\")\n",
    "md_test = \"MMD\"\n",
    "sign_level = 0.05\n",
    "sample = 1000\n",
    "dataset = \"gemini\"\n",
    "context_type = \"rnn\"\n",
    "representation = \"rnn\"\n",
    "\n",
    "shift_reductor = ShiftReductor(\n",
    "    X_tr_final,\n",
    "    y_tr,\n",
    "    dr_technique,\n",
    "    dataset,\n",
    "    var_ret=0.8,\n",
    "    model_path=model_path,\n",
    ")\n",
    "# Get shift detector\n",
    "shift_detector = ShiftDetector(\n",
    "    dr_technique,\n",
    "    md_test,\n",
    "    sign_level,\n",
    "    shift_reductor,\n",
    "    sample,\n",
    "    dataset,\n",
    "    feats,\n",
    "    model_path,\n",
    "    context_type,\n",
    "    representation,\n",
    ")\n",
    "\n",
    "output_dim = 1\n",
    "batch_size = 64\n",
    "input_dim = 108\n",
    "timesteps = 6\n",
    "hidden_dim = 64\n",
    "layer_dim = 2\n",
    "dropout = 0.2\n",
    "n_epochs = 256\n",
    "learning_rate = 2e-3\n",
    "weight_decay = 1e-6\n",
    "last_timestep_only = False\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "model_params = {\n",
    "    \"device\": device,\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"layer_dim\": layer_dim,\n",
    "    \"output_dim\": output_dim,\n",
    "    \"dropout_prob\": dropout,\n",
    "    \"last_timestep_only\": last_timestep_only,\n",
    "}\n",
    "\n",
    "model = get_temporal_model(\"lstm\", model_params).to(device)\n",
    "checkpoint_fpath = os.path.join(os.getcwd(), \"../../saved_models/\", shift + \"_lstm.pt\")\n",
    "model, opt, n_epochs = load_ckp(checkpoint_fpath, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8d9033-b361-4a53-906c-eed20b26f503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "all_runs = []\n",
    "for i in range(0, 5):\n",
    "    random.seed(1)\n",
    "    np.random.seed(1)\n",
    "\n",
    "    dist_test, pvals_test = rolling_window_drift(\n",
    "        X_tr_final,\n",
    "        x_test_stream,\n",
    "        shift_detector,\n",
    "        sample,\n",
    "        stat_window,\n",
    "        lookup_window,\n",
    "        stride,\n",
    "        num_timesteps,\n",
    "        threshold,\n",
    "        X_val_final,\n",
    "    )\n",
    "    performance_metrics = rolling_window_performance(\n",
    "        x_test_stream,\n",
    "        y_test_stream,\n",
    "        opt,\n",
    "        sample,\n",
    "        stat_window,\n",
    "        lookup_window,\n",
    "        stride,\n",
    "        num_timesteps,\n",
    "        input_dim,\n",
    "        threshold,\n",
    "        X_val_final,\n",
    "    )\n",
    "    total_alarms = len(pvals_test[pvals_test < sign_level])\n",
    "    run_dict = {\n",
    "        \"dist\": dist_test,\n",
    "        \"pval\": pvals_test,\n",
    "        \"performance\": performance_metrics,\n",
    "        \"alarms\": total_alarms,\n",
    "    }\n",
    "    all_runs.append(run_dict)\n",
    "    mean = np.mean(pvals_test[pvals_test < 0.05])\n",
    "    ci = st.t.interval(\n",
    "        0.95,\n",
    "        len(pvals_test[pvals_test < 0.05]) - 1,\n",
    "        loc=np.mean(pvals_test[pvals_test < 0.05]),\n",
    "        scale=st.sem(pvals_test[pvals_test < 0.05]),\n",
    "    )\n",
    "    print(total_alarms, \" alarms with avg p-value of \", mean, ci)\n",
    "np.save(os.path.join(PATH, shift, shift + \"_rolling_window.npy\"), all_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfa1dee-dce1-461e-958c-7870e4050984",
   "metadata": {},
   "source": [
    "## Plot Drift and Prediction Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c4178f-53af-4787-957e-95dc1b37912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = performance_metrics.shape[0]\n",
    "threshold = 0.05\n",
    "measure_dates_test_adjust = [\n",
    "    (\n",
    "        datetime.datetime.strptime(date, \"%Y-%m-%d\")\n",
    "        + datetime.timedelta(days=lookup_window + stat_window)\n",
    "    ).strftime(\"%Y-%m-%d\")\n",
    "    for date in measure_dates_test\n",
    "]\n",
    "fig, (ax1, ax2, ax3, ax4, ax5, ax6) = plt.subplots(6, 1, figsize=(22, 12))\n",
    "results = pd.DataFrame(\n",
    "    {\n",
    "        \"dates\": measure_dates_test_adjust[0:end],\n",
    "        \"pval\": pvals_test[0:end],\n",
    "        \"dist\": dist_test[0:end],\n",
    "        \"detection\": np.where(pvals_test[0:end] < threshold, 1, 0),\n",
    "    }\n",
    ")\n",
    "results = pd.concat([results, performance_metrics], axis=1)\n",
    "results.to_pickle(\n",
    "    os.path.join(\n",
    "        PATH, shift, shift + \"_\" + dr_technique + \"_\" + md_test + \"_results.pkl\"\n",
    "    )\n",
    ")\n",
    "start = 0\n",
    "end = performance_metrics.shape[0] - 1\n",
    "cmap = ListedColormap([\"lightgrey\", \"red\"])\n",
    "ax1.plot(\n",
    "    results[\"dates\"], results[\"pval\"], \".-\", color=\"red\", linewidth=0.5, markersize=2\n",
    ")\n",
    "ax1.set_xlim(results[\"dates\"][start], results[\"dates\"][end])\n",
    "ax1.axhline(y=threshold, color=\"dimgrey\", linestyle=\"--\")\n",
    "ax1.set_ylabel(\"P-Values\", fontsize=16)\n",
    "ax1.set_xticklabels([])\n",
    "ax1.pcolorfast(\n",
    "    ax1.get_xlim(),\n",
    "    ax1.get_ylim(),\n",
    "    results[\"detection\"].values[np.newaxis],\n",
    "    cmap=cmap,\n",
    "    alpha=0.4,\n",
    ")\n",
    "\n",
    "ax2.plot(\n",
    "    results[\"dates\"], results[\"dist\"], \".-\", color=\"red\", linewidth=0.5, markersize=2\n",
    ")\n",
    "ax2.set_xlim(results[\"dates\"][start], results[\"dates\"][end])\n",
    "ax2.set_ylabel(\"Distance\", fontsize=16)\n",
    "ax2.axhline(y=np.mean(results[\"dist\"]), color=\"dimgrey\", linestyle=\"--\")\n",
    "ax2.set_xticklabels([])\n",
    "ax2.pcolorfast(\n",
    "    ax2.get_xlim(),\n",
    "    ax2.get_ylim(),\n",
    "    results[\"detection\"].values[np.newaxis],\n",
    "    cmap=cmap,\n",
    "    alpha=0.4,\n",
    ")\n",
    "\n",
    "ax3.plot(\n",
    "    results[\"dates\"], results[\"auroc\"], \".-\", color=\"blue\", linewidth=0.5, markersize=2\n",
    ")\n",
    "ax3.set_xlim(results[\"dates\"][start], results[\"dates\"][end])\n",
    "ax3.set_ylabel(\"AUROC\", fontsize=16)\n",
    "ax3.axhline(y=np.mean(results[\"auroc\"]), color=\"dimgrey\", linestyle=\"--\")\n",
    "ax3.set_xticklabels([])\n",
    "ax3.pcolorfast(\n",
    "    ax3.get_xlim(),\n",
    "    ax3.get_ylim(),\n",
    "    results[\"detection\"].values[np.newaxis],\n",
    "    cmap=cmap,\n",
    "    alpha=0.4,\n",
    ")\n",
    "\n",
    "ax4.plot(\n",
    "    results[\"dates\"], results[\"auprc\"], \".-\", color=\"blue\", linewidth=0.5, markersize=2\n",
    ")\n",
    "ax4.set_xlim(results[\"dates\"][start], results[\"dates\"][end])\n",
    "ax4.set_ylabel(\"AUPRC\", fontsize=16)\n",
    "ax4.axhline(y=np.mean(results[\"auprc\"]), color=\"dimgrey\", linestyle=\"--\")\n",
    "ax4.set_xticklabels([])\n",
    "ax4.pcolorfast(\n",
    "    ax4.get_xlim(),\n",
    "    ax4.get_ylim(),\n",
    "    results[\"detection\"].values[np.newaxis],\n",
    "    cmap=cmap,\n",
    "    alpha=0.4,\n",
    ")\n",
    "\n",
    "ax5.plot(\n",
    "    results[\"dates\"], results[\"prec1\"], \".-\", color=\"blue\", linewidth=0.5, markersize=2\n",
    ")\n",
    "ax5.set_xlim(results[\"dates\"][start], results[\"dates\"][end])\n",
    "ax5.set_ylabel(\"PPV\", fontsize=16)\n",
    "ax5.axhline(y=np.mean(results[\"prec1\"]), color=\"dimgrey\", linestyle=\"--\")\n",
    "ax5.set_xticklabels([])\n",
    "ax5.pcolorfast(\n",
    "    ax5.get_xlim(),\n",
    "    ax5.get_ylim(),\n",
    "    results[\"detection\"].values[np.newaxis],\n",
    "    cmap=cmap,\n",
    "    alpha=0.4,\n",
    ")\n",
    "\n",
    "ax6.plot(\n",
    "    results[\"dates\"], results[\"rec1\"], \".-\", color=\"blue\", linewidth=0.5, markersize=2\n",
    ")\n",
    "ax6.set_xlim(results[\"dates\"][start], results[\"dates\"][end])\n",
    "ax6.set_ylabel(\"Sensitivity\", fontsize=16)\n",
    "ax6.set_xlabel(\"time (s)\", fontsize=16)\n",
    "ax6.axhline(y=np.mean(results[\"rec1\"]), color=\"dimgrey\", linestyle=\"--\")\n",
    "ax6.tick_params(axis=\"x\", labelrotation=45)\n",
    "ax6.pcolorfast(\n",
    "    ax6.get_xlim(),\n",
    "    ax6.get_ylim(),\n",
    "    results[\"detection\"].values[np.newaxis],\n",
    "    cmap=cmap,\n",
    "    alpha=0.4,\n",
    ")\n",
    "\n",
    "for index, label in enumerate(ax6.xaxis.get_ticklabels()):\n",
    "    if index % 28 != 0:\n",
    "        label.set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d883afb-2a5a-4c09-8fb0-f80c264a7f49",
   "metadata": {},
   "source": [
    "## Retraining: Drift Alarms "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39a259d-0394-48f8-b52a-e58c25f05368",
   "metadata": {},
   "source": [
    "### Drift Alarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af5b979-7243-4675-97a7-dcc4b47ae7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = [127, 118, 119, 123, 127]\n",
    "mostrecent30 = [132, 116, 97, 98, 128]\n",
    "mostrecent60 = [100, 96, 108, 97, 97]\n",
    "mostrecent120 = [96, 76, 101, 67, 89]\n",
    "cumulative = [72, 112, 64, 85, 107]\n",
    "\n",
    "retraining_drift = pd.DataFrame(\n",
    "    {\n",
    "        \"Baseline\": baseline,\n",
    "        \"Most Recent \\n(30 days)\": mostrecent30,\n",
    "        \"Most Recent \\n(60 days)\": mostrecent60,\n",
    "        \"Most Recent \\n(120 days)\": mostrecent120,\n",
    "        \"Cumulative\": cumulative,\n",
    "    }\n",
    ")\n",
    "fig, ax = plt.subplots(figsize=(7, 4))\n",
    "ax.boxplot(retraining_drift, patch_artist=True)\n",
    "ax.set_xticks([1, 2, 3, 4, 5], retraining_drift.columns, rotation=45, fontsize=12)\n",
    "ax.set_xlabel(\"Retraining Strategies\", fontsize=12)\n",
    "ax.set_ylabel(\"Number of Drift Alarms\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d780a7-1c4d-4466-93b8-a72af9c3eb57",
   "metadata": {},
   "source": [
    "### Number of Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414f713f-ed48-49e6-8e01-51fbb62888cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = [127, 118, 119, 123, 127]\n",
    "mostrecent120 = [96, 76, 101, 67, 89]\n",
    "mostrecent120_10 = [97, 103, 98, 64, 94]\n",
    "\n",
    "retraining_drift = pd.DataFrame(\n",
    "    {\n",
    "        \"Baseline\": baseline,\n",
    "        \"Most Recent \\n(120 days, 1 epoch)\": mostrecent120,\n",
    "        \"Most Recent\\n (120 days, 10 epochs)\": mostrecent120_10,\n",
    "    }\n",
    ")\n",
    "fig, ax = plt.subplots(figsize=(7, 4))\n",
    "ax.boxplot(retraining_drift, patch_artist=True)\n",
    "ax.set_xticks([1, 2, 3], retraining_drift.columns, rotation=45, fontsize=12)\n",
    "ax.set_xlabel(\"Retraining Strategies\", fontsize=12)\n",
    "ax.set_ylabel(\"Number of Drift Alarms\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aceca93-ac9a-41a9-8c1a-a2702acbe587",
   "metadata": {},
   "source": [
    "### Drift Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a00d0e-3c6b-4527-a0cb-fd2cc31a02ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrecent120_10_2 = [50, 44, 40, 51, 61]\n",
    "mostrecent120 = [96, 76, 101, 67, 89]\n",
    "mostrecent120_10_1 = [121, 150, 123, 139, 131]\n",
    "\n",
    "retraining_drift = pd.DataFrame(\n",
    "    {\n",
    "        \"P-Val=0.01\": mostrecent120_10_2,\n",
    "        \"P-Val=0.05\": mostrecent120,\n",
    "        \"P-Val=0.1\": mostrecent120_10_1,\n",
    "    }\n",
    ")\n",
    "fig, ax = plt.subplots(figsize=(7, 4))\n",
    "ax.boxplot(retraining_drift, patch_artist=True)\n",
    "ax.set_xticks([1, 2, 3], retraining_drift.columns, rotation=45, fontsize=12)\n",
    "ax.set_xlabel(\"Retraining Strategies\", fontsize=12)\n",
    "ax.set_ylabel(\"Number of Drift Alarms\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f972b02a-f2f4-4e84-8891-a1bc650d34b2",
   "metadata": {},
   "source": [
    "## Retraining: PPV & Sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d7cbaf-d645-40b3-9e0f-a8a324298c23",
   "metadata": {},
   "source": [
    "### Window Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22682c3-5501-44cc-96bf-4099eb9622f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "types = [\n",
    "    \"baseline\",\n",
    "    \"mostrecent30\",\n",
    "    \"mostrecent60\",\n",
    "    \"mostrecent120\",\n",
    "    \"cumulative_1epoch\",\n",
    "]\n",
    "labels = [\n",
    "    \"Baseline\",\n",
    "    \"Most Recent\\n(30days)\",\n",
    "    \"Most Recent\\n(60 days)\",\n",
    "    \"Most Recent\\n(120 days)\",\n",
    "    \"Cumulative\",\n",
    "]\n",
    "\n",
    "drift_sensitivity = []\n",
    "drift_ppv = []\n",
    "for retraining_type in types:\n",
    "    for i in range(0, 5):\n",
    "        res_path = os.path.join(\n",
    "            PATH, shift, shift + \"_\" + retraining_type + \"_retraining_update.npy\"\n",
    "        )\n",
    "        cum = np.load(res_path, allow_pickle=True)[i]\n",
    "        drift_sensitivity.append(np.mean(cum[\"performance\"][\"rec1\"]))\n",
    "        drift_ppv.append(np.mean(cum[\"performance\"][\"prec1\"]))\n",
    "        # drift_sensitivity.append(np.mean(cum['performance']['rec1'][[i for i,v in enumerate(cum['pval']) if v < 0.05]]))\n",
    "        # drift_ppv.append(np.mean(cum['performance']['prec1'][[i for i,v in enumerate(cum['pval']) if v < 0.05]]))\n",
    "\n",
    "retraining_drift = pd.DataFrame(\n",
    "    {\n",
    "        \"Retraining Strategy\": np.repeat(types, 5),\n",
    "        \"PPV\": drift_ppv,\n",
    "        \"Sensitivity\": drift_sensitivity,\n",
    "    }\n",
    ")\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 4))\n",
    "for j, variable in enumerate([\"PPV\", \"Sensitivity\"]):\n",
    "    for i, grp in enumerate(retraining_drift.groupby(\"Retraining Strategy\")):\n",
    "        axs[j].boxplot(\n",
    "            x=variable, data=grp[1], positions=[i], widths=0.4, patch_artist=True\n",
    "        )\n",
    "        axs[j].set_xticks(range(0, len(types)), labels, rotation=45, fontsize=12)\n",
    "        axs[j].set_ylabel(variable, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e011a5-92d0-4ebf-adca-83ae40c32f07",
   "metadata": {},
   "source": [
    "### Number of Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395c27bf-4553-473c-8fe4-f95e99a03ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "types = [\"baseline\", \"mostrecent120\", \"mostrecent120_10epochs\"]\n",
    "labels = [\"Baseline\", \"Most Recent\\n(120 days)\", \"Most Recent\\n(120 days, 10 epochs)\"]\n",
    "\n",
    "drift_sensitivity = []\n",
    "drift_ppv = []\n",
    "for retraining_type in types:\n",
    "    for i in range(0, 5):\n",
    "        res_path = os.path.join(\n",
    "            PATH, shift, shift + \"_\" + retraining_type + \"_retraining_update.npy\"\n",
    "        )\n",
    "        cum = np.load(res_path, allow_pickle=True)[i]\n",
    "        drift_sensitivity.append(np.mean(cum[\"performance\"][\"rec1\"]))\n",
    "        drift_ppv.append(np.mean(cum[\"performance\"][\"prec1\"]))\n",
    "        # drift_sensitivity.append(np.mean(cum['performance']['rec1'][[i for i,v in enumerate(cum['pval']) if v < 0.05]]))\n",
    "        # drift_ppv.append(np.mean(cum['performance']['prec1'][[i for i,v in enumerate(cum['pval']) if v < 0.05]]))\n",
    "\n",
    "retraining_drift = pd.DataFrame(\n",
    "    {\n",
    "        \"Retraining Strategy\": np.repeat(types, 5),\n",
    "        \"PPV\": drift_ppv,\n",
    "        \"Sensitivity\": drift_sensitivity,\n",
    "    }\n",
    ")\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 4))\n",
    "for j, variable in enumerate([\"PPV\", \"Sensitivity\"]):\n",
    "    for i, grp in enumerate(retraining_drift.groupby(\"Retraining Strategy\")):\n",
    "        axs[j].boxplot(\n",
    "            x=variable, data=grp[1], positions=[i], widths=0.4, patch_artist=True\n",
    "        )\n",
    "        axs[j].set_xticks(range(0, len(types)), labels, rotation=45, fontsize=12)\n",
    "        axs[j].set_ylabel(variable, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97902e7f-d9c4-4c05-81e2-57ba1dde34e0",
   "metadata": {},
   "source": [
    "### Drift Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c58a8e0-e101-4ecc-a1e8-e04fd366cd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "types = [\n",
    "    \"mostrecent120_1epoch_pval0.01\",\n",
    "    \"mostrecent120\",\n",
    "    \"mostrecent120_1epoch_pval0.1\",\n",
    "]\n",
    "labels = [\"P-Val=0.01\", \"P-Val=0.05\", \"P-Val=0.1\"]\n",
    "\n",
    "drift_sensitivity = []\n",
    "drift_ppv = []\n",
    "for retraining_type in types:\n",
    "    for i in range(0, 5):\n",
    "        res_path = os.path.join(\n",
    "            PATH, shift, shift + \"_\" + retraining_type + \"_retraining_update.npy\"\n",
    "        )\n",
    "        cum = np.load(res_path, allow_pickle=True)[i]\n",
    "        drift_sensitivity.append(np.mean(cum[\"performance\"][\"rec1\"]))\n",
    "        drift_ppv.append(np.mean(cum[\"performance\"][\"prec1\"]))\n",
    "        # drift_sensitivity.append(np.mean(cum['performance']['rec1'][[i for i,v in enumerate(cum['pval']) if v < 0.05]]))\n",
    "        # drift_ppv.append(np.mean(cum['performance']['prec1'][[i for i,v in enumerate(cum['pval']) if v < 0.05]]))\n",
    "\n",
    "retraining_drift = pd.DataFrame(\n",
    "    {\n",
    "        \"Retraining Strategy\": np.repeat(types, 5),\n",
    "        \"PPV\": drift_ppv,\n",
    "        \"Sensitivity\": drift_sensitivity,\n",
    "    }\n",
    ")\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 4))\n",
    "for j, variable in enumerate([\"PPV\", \"Sensitivity\"]):\n",
    "    for i, grp in enumerate(retraining_drift.groupby(\"Retraining Strategy\")):\n",
    "        axs[j].boxplot(\n",
    "            x=variable, data=grp[1], positions=[i], widths=0.4, patch_artist=True\n",
    "        )\n",
    "        axs[j].set_xticks(range(0, len(types)), labels, rotation=45, fontsize=12)\n",
    "        axs[j].set_ylabel(variable, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92f0a10-92fb-479d-a626-c5a28dbf88b8",
   "metadata": {},
   "source": [
    "## Relationship between Performance and Drift P-Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ea7822-b83a-41ee-9bc4-394eb13b296b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Pearson's correlation\n",
    "pcorr, pcorr_pval = pearsonr(results[\"prec1\"], results[\"pval\"])\n",
    "print(\"Pearsons correlation: %.3f P-Value: %.3f\" % (pcorr, pcorr_pval))\n",
    "# calculate spearman's correlation\n",
    "scorr, scorr_pval = spearmanr(results[\"prec1\"], results[\"pval\"])\n",
    "print(\"Spearmans correlation: %.3f P-Value: %.3f\" % (scorr, scorr_pval))\n",
    "# plot\n",
    "plt.scatter(results[\"prec1\"], results[\"pval\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115e6398-411d-4c69-8770-9c76f30f3da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Pearson's correlation\n",
    "pcorr, pcorr_pval = pearsonr(results[\"rec1\"], results[\"pval\"])\n",
    "print(\"Pearsons correlation: %.3f P-Value: %.3f\" % (pcorr, pcorr_pval))\n",
    "# calculate spearman's correlation\n",
    "scorr, scorr_pval = spearmanr(results[\"rec1\"], results[\"pval\"])\n",
    "print(\"Spearmans correlation: %.3f P-Value: %.3f\" % (scorr, scorr_pval))\n",
    "# plot\n",
    "plt.scatter(results[\"rec1\"], results[\"pval\"])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyclops-KKtuQLwg-py3.9",
   "language": "python",
   "name": "cyclops-kktuqlwg-py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

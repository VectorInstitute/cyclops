{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a0204ce-4c3e-44d4-ba4e-87700c720acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from alibi_detect.cd import MMDDrift\n",
    "import random\n",
    "from matplotlib.colors import ListedColormap\n",
    "from datetime import date, timedelta\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from utils.utils import *\n",
    "from baseline_models.temporal.pytorch.optimizer import Optimizer\n",
    "from baseline_models.temporal.pytorch.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dc229b2-82b7-45f6-808a-f03b438f09ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/mnt/nfs/project/delirium/drift_exp/JULY-04-2022\"\n",
    "threshold = 0.05\n",
    "num_timesteps = 6\n",
    "stat_window=30\n",
    "lookup_window=30\n",
    "stride=1\n",
    "run=1\n",
    "shift=\"covid\"\n",
    "hospital = [\"SBK\", \"UHNTG\", \"THPC\", \"THPM\", \"UHNTW\", \"SMH\",\"MSH\",\"PMH\"]\n",
    "outcome=\"mortality\"\n",
    "aggregation_type=\"time\"\n",
    "scale=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94627389-7636-4555-a27b-457d3980fad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-18 16:46:57,019 \u001b[1;37mINFO\u001b[0m cyclops.utils.file - Loading dataframe to /mnt/nfs/project/delirium/drift_exp/JULY-04-2022/aggregated_events.parquet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data from aggregated events...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-18 16:46:57,452 \u001b[1;37mINFO\u001b[0m cyclops.utils.file - Loading dataframe to /mnt/nfs/project/delirium/drift_exp/JULY-04-2022/aggmeta_start_ts.parquet\n",
      "2022-07-18 16:46:57,595 \u001b[1;37mINFO\u001b[0m cyclops.feature_handler - Loading features from file...\n",
      "2022-07-18 16:46:57,599 \u001b[1;37mINFO\u001b[0m cyclops.feature_handler - Found file to load for static features...\n",
      "2022-07-18 16:46:57,600 \u001b[1;37mINFO\u001b[0m cyclops.feature_handler - Successfully loaded static features from file...\n",
      "2022-07-18 16:46:57,708 \u001b[1;37mINFO\u001b[0m cyclops.feature_handler - Found file to load for temporal features...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data from feature handler...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-18 16:47:02,949 \u001b[1;37mINFO\u001b[0m cyclops.feature_handler - Successfully loaded temporal features from file...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data from admin data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-18 16:47:11,595 \u001b[1;37mINFO\u001b[0m cyclops.utils.file - Loading dataframe to /mnt/nfs/project/delirium/drift_exp/JULY-04-2022/aggmeta_end_ts.parquet\n",
      "2022-07-18 16:47:31,487 \u001b[1;37mINFO\u001b[0m cyclops.feature_handler - Loading features from file...\n",
      "2022-07-18 16:47:31,490 \u001b[1;37mINFO\u001b[0m cyclops.feature_handler - Found file to load for static features...\n",
      "2022-07-18 16:47:31,491 \u001b[1;37mINFO\u001b[0m cyclops.feature_handler - Successfully loaded static features from file...\n",
      "2022-07-18 16:47:31,597 \u001b[1;37mINFO\u001b[0m cyclops.feature_handler - Found file to load for temporal features...\n",
      "2022-07-18 16:47:36,370 \u001b[1;37mINFO\u001b[0m cyclops.feature_handler - Successfully loaded temporal features from file...\n"
     ]
    }
   ],
   "source": [
    "admin_data, x, y = get_gemini_data(PATH)\n",
    "\n",
    "numerical_cols = get_numerical_cols(PATH)\n",
    "for col in numerical_cols:\n",
    "    scaler = StandardScaler().fit(x[col].values.reshape(-1, 1))\n",
    "    x[col] = pd.Series(\n",
    "        np.squeeze(scaler.transform(x[col].values.reshape(-1, 1))),\n",
    "        index=x[col].index,\n",
    "    )\n",
    "X = reshape_inputs(x, num_timesteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3508a128-d17a-4601-b97e-18628c9bdee2",
   "metadata": {},
   "source": [
    "## Set constant reference distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb25fc74-11f8-4ff7-89dc-93b5e5164d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_val, y_val), (x_test, y_test), feats, orig_dims, admin_data = import_dataset_hospital(admin_data, x, y, shift, outcome, hospital, run, shuffle=True)\n",
    "\n",
    "random.seed(1)\n",
    "\n",
    "# Normalize data\n",
    "(X_tr_normalized, y_tr),(X_val_normalized, y_val), (X_t_normalized, y_t) = normalize_data(aggregation_type, admin_data, num_timesteps, x_train, y_train, x_val, y_val, x_test, y_test)\n",
    "# Scale data\n",
    "if scale:\n",
    "    X_tr_normalized, X_val_normalized, X_t_normalized = scale_data(numerical_cols, X_tr_normalized, X_val_normalized, X_t_normalized)\n",
    "# Process data\n",
    "X_tr_final, X_val_final, X_t_final = process_data(aggregation_type, num_timesteps, X_tr_normalized, X_val_normalized, X_t_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875c1032-4b87-4c8b-bc89-ffcc311259c0",
   "metadata": {},
   "source": [
    "## Create Data Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4213b586-46d5-4607-ae79-7a262e252ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-01 - 2019-01-02\n",
      "2020-01-01 - 2020-01-02\n"
     ]
    }
   ],
   "source": [
    "#####################################################\n",
    "## a given date contains data from previous two weeks \n",
    "#####################################################\n",
    "\n",
    "start_date = date(2019, 1, 1)\n",
    "end_date = date(2020, 8, 1)\n",
    "\n",
    "def daterange(start_date, end_date, stride, window):\n",
    "    for n in range(int((end_date - start_date).days)):\n",
    "        if start_date + timedelta(n*stride+window) < end_date:\n",
    "            yield start_date+ timedelta(n*stride)\n",
    "            \n",
    "\n",
    "def get_streams(x, y, admin_data, start_date, end_date, stride, window, ids_to_exclude=None):\n",
    "    target_stream_x = []\n",
    "    target_stream_y = [] \n",
    "    measure_dates = []\n",
    "\n",
    "    admit_df = admin_data[[ENCOUNTER_ID,ADMIT_TIMESTAMP]].sort_values(by=ADMIT_TIMESTAMP)\n",
    "    for single_date in daterange(start_date, end_date, stride, window):\n",
    "        if single_date.month ==1 and single_date.day == 1:\n",
    "            print(single_date.strftime(\"%Y-%m-%d\"),\"-\",(single_date+timedelta(days=window)).strftime(\"%Y-%m-%d\"))\n",
    "        encounters_inwindow = admit_df.loc[((single_date+timedelta(days=window)).strftime(\"%Y-%m-%d\") > admit_df[ADMIT_TIMESTAMP].dt.strftime(\"%Y-%m-%d\")) \n",
    "                           & (admit_df[ADMIT_TIMESTAMP].dt.strftime(\"%Y-%m-%d\") >= single_date.strftime(\"%Y-%m-%d\")), ENCOUNTER_ID].unique()\n",
    "        if ids_to_exclude:\n",
    "            encounters_inwindow = [x for x in encounters_inwindow if x not in ids_to_exclude]\n",
    "        encounter_ids = x.index.get_level_values(0).unique()\n",
    "        x_inwindow = x.loc[x.index.get_level_values(0).isin(encounters_inwindow)]\n",
    "        y_inwindow = pd.DataFrame(y[np.in1d(encounter_ids, encounters_inwindow)])\n",
    "        if not x_inwindow.empty:\n",
    "            target_stream_x.append(x_inwindow)\n",
    "            target_stream_y.append(y_inwindow)\n",
    "            measure_dates.append((single_date+timedelta(days=window)).strftime(\"%Y-%m-%d\"))\n",
    "    return(target_stream_x, target_stream_y, measure_dates)\n",
    "\n",
    "val_ids=list(X_val_normalized.index.get_level_values(0))\n",
    "x_test_stream, y_test_stream, measure_dates_test = get_streams(x, y, admin_data, start_date, end_date, stride=1, window=1, val_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8fcfb0-9637-4eb9-a1e1-4e4463ba537a",
   "metadata": {},
   "source": [
    "## Rolling Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3547994e-dab9-4ade-864b-97c1d0f4e49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_technique=\"NoRed\"\n",
    "model_path=os.path.join(os.getcwd(),\"../../saved_models/covid_lstm.pt\")\n",
    "md_test=\"Context-Aware MMD\"\n",
    "sign_level=0.05\n",
    "sample=1000\n",
    "dataset=\"gemini\"\n",
    "context_type=\"lstm\"\n",
    "representation=None\n",
    "\n",
    "shift_reductor = ShiftReductor(\n",
    "    X_tr_final, y_tr, dr_technique, orig_dims, dataset, var_ret=0.8, model_path=model_path,\n",
    ")\n",
    "# Get shift detector\n",
    "shift_detector = ShiftDetector(\n",
    "    dr_technique, md_test, sign_level, shift_reductor, sample, dataset, feats, model_path, context_type, representation,\n",
    ")\n",
    "            \n",
    "#####################################################\n",
    "## rolling window - not cumulatively including data and no adjustment made when drift occurs\n",
    "##################################################### \n",
    "def rolling_window(X_train, X_stream, shift_detector, sample, stat_window, lookup_window, stride, num_timesteps, threshold, custom_ref=None):\n",
    "\n",
    "    p_vals = np.asarray([])\n",
    "    dist_vals = np.asarray([])\n",
    "    i = 0 \n",
    "\n",
    "    if custom_ref is not None:\n",
    "        X_prev = custom_ref\n",
    "    \n",
    "    while i+stat_window+lookup_window < len(X_stream):\n",
    "        feat_index = 0\n",
    "        \n",
    "        if custom_ref is None:\n",
    "            X_prev = pd.concat(X_stream[i:i+stat_window])\n",
    "            X_prev = X_prev[~X_prev.index.duplicated(keep='first')]\n",
    "            \n",
    "        X_next = pd.concat(X_stream[i+lookup_window:i+lookup_window+stat_window])\n",
    "        X_next = X_next[~X_next.index.duplicated(keep='first')]\n",
    "        X_next = reshape_inputs(X_next, num_timesteps)\n",
    "       \n",
    "        if X_next.shape[0]<=2 or X_prev.shape[0]<=2:\n",
    "            break\n",
    "        \n",
    "        (p_val, dist, val_acc, te_acc) = shift_detector.detect_data_shift(X_train, \n",
    "                                                                          X_prev, \n",
    "                                                                          X_next[:sample,:], \n",
    "                                                                          orig_dims,\n",
    "        )\n",
    "        \n",
    "        if p_val < threshold:\n",
    "            print(\"P-value below threshold.\")\n",
    "            print(\"Ref -->\",i+lookup_window,\"-\",i+stat_window+lookup_window,\"\\tP-Value: \",p_val)\n",
    "        dist_vals = np.concatenate((dist_vals, np.repeat(dist, 1)))\n",
    "        p_vals = np.concatenate((p_vals, np.repeat(p_val, 1)))\n",
    "        i += stride\n",
    "    return dist_vals, p_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbcfaf8-4e44-4eea-8346-1c6b3fb3ae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_vals_test_covid, p_vals_test_covid = rolling_window(X_tr_final, x_test_stream, shift_detector, sample, stat_window, lookup_window, stride, num_timesteps, threshold, X_val_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b89d94a-1c75-4489-b819-a78fa841727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = len(p_vals_test_covid)\n",
    "measure_dates_test_covid = [(datetime.datetime.strptime(date,\"%Y-%m-%d\")+datetime.timedelta(days=lookup_window+stat_window*2)).strftime(\"%Y-%m-%d\") for date in measure_dates_test]\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20,8))\n",
    "fig.suptitle('Rolling Windowing')\n",
    "\n",
    "threshold=0.000001\n",
    "results = percentile_list = pd.DataFrame(\n",
    "    {'dates': measure_dates_test_covid[1:end],\n",
    "     'p_val_val': p_vals_test_covid[1:end],\n",
    "     'dist metric_val': dist_vals_test_covid[1:end],\n",
    "     'detection': np.where(p_vals_test_covid[1:end]<threshold,1,0)\n",
    "    })\n",
    "\n",
    "\n",
    "cmap = ListedColormap(['lightgrey','red'])\n",
    "ax1.plot(measure_dates_test_covid[1:end], p_vals_test_covid[1:end], '.-', color=\"red\")\n",
    "ax1.set_xlim(measure_dates_test_covid[1],measure_dates_test_covid[end])\n",
    "ax1.axhline(y=0.05, color='black', linestyle='--')\n",
    "ax1.set_ylabel('P-Values')\n",
    "ax1.set_xticklabels([])\n",
    "ax1.pcolorfast(ax1.get_xlim(), ax1.get_ylim(),results['detection'].values[np.newaxis], cmap = cmap, alpha = 0.4)\n",
    "        \n",
    "ax2.plot(measure_dates_test_covid[1:end], dist_vals_test_covid[1:end], '.-',color=\"blue\")\n",
    "ax2.set_xlim(measure_dates_test_covid[1],measure_dates_test_covid[end])\n",
    "ax2.set_xlabel('time (s)')\n",
    "ax2.set_ylabel('Distance Metric')\n",
    "ax2.tick_params(axis='x', labelrotation=45)\n",
    "ax2.pcolorfast(ax2.get_xlim(), ax2.get_ylim(),results['detection'].values[np.newaxis], cmap = cmap, alpha = 0.4)\n",
    "for index, label in enumerate(ax2.xaxis.get_ticklabels()):\n",
    "    if index % 28 != 0:\n",
    "        label.set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfa1dee-dce1-461e-958c-7870e4050984",
   "metadata": {},
   "source": [
    "## Rolling window prediction performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a1d71e-19f8-4d70-bd65-c4c4f7e3124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from drift_detection.baseline_models.temporal.pytorch.optimizer import Optimizer\n",
    "from drift_detection.baseline_models.temporal.pytorch.utils import *\n",
    "\n",
    "output_dim = 1\n",
    "batch_size = 64\n",
    "input_dim = X_tr_final.shape[2]\n",
    "timesteps = X_tr_final.shape[1]\n",
    "hidden_dim = 64\n",
    "layer_dim = 2\n",
    "dropout = 0.2\n",
    "n_epochs = 256\n",
    "learning_rate = 2e-3\n",
    "weight_decay = 1e-6\n",
    "last_timestep_only = False\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "model_params = {\n",
    "    \"device\": device,\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"layer_dim\": layer_dim,\n",
    "    \"output_dim\": output_dim,\n",
    "    \"dropout_prob\": dropout,\n",
    "    \"last_timestep_only\": last_timestep_only,\n",
    "}\n",
    "\n",
    "model = get_temporal_model(\"lstm\", model_params).to(device)\n",
    "model_path=os.path.join(os.getcwd(),\"../../saved_models/covid_lstm.pt\")\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "loss_fn = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "optimizer = optim.Adagrad(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=weight_decay\n",
    ")\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=128, gamma=0.5)\n",
    "activation = nn.Sigmoid()\n",
    "opt = Optimizer(\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    activation=activation,\n",
    "    lr_scheduler=lr_scheduler,\n",
    ")\n",
    "\n",
    "#####################################################\n",
    "## rolling window - not cumulatively including data and no adjustment made when drift occurs\n",
    "##################################################### \n",
    "def rolling_window_performance(X_stream, y_stream, opt, sample, stat_window, lookup_window, stride, num_timesteps, threshold, custom_ref=None):\n",
    "    auroc = np.asarray([])\n",
    "    accuracy = np.asarray([])\n",
    "    auprc = np.asarray([])\n",
    "    \n",
    "    i = 0 \n",
    "\n",
    "    if custom_ref is not None:\n",
    "        X_prev = custom_ref\n",
    "    \n",
    "    while i+stat_window+lookup_window < len(X_stream):\n",
    "        feat_index = 0\n",
    "        \n",
    "        if custom_ref is None:\n",
    "            X_prev = pd.concat(X_stream[i:i+stat_window])\n",
    "            X_prev = X_prev[~X_prev.index.duplicated(keep='first')]\n",
    "            \n",
    "        X_next = pd.concat(X_stream[i+lookup_window:i+lookup_window+stat_window])\n",
    "        X_next = X_next[~X_next.index.duplicated(keep='first')]\n",
    "        X_next = reshape_inputs(X_next, num_timesteps)\n",
    "        \n",
    "        y_next = pd.concat(y_stream[i+lookup_window:i+lookup_window+stat_window])\n",
    "        y_next = y_next[~y_next.index.duplicated(keep='first')].to_numpy()\n",
    "       \n",
    "        if X_next.shape[0]<=2 or X_prev.shape[0]<=2:\n",
    "            break\n",
    "        \n",
    "        test_dataset = get_data(X_next, y_next)\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "        y_test_labels, y_pred_values, y_pred_labels = opt.evaluate(\n",
    "            test_loader, batch_size=1, n_features=input_dim, timesteps=num_timesteps\n",
    "        )\n",
    "\n",
    "        y_pred_values = y_pred_values[y_test_labels != -1]\n",
    "        y_pred_labels = y_pred_labels[y_test_labels != -1]\n",
    "        y_test_labels = y_test_labels[y_test_labels != -1]\n",
    "\n",
    "        pred_metrics = print_metrics_binary(y_test_labels, y_pred_values, y_pred_labels, verbose=0)\n",
    "        auroc = np.concatenate((auroc, np.repeat(pred_metrics[\"auroc\"], 1)))\n",
    "        accuracy = np.concatenate((accuracy, np.repeat(pred_metrics[\"acc\"], 1)))\n",
    "        auprc = np.concatenate((auprc, np.repeat(pred_metrics[\"auprc\"], 1)))\n",
    "        \n",
    "        i += stride\n",
    "            \n",
    "    return auroc, auprc, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37651b2c-3c16-469d-a6b7-897932cab2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc_test_covid, auprc_test_covid, accuracy_test_covid = rolling_window_performance(x_test_stream, y_test_stream, opt, sample, stat_window, lookup_window, stride, num_timesteps, threshold, X_val_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371b47d0-eec9-482f-a702-5b44cd633f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = len(p_vals_test_covid)\n",
    "measure_dates_test_covid = [(datetime.datetime.strptime(date,\"%Y-%m-%d\")+datetime.timedelta(days=lookup_window+stat_window*2)).strftime(\"%Y-%m-%d\") for date in measure_dates_test]\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(22,12))\n",
    "results = percentile_list = pd.DataFrame(\n",
    "    {'dates': measure_dates_test_covid[1:end],\n",
    "     'p_val_val': p_vals_test_covid[1:end],\n",
    "     'auroc_val': auroc_test_covid[1:end],\n",
    "     'auprc_val': auprc_test_covid[1:end],\n",
    "     'accuracy_val': accuracy_test_covid[1:end],\n",
    "     'detection': np.where(p_vals_test_covid[1:end]<threshold,1,0)\n",
    "    })\n",
    "\n",
    "\n",
    "cmap = ListedColormap(['lightgrey','red'])\n",
    "ax1.plot(measure_dates_test_covid[1:end], p_vals_test_covid[1:end], '.-', color=\"red\", linewidth=0.5, markersize=2)\n",
    "ax1.set_xlim(measure_dates_test_covid[1],measure_dates_test_covid[end])\n",
    "ax1.axhline(y=0.05, color='dimgrey', linestyle='--')\n",
    "ax1.set_ylabel('P-Values',fontsize=16)\n",
    "ax1.set_xticklabels([])\n",
    "ax1.pcolorfast(ax1.get_xlim(), ax1.get_ylim(),results['detection'].values[np.newaxis], cmap = cmap, alpha = 0.4)\n",
    "  \n",
    "ax2.plot(measure_dates_test_covid[1:end], dist_vals_test_covid[1:end], '.-',color=\"red\", linewidth=0.5, markersize=2)\n",
    "ax2.set_xlim(measure_dates_test_covid[1],measure_dates_test_covid[end])\n",
    "ax2.set_ylabel('Distance',fontsize=16)\n",
    "ax2.axhline(y=np.mean(dist_vals_test_covid), color='dimgrey', linestyle='--')\n",
    "ax2.set_xticklabels([])\n",
    "ax2.pcolorfast(ax2.get_xlim(), ax2.get_ylim(),results['detection'].values[np.newaxis], cmap = cmap, alpha = 0.4)\n",
    "\n",
    "\n",
    "ax3.plot(measure_dates_test_covid[1:end], auroc_test_covid[1:end], '.-',color=\"blue\", linewidth=0.5, markersize=2)\n",
    "ax3.set_xlim(measure_dates_test_covid[1],measure_dates_test_covid[end])\n",
    "ax3.set_ylabel('AuRoc', fontsize=16)\n",
    "ax3.axhline(y=np.mean(auroc_test_covid), color='dimgrey', linestyle='--')\n",
    "ax3.set_xticklabels([])\n",
    "ax3.pcolorfast(ax3.get_xlim(), ax3.get_ylim(),results['detection'].values[np.newaxis], cmap = cmap, alpha = 0.4)\n",
    "\n",
    "ax4.plot(measure_dates_test_covid[1:end], auprc_test_covid[1:end], '.-',color=\"blue\", linewidth=0.5, markersize=2)\n",
    "ax4.set_xlim(measure_dates_test_covid[1],measure_dates_test_covid[end])\n",
    "ax4.set_ylabel('AuPrc',fontsize=16)\n",
    "ax4.set_xlabel('time (s)', fontsize=16)\n",
    "ax4.axhline(y=np.mean(auprc_test_covid), color='dimgrey', linestyle='--')\n",
    "ax4.set_xticklabels([])\n",
    "ax4.pcolorfast(ax4.get_xlim(), ax4.get_ylim(),results['detection'].values[np.newaxis], cmap = cmap, alpha = 0.4)\n",
    "\n",
    "for index, label in enumerate(ax4.xaxis.get_ticklabels()):\n",
    "    if index % 28 != 0:\n",
    "        label.set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyclops-KKtuQLwg-py3.9",
   "language": "python",
   "name": "cyclops-kktuqlwg-py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11504cf1-e260-41ab-8854-79df66acd092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from baseline_models.temporal.pytorch.optimizer import Optimizer\n",
    "from baseline_models.temporal.pytorch.utils import *\n",
    "from drift_detector.rolling_window import *\n",
    "from gemini.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cff9cf-c682-4973-ab27-1161b70d516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/mnt/nfs/project/delirium/drift_exp/JULY-04-2022\"\n",
    "threshold = 0.05\n",
    "num_timesteps = 6\n",
    "run = 1\n",
    "shift = \"simulated_deployment\"\n",
    "hospital = [\"SBK\", \"UHNTG\", \"THPC\", \"THPM\", \"UHNTW\", \"SMH\", \"MSH\", \"PMH\"]\n",
    "outcome = \"mortality\"\n",
    "aggregation_type = \"time\"\n",
    "scale = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93113177-c6d6-44af-9f74-0c043c781416",
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_data, x, y = get_gemini_data(PATH)\n",
    "x = scale_temporal_data(x)\n",
    "X = reshape_inputs(x, num_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d91c48-3b72-4510-bfbe-82f70193090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    (x_train, y_train),\n",
    "    (x_val, y_val),\n",
    "    (x_test, y_test),\n",
    "    feats,\n",
    "    admin_data,\n",
    ") = import_dataset_hospital(\n",
    "    admin_data, x, y, shift, outcome, hospital, run, shuffle=True\n",
    ")\n",
    "\n",
    "random.seed(1)\n",
    "\n",
    "# Normalize data\n",
    "(\n",
    "    (X_tr_normalized, y_tr),\n",
    "    (X_val_normalized, y_val),\n",
    "    (X_t_normalized, y_t),\n",
    ") = normalize_data(\n",
    "    aggregation_type,\n",
    "    admin_data,\n",
    "    num_timesteps,\n",
    "    x_train,\n",
    "    y_train,\n",
    "    x_val,\n",
    "    y_val,\n",
    "    x_test,\n",
    "    y_test,\n",
    ")\n",
    "# Scale data\n",
    "if scale:\n",
    "    X_tr_normalized, X_val_normalized, X_t_normalized = scale_data(\n",
    "        numerical_cols, X_tr_normalized, X_val_normalized, X_t_normalized\n",
    "    )\n",
    "# Process data\n",
    "X_tr_final, X_val_final, X_t_final = process_data(\n",
    "    aggregation_type, num_timesteps, X_tr_normalized, X_val_normalized, X_t_normalized\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0a5be5-e6e5-48da-aa6a-94511b907a69",
   "metadata": {},
   "source": [
    "## Create Data Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950b8746-7262-489e-bd31-c4e381900525",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = date(2019, 1, 1)\n",
    "end_date = date(2020, 8, 1)\n",
    "\n",
    "val_ids = list(X_val_normalized.index.get_level_values(0).unique())\n",
    "\n",
    "x_test_stream, y_test_stream, measure_dates_test = get_streams(\n",
    "    x, y, admin_data, start_date, end_date, stride=1, window=1, ids_to_exclude=val_ids\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6b18be-663a-42fc-a4c6-056e2be2fe7a",
   "metadata": {},
   "source": [
    "## Dynamic Rolling Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61f657a-4e2b-4933-ad74-c91bd69b9292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rolling window parameters\n",
    "threshold = 0.05\n",
    "num_timesteps = 6\n",
    "stat_window = 30\n",
    "retrain_window = 120\n",
    "lookup_window = 0\n",
    "stride = 1\n",
    "model_name = \"rnn\"\n",
    "retrain = \"update\"\n",
    "\n",
    "# model parameters\n",
    "output_dim = 1\n",
    "batch_size = 64\n",
    "input_dim = 108\n",
    "timesteps = 6\n",
    "hidden_dim = 64\n",
    "layer_dim = 2\n",
    "dropout = 0.2\n",
    "learning_rate = 2e-3\n",
    "weight_decay = 1e-6\n",
    "last_timestep_only = False\n",
    "device = get_device()\n",
    "model_params = {\n",
    "    \"device\": device,\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"layer_dim\": layer_dim,\n",
    "    \"output_dim\": output_dim,\n",
    "    \"dropout_prob\": dropout,\n",
    "    \"last_timestep_only\": last_timestep_only,\n",
    "}\n",
    "\n",
    "# drift detector parameters\n",
    "dr_technique = \"BBSDs_trained_LSTM\"\n",
    "model_path = os.path.join(os.getcwd(), \"../../saved_models/\" + shift + \"_lstm.pt\")\n",
    "md_test = \"MMD\"\n",
    "sign_level = 0.05\n",
    "sample = 100\n",
    "dataset = \"gemini\"\n",
    "context_type = \"rnn\"\n",
    "representation = \"rnn\"\n",
    "\n",
    "# Get shift reductor\n",
    "shift_reductor = ShiftReductor(\n",
    "    X_tr_final,\n",
    "    y_tr,\n",
    "    dr_technique,\n",
    "    dataset,\n",
    "    var_ret=0.8,\n",
    "    model_path=model_path,\n",
    ")\n",
    "# Get shift detector\n",
    "shift_detector = ShiftDetector(\n",
    "    dr_technique,\n",
    "    md_test,\n",
    "    sign_level,\n",
    "    shift_reductor,\n",
    "    sample,\n",
    "    dataset,\n",
    "    feats,\n",
    "    model_path,\n",
    "    context_type,\n",
    "    representation,\n",
    ")\n",
    "\n",
    "if model_name == \"rnn\":\n",
    "    model = get_temporal_model(\"lstm\", model_params).to(device)\n",
    "\n",
    "    if retrain == \"update\":\n",
    "        checkpoint_fpath = os.path.join(\n",
    "            os.getcwd(), \"../../saved_models/\", shift + \"_lstm.pt\"\n",
    "        )\n",
    "        model, opt, n_epochs = load_ckp(checkpoint_fpath, model)\n",
    "        n_epochs = 1\n",
    "    else:\n",
    "        n_epochs = 64\n",
    "        loss_fn = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "        optimizer = optim.Adagrad(\n",
    "            model.parameters(), lr=learning_rate, weight_decay=weight_decay\n",
    "        )\n",
    "        lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=128, gamma=0.5)\n",
    "        activation = nn.Sigmoid()\n",
    "        opt = Optimizer(\n",
    "            model=model,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            activation=activation,\n",
    "            lr_scheduler=lr_scheduler,\n",
    "        )\n",
    "if model_name == \"gbt\":\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "retrain_parameters = {\n",
    "    \"stat_window\": stat_window,\n",
    "    \"retrain_window\": retrain_window,\n",
    "    \"stride\": stride,\n",
    "    \"drift_threshold\": drift_threshold,\n",
    "    \"retrain_type\": retrain_type,\n",
    "    \"sample\": sample,\n",
    "    \"verbose\": verbose,\n",
    "    \"shift_detector\": shift_detector,\n",
    "}\n",
    "\n",
    "model_parameters = {\n",
    "    \"model_name\": model_name,\n",
    "    \"model\": model,\n",
    "    \"optimizer\": optimizer,\n",
    "    \"num_timesteps\": num_timesteps,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"n_epochs\": n_epochs,\n",
    "    \"input_dim\": input_dim,\n",
    "}\n",
    "\n",
    "data_parameters = {\n",
    "    \"X_train\": X_train,\n",
    "    \"X_val\": X_val,\n",
    "    \"y_val\": y_val,\n",
    "    \"X_test\": X_test_stream,\n",
    "    \"y_test\": y_test_stream,\n",
    "}\n",
    "\n",
    "#####################################################\n",
    "## dynamically adjusting drift detector - if drift is significant, reference dataset is reset to current time\n",
    "#####################################################\n",
    "\n",
    "\n",
    "def dynamic_rolling_window(retrain_parameters, model_parameters, data_parameters):\n",
    "\n",
    "    p_vals = []\n",
    "    dist_vals = []\n",
    "    rolling_metrics = []\n",
    "    run_length = retrain_parameters[\"stat_window\"]\n",
    "    i = retrain_parameters[\"stat_window\"]\n",
    "    p_val = 1\n",
    "    val_dataset = get_data(data_parameters[\"X_val\"], data_parameters[\"y_val\"])\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=model_parameters[\"batch_size\"], shuffle=False\n",
    "    )\n",
    "    X_ref = data_parameters[\"X_val\"]\n",
    "\n",
    "    while i + retrain_parameters[\"stat_window\"] + retrain_parameters[\n",
    "        \"lookup_window\"\n",
    "    ] <= len(data_parameters[\"X_test\"]):\n",
    "        feat_index = 0\n",
    "\n",
    "        if p_val < retrain_parameters[\"drift_threshold\"]:\n",
    "\n",
    "            if retrain_parameters[\"retrain_type\"] is not None:\n",
    "                X_update = pd.concat(\n",
    "                    data_parameters[\"X_test\"][max(int(i) - run_length, 0) : int(i)]\n",
    "                )\n",
    "                X_update = X_update[~X_update.index.duplicated(keep=\"first\")]\n",
    "                ind = X_update.index.get_level_values(0).unique()\n",
    "                X_update = reshape_inputs(X_update, model_parameters[\"num_timesteps\"])\n",
    "\n",
    "                ## Get updated source data for two-sample test (including data for retraining)\n",
    "                X_ref = np.concatenate((X_ref, X_update), axis=0)\n",
    "                tups = [tuple(row) for row in X_ref]\n",
    "                X_ref = np.unique(tups, axis=0)\n",
    "                np.random.shuffle(X_ref)\n",
    "\n",
    "                y_update = pd.concat(y_stream[max(int(i) - run_length, 0) : int(i)])\n",
    "                y_update.index = ind\n",
    "                y_update = y_update[~y_update.index.duplicated(keep=\"first\")].to_numpy()\n",
    "\n",
    "                if verbose:\n",
    "                    print(\n",
    "                        \"Retrain \",\n",
    "                        model_parameters[\"model_name\"],\n",
    "                        \" on: \",\n",
    "                        max(int(i) - run_length, 0),\n",
    "                        \"-\",\n",
    "                        int(i),\n",
    "                    )\n",
    "\n",
    "                if model_parameters[\"model_name\"] == \"rnn\":\n",
    "                    ## create train loader\n",
    "                    update_dataset = get_data(X_update, y_update)\n",
    "                    update_loader = torch.utils.data.DataLoader(\n",
    "                        update_dataset,\n",
    "                        batch_size=model_parameters[\"batch_size\"],\n",
    "                        shuffle=False,\n",
    "                    )\n",
    "\n",
    "                    retrain_model_path = (\n",
    "                        \"mostrecent120_1epoch_n100_window_retrain.model\"\n",
    "                    )\n",
    "\n",
    "                    ## train\n",
    "                    opt.train(\n",
    "                        update_loader,\n",
    "                        val_loader,\n",
    "                        batch_size=model_parameters[\"batch_size\"],\n",
    "                        n_epochs=model_parameters[\"n_epochs\"],\n",
    "                        n_features=model_parameters[\"input_dim\"],\n",
    "                        timesteps=model_parameters[\"num_timesteps\"],\n",
    "                        model_path=retrain_model_path,\n",
    "                    )\n",
    "\n",
    "                    model.load_state_dict(torch.load(retrain_model_path))\n",
    "                    opt.model = model\n",
    "                    shift_detector.model_path = retrain_model_path\n",
    "\n",
    "                elif model_parameters[\"model_name\"] == \"gbt\":\n",
    "                    model = model.fit(\n",
    "                        X_retrain, y_retrain, xgb_model=model.get_booster()\n",
    "                    )\n",
    "\n",
    "                else:\n",
    "                    print(\"Invalid Model Name\")\n",
    "\n",
    "            i += retrain_parameters[\"stride\"]\n",
    "\n",
    "        X_next = pd.concat(\n",
    "            data_parameters[\"X_test\"][\n",
    "                max(int(i) + retrain_parameters[\"lookup_window\"], 0) : int(i)\n",
    "                + retrain_parameters[\"stat_window\"]\n",
    "                + retrain_parameters[\"lookup_window\"]\n",
    "            ]\n",
    "        )\n",
    "        X_next = X_next[~X_next.index.duplicated(keep=\"first\")]\n",
    "        next_ind = X_next.index.get_level_values(0).unique()\n",
    "        X_next = reshape_inputs(X_next, model_parameters[\"num_timesteps\"])\n",
    "\n",
    "        y_next = pd.concat(\n",
    "            data_parameters[\"y_test\"][\n",
    "                max(int(i) + retrain_parameters[\"lookup_window\"], 0) : int(i)\n",
    "                + retrain_parameters[\"stat_window\"]\n",
    "                + retrain_parameters[\"lookup_window\"]\n",
    "            ]\n",
    "        )\n",
    "        y_next.index = next_ind\n",
    "        y_next = y_next[~y_next.index.duplicated(keep=\"first\")].to_numpy()\n",
    "\n",
    "        if X_next.shape[0] <= 2 or X_ref.shape[0] <= 2:\n",
    "            break\n",
    "\n",
    "        ## Check Performance\n",
    "        test_dataset = get_data(X_next, y_next)\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            test_dataset, batch_size=1, shuffle=False\n",
    "        )\n",
    "        y_test_labels, y_pred_values, y_pred_labels = model_parameters[\n",
    "            \"optimizer\"\n",
    "        ].evaluate(\n",
    "            test_loader,\n",
    "            batch_size=1,\n",
    "            n_features=model_parameters[\"input_dim\"],\n",
    "            timesteps=model_parameters[\"num_timesteps\"],\n",
    "        )\n",
    "        assert y_test_labels.shape == y_pred_labels.shape == y_pred_values.shape\n",
    "        y_pred_values = y_pred_values[y_test_labels != -1]\n",
    "        y_pred_labels = y_pred_labels[y_test_labels != -1]\n",
    "        y_test_labels = y_test_labels[y_test_labels != -1]\n",
    "        pred_metrics = print_metrics_binary(\n",
    "            y_test_labels, y_pred_values, y_pred_labels, verbose=0\n",
    "        )\n",
    "        rolling_metrics.append(\n",
    "            pd.DataFrame(pred_metrics.values(), index=pred_metrics.keys()).T\n",
    "        )\n",
    "\n",
    "        ## Detect Distribution Shift\n",
    "        (p_val, dist, val_acc, te_acc) = retrain_parameters[\n",
    "            \"shift_detector\"\n",
    "        ].detect_data_shift(\n",
    "            data_parameters[\"X_train\"],\n",
    "            X_ref[:1000, :],\n",
    "            X_next[: retrain_parameters[\"sample\"], :],\n",
    "        )\n",
    "\n",
    "        if retrain_parameters[\"verbose\"]:\n",
    "            print(\n",
    "                \"Drift on \",\n",
    "                max(int(i) + retrain_parameters[\"lookup_window\"], 0),\n",
    "                \"-\",\n",
    "                int(i)\n",
    "                + retrain_parameters[\"stat_window\"]\n",
    "                + retrain_parameters[\"lookup_window\"],\n",
    "                \" P-Value: \",\n",
    "                p_val,\n",
    "            )\n",
    "\n",
    "        dist_vals.append(dist)\n",
    "        p_vals.append(p_val)\n",
    "\n",
    "        if p_val >= retrain_parameters[\"drift_threshold\"]:\n",
    "            run_length += retrain_parameters[\"stride\"]\n",
    "            i += retrain_parameters[\"stride\"]\n",
    "        else:\n",
    "            run_length = retrain_parameters[\"retrain_window\"]\n",
    "\n",
    "    rolling_metrics = pd.concat(rolling_metrics).reset_index(drop=True)\n",
    "\n",
    "    return dist_vals, p_vals, rolling_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034bf954-071b-4cdd-a2f8-0b38880e290a",
   "metadata": {},
   "source": [
    "## Run retraining experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f739d2-ae18-438d-bd69-e714813c8ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs = []\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "for i in range(0, 5):\n",
    "    np.random.seed(1)\n",
    "    random.seed(1)\n",
    "    dist_test, pvals_test, performance_metrics, total_alarms = dynamic_rolling_window(\n",
    "        X_tr_final,\n",
    "        x_test_stream,\n",
    "        y_test_stream,\n",
    "        shift_detector,\n",
    "        sample,\n",
    "        stat_window,\n",
    "        retrain_window,\n",
    "        lookup_window,\n",
    "        stride,\n",
    "        num_timesteps,\n",
    "        threshold,\n",
    "        model_name,\n",
    "        model,\n",
    "        opt,\n",
    "        X_val_final,\n",
    "        y_val,\n",
    "        retrain,\n",
    "    )\n",
    "    run_dict = {\n",
    "        \"dist\": dist_test,\n",
    "        \"pval\": pvals_test,\n",
    "        \"performance\": performance_metrics,\n",
    "        \"alarms\": total_alarms,\n",
    "    }\n",
    "    all_runs.append(run_dict)\n",
    "    mean = np.mean(pvals_test[pvals_test < 0.05])\n",
    "    ci = st.t.interval(\n",
    "        0.95,\n",
    "        len(pvals_test[pvals_test < 0.05]) - 1,\n",
    "        loc=np.mean(pvals_test[pvals_test < 0.05]),\n",
    "        scale=st.sem(pvals_test[pvals_test < 0.05]),\n",
    "    )\n",
    "    print(total_alarms, \" alarms with avg p-value of \", mean, ci)\n",
    "    np.save(\n",
    "        os.path.join(\n",
    "            PATH, shift, shift + \"_mostrecent120_1epoch_n100_retraining_update.npy\"\n",
    "        ),\n",
    "        all_runs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf9d8fd-0dd6-4645-9a7f-1b7060109d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = performance_metrics.shape[0]\n",
    "threshold = 0.05\n",
    "measure_dates_test_adjust = [\n",
    "    (\n",
    "        datetime.datetime.strptime(date, \"%Y-%m-%d\")\n",
    "        + datetime.timedelta(days=lookup_window + stat_window)\n",
    "    ).strftime(\"%Y-%m-%d\")\n",
    "    for date in measure_dates_test\n",
    "]\n",
    "fig, (ax1, ax2, ax3, ax4, ax5, ax6) = plt.subplots(6, 1, figsize=(22, 12))\n",
    "results = pd.DataFrame(\n",
    "    {\n",
    "        \"dates\": measure_dates_test_adjust[0:end],\n",
    "        \"pval\": pvals_test[0:end],\n",
    "        \"dist\": dist_test[0:end],\n",
    "        \"detection\": np.where(pvals_test[0:end] < threshold, 1, 0),\n",
    "    }\n",
    ")\n",
    "results = pd.concat([results, performance_metrics], axis=1)\n",
    "results.to_pickle(\n",
    "    os.path.join(\n",
    "        PATH, shift, shift + \"_\" + dr_technique + \"_\" + md_test + \"_results.pkl\"\n",
    "    )\n",
    ")\n",
    "start = 0\n",
    "end = performance_metrics.shape[0] - 1\n",
    "cmap = ListedColormap([\"lightgrey\", \"red\"])\n",
    "ax1.plot(\n",
    "    results[\"dates\"], results[\"pval\"], \".-\", color=\"red\", linewidth=0.5, markersize=2\n",
    ")\n",
    "ax1.set_xlim(results[\"dates\"][start], results[\"dates\"][end])\n",
    "ax1.axhline(y=threshold, color=\"dimgrey\", linestyle=\"--\")\n",
    "ax1.set_ylabel(\"P-Values\", fontsize=16)\n",
    "ax1.set_xticklabels([])\n",
    "ax1.pcolorfast(\n",
    "    ax1.get_xlim(),\n",
    "    ax1.get_ylim(),\n",
    "    results[\"detection\"].values[np.newaxis],\n",
    "    cmap=cmap,\n",
    "    alpha=0.4,\n",
    ")\n",
    "\n",
    "ax2.plot(\n",
    "    results[\"dates\"], results[\"dist\"], \".-\", color=\"red\", linewidth=0.5, markersize=2\n",
    ")\n",
    "ax2.set_xlim(results[\"dates\"][start], results[\"dates\"][end])\n",
    "ax2.set_ylabel(\"Distance\", fontsize=16)\n",
    "ax2.axhline(y=np.mean(results[\"dist\"]), color=\"dimgrey\", linestyle=\"--\")\n",
    "ax2.set_xticklabels([])\n",
    "ax2.pcolorfast(\n",
    "    ax2.get_xlim(),\n",
    "    ax2.get_ylim(),\n",
    "    results[\"detection\"].values[np.newaxis],\n",
    "    cmap=cmap,\n",
    "    alpha=0.4,\n",
    ")\n",
    "\n",
    "ax3.plot(\n",
    "    results[\"dates\"], results[\"auroc\"], \".-\", color=\"blue\", linewidth=0.5, markersize=2\n",
    ")\n",
    "ax3.set_xlim(results[\"dates\"][start], results[\"dates\"][end])\n",
    "ax3.set_ylabel(\"AUROC\", fontsize=16)\n",
    "ax3.axhline(y=np.mean(results[\"auroc\"]), color=\"dimgrey\", linestyle=\"--\")\n",
    "ax3.set_xticklabels([])\n",
    "ax3.pcolorfast(\n",
    "    ax3.get_xlim(),\n",
    "    ax3.get_ylim(),\n",
    "    results[\"detection\"].values[np.newaxis],\n",
    "    cmap=cmap,\n",
    "    alpha=0.4,\n",
    ")\n",
    "\n",
    "ax4.plot(\n",
    "    results[\"dates\"], results[\"auprc\"], \".-\", color=\"blue\", linewidth=0.5, markersize=2\n",
    ")\n",
    "ax4.set_xlim(results[\"dates\"][start], results[\"dates\"][end])\n",
    "ax4.set_ylabel(\"AUPRC\", fontsize=16)\n",
    "ax4.axhline(y=np.mean(results[\"auprc\"]), color=\"dimgrey\", linestyle=\"--\")\n",
    "ax4.set_xticklabels([])\n",
    "ax4.pcolorfast(\n",
    "    ax4.get_xlim(),\n",
    "    ax4.get_ylim(),\n",
    "    results[\"detection\"].values[np.newaxis],\n",
    "    cmap=cmap,\n",
    "    alpha=0.4,\n",
    ")\n",
    "\n",
    "ax5.plot(\n",
    "    results[\"dates\"], results[\"prec1\"], \".-\", color=\"blue\", linewidth=0.5, markersize=2\n",
    ")\n",
    "ax5.set_xlim(results[\"dates\"][start], results[\"dates\"][end])\n",
    "ax5.set_ylabel(\"PPV\", fontsize=16)\n",
    "ax5.axhline(y=np.mean(results[\"prec1\"]), color=\"dimgrey\", linestyle=\"--\")\n",
    "ax5.set_xticklabels([])\n",
    "ax5.pcolorfast(\n",
    "    ax5.get_xlim(),\n",
    "    ax5.get_ylim(),\n",
    "    results[\"detection\"].values[np.newaxis],\n",
    "    cmap=cmap,\n",
    "    alpha=0.4,\n",
    ")\n",
    "\n",
    "ax6.plot(\n",
    "    results[\"dates\"], results[\"rec1\"], \".-\", color=\"blue\", linewidth=0.5, markersize=2\n",
    ")\n",
    "ax6.set_xlim(results[\"dates\"][start], results[\"dates\"][end])\n",
    "ax6.set_ylabel(\"Sensitivity\", fontsize=16)\n",
    "ax6.set_xlabel(\"time (s)\", fontsize=16)\n",
    "ax6.axhline(y=np.mean(results[\"rec1\"]), color=\"dimgrey\", linestyle=\"--\")\n",
    "ax6.tick_params(axis=\"x\", labelrotation=45)\n",
    "ax6.pcolorfast(\n",
    "    ax6.get_xlim(),\n",
    "    ax6.get_ylim(),\n",
    "    results[\"detection\"].values[np.newaxis],\n",
    "    cmap=cmap,\n",
    "    alpha=0.4,\n",
    ")\n",
    "\n",
    "for index, label in enumerate(ax6.xaxis.get_ticklabels()):\n",
    "    if index % 28 != 0:\n",
    "        label.set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ea2aa0-0eff-4acb-8986-f8572f38b4d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyclops-KKtuQLwg-py3.9",
   "language": "python",
   "name": "cyclops-kktuqlwg-py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

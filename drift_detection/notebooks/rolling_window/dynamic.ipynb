{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d995dcd3-fb7a-4398-b8b8-984c2ddc78be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from alibi_detect.cd import MMDDrift\n",
    "import random\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from utils.utils import *\n",
    "from baseline_models.temporal.pytorch.optimizer import Optimizer\n",
    "from baseline_models.temporal.pytorch.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cff9cf-c682-4973-ab27-1161b70d516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital = [\"SBK\", \"UHNTG\", \"THPC\", \"THPM\", \"UHNTW\", \"SMH\",\"MSH\"]\n",
    "dataset=\"all\"\n",
    "BASE_DATA_PATH = \"/mnt/nfs/project/delirium/drift_exp/risk_of_mortality\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93113177-c6d6-44af-9f74-0c043c781416",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_val, y_val), (x_test, y_test), feats, orig_dims, admin_data = import_dataset_hospital(BASE_DATA_PATH, dataset, hospital, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d91c48-3b72-4510-bfbe-82f70193090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_handler = FeatureHandler()\n",
    "feature_handler.load(BASE_DATA_PATH, \"features\")\n",
    "\n",
    "# Get types of columns\n",
    "numerical_cols = feature_handler.get_numerical_feature_names()[\"temporal\"]\n",
    "numerical_cols += [\"age\"]\n",
    "\n",
    "x_train_normalized = x_train.copy()\n",
    "x_val_normalized = x_val.copy()\n",
    "x_test_normalized = x_test.copy()\n",
    "\n",
    "for col in numerical_cols:\n",
    "    scaler = StandardScaler().fit(x_train[col].values.reshape(-1, 1))\n",
    "    x_train_normalized[col] = pd.Series(\n",
    "        np.squeeze(scaler.transform(x_train[col].values.reshape(-1, 1))),\n",
    "        index=x_train[col].index,\n",
    "    )\n",
    "    x_val_normalized[col] = pd.Series(\n",
    "        np.squeeze(scaler.transform(x_val[col].values.reshape(-1, 1))),\n",
    "        index=x_val[col].index,\n",
    "    )\n",
    "    x_test_normalized[col] = pd.Series(\n",
    "        np.squeeze(scaler.transform(x_test[col].values.reshape(-1, 1))),\n",
    "        index=x_test[col].index,\n",
    "    )\n",
    "\n",
    "OUT_DATA_PATH = \"/mnt/nfs/project/delirium/drift_exp/datasets\"\n",
    "os.makedirs(os.path.join(OUT_DATA_PATH, dataset), exist_ok=True)\n",
    "\n",
    "x_train_normalized.to_parquet(\n",
    "    os.path.join(OUT_DATA_PATH, dataset, \"x_train.parquet\")\n",
    ")\n",
    "x_val_normalized.to_parquet(os.path.join(OUT_DATA_PATH, dataset, \"x_val.parquet\"))\n",
    "x_test_normalized.to_parquet(os.path.join(OUT_DATA_PATH, dataset, \"x_test.parquet\"))\n",
    "\n",
    "np.save(os.path.join(OUT_DATA_PATH, dataset, \"y_train.npy\"), y_train)\n",
    "np.save(os.path.join(OUT_DATA_PATH, dataset, \"y_val.npy\"), y_val)\n",
    "np.save(os.path.join(OUT_DATA_PATH, dataset, \"y_test.npy\"), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0a5be5-e6e5-48da-aa6a-94511b907a69",
   "metadata": {},
   "source": [
    "## Create Data Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950b8746-7262-489e-bd31-c4e381900525",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "\n",
    "#####################################################\n",
    "## a given date contains data from previous two weeks \n",
    "#####################################################\n",
    "\n",
    "start_date = date(2018, 1, 1)\n",
    "end_date = date(2020, 8, 1)\n",
    "\n",
    "def daterange(start_date, end_date, stride, window):\n",
    "    for n in range(int((end_date - start_date).days)):\n",
    "        if start_date + timedelta(n*stride+window) < end_date:\n",
    "            yield start_date+ timedelta(n*stride)\n",
    "            \n",
    "\n",
    "def get_streams(x, y, admin_data, start_date, end_date, stride, window):\n",
    "    target_stream_x = []\n",
    "    target_stream_y = [] \n",
    "    measure_dates = []\n",
    "\n",
    "    admit_df = admin_data[[ENCOUNTER_ID,ADMIT_TIMESTAMP]].sort_values(by=ADMIT_TIMESTAMP)\n",
    "    for single_date in daterange(start_date, end_date, stride, window):\n",
    "        if single_date.month ==1 and single_date.day == 1:\n",
    "            print(single_date.strftime(\"%Y-%m-%d\"),\"-\",(single_date+timedelta(days=window)).strftime(\"%Y-%m-%d\"))\n",
    "        encounters_inwindow = admit_df.loc[((single_date+timedelta(days=window)).strftime(\"%Y-%m-%d\") > admit_df[ADMIT_TIMESTAMP].dt.strftime(\"%Y-%m-%d\")) \n",
    "                           & (admit_df[ADMIT_TIMESTAMP].dt.strftime(\"%Y-%m-%d\") >= single_date.strftime(\"%Y-%m-%d\")), ENCOUNTER_ID].unique()\n",
    "        encounter_ids = x.index.get_level_values(0).unique()\n",
    "        x_inwindow = x.loc[x.index.get_level_values(0).isin(encounters_inwindow)]\n",
    "        y_inwindow = y[np.in1d(encounter_ids, encounters_inwindow)]\n",
    "        if not x_inwindow.empty:\n",
    "            target_stream_x.append(x_inwindow)\n",
    "            target_stream_y.append(y_inwindow)\n",
    "            measure_dates.append((single_date+timedelta(days=window)).strftime(\"%Y-%m-%d\"))\n",
    "    return(target_stream_x, target_stream_y, measure_dates)\n",
    "\n",
    "x_test_stream, y_test_stream, measure_dates_test = get_streams(x_test_normalized, y_test, admin_data, start_date, end_date, stride=1, window=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6b18be-663a-42fc-a4c6-056e2be2fe7a",
   "metadata": {},
   "source": [
    "## Dynamic Rolling Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00db63fd-f8e9-4cd0-8ada-b47be0753be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.05\n",
    "num_timesteps = 6\n",
    "stat_window=14\n",
    "lookup_window=14\n",
    "stride=1\n",
    "random.seed(1)\n",
    "#####################################################\n",
    "## dynamically adjusting drift detector - if drift is significant, reference dataset is reset to current time \n",
    "#####################################################\n",
    "def dynamic_rolling_window(stat_window, lookup_window, stride, num_timesteps, series, threshold,custom_ref=None):\n",
    "\n",
    "    p_vals = np.asarray([])\n",
    "    dist_vals = np.asarray([])\n",
    "    run_length = int(stat_window) \n",
    "    \n",
    "    i = stat_window\n",
    "    \n",
    "    if custom_ref is not None:\n",
    "        prev = reshape_inputs(custom_ref, num_timesteps)\n",
    "    \n",
    "    while i+stat_window+lookup_window <= len(series):\n",
    "        feat_index = 0\n",
    "        \n",
    "        if custom_ref is None:\n",
    "            prev = pd.concat(series[max(int(i)-run_length,0):int(i)+stat_window])\n",
    "            prev = prev[~prev.index.duplicated(keep='first')]\n",
    "            prev = reshape_inputs(prev, num_timesteps)\n",
    "            #prev = prev.reshape(prev.shape[0]*prev.shape[1],prev.shape[2])\n",
    "            \n",
    "        next = pd.concat(series[max(int(i)+lookup_window,0):int(i)+stat_window+lookup_window])\n",
    "        next = next[~next.index.duplicated(keep='first')]\n",
    "        next = reshape_inputs(next, num_timesteps)\n",
    "        #next = next.reshape(next.shape[0]*next.shape[1],next.shape[2])\n",
    "        if next.shape[0]<=2 or prev.shape[0]<=2:\n",
    "            break\n",
    "            \n",
    "        ## run distribution shift check here\n",
    "        cd = MMDDrift(prev, backend='pytorch', p_val=.05)\n",
    "        preds = cd.predict(next, return_p_val=True, return_distance=True)\n",
    "        p_val = preds['data']['p_val']\n",
    "        dist_val = preds['data']['distance']\n",
    "\n",
    "        #print(max(int(i)-run_length,0),\"-\", int(i),\"-->\",max(int(i)+lookup_window,0),\"-\",int(i)+stat_window+lookup_window,\"\\tP-Value: \",p_val)\n",
    "        \n",
    "        i += stride\n",
    "        dist_vals = np.concatenate((dist_vals, np.repeat(dist_val, 1)))\n",
    "        p_vals = np.concatenate((p_vals, np.repeat(p_val, 1)))\n",
    "\n",
    "        if p_val >= threshold:\n",
    "            run_length += stride\n",
    "        else:\n",
    "            print(\"P-value below threshold, reset.\")\n",
    "            print(max(int(i)-run_length,0),\"-\", int(i),\"-->\",max(int(i)+lookup_window,0),\"-\",int(i)+stat_window+lookup_window,\"\\tP-Value: \",p_val)\n",
    "            run_length= stat_window\n",
    "    \n",
    "    return dist_vals, p_vals\n",
    "\n",
    "dist_vals_test, p_vals_test = dynamic_rolling_window(stat_window, lookup_window, stride, num_timesteps, x_test_stream, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf9d8fd-0dd6-4645-9a7f-1b7060109d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_dates_test_14d = [(datetime.datetime.strptime(date,\"%Y-%m-%d\")+datetime.timedelta(days=stat_window*2+lookup_window)).strftime(\"%Y-%m-%d\") for date in measure_dates_test]\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20,8))\n",
    "fig.suptitle('Rolling Windowing')\n",
    "\n",
    "end = len(p_vals_test)\n",
    "results = percentile_list = pd.DataFrame(\n",
    "    {'dates': measure_dates_test_14d[1:end],\n",
    "     'p_val_val': p_vals_test[1:end],\n",
    "     'dist metric_val': dist_vals_test[1:end],\n",
    "     'detection': np.where(p_vals_test[1:end]<threshold,1,0)\n",
    "    })\n",
    "\n",
    "\n",
    "cmap = ListedColormap(['lightgrey','red'])\n",
    "ax1.plot(measure_dates_test_14d[1:end], p_vals_test[1:end], '.-', color=\"red\")\n",
    "ax1.set_xlim(measure_dates_test_14d[1],measure_dates_test_14d[end])\n",
    "ax1.axhline(y=0.05, color='black', linestyle='--')\n",
    "ax1.set_ylabel('P-Values')\n",
    "ax1.set_xticklabels([])\n",
    "ax1.pcolorfast(ax1.get_xlim(), ax1.get_ylim(),results['detection'].values[np.newaxis], cmap = cmap, alpha = 0.4)\n",
    "        \n",
    "ax2.plot(measure_dates_test_14d[1:end], dist_vals_test[1:end], '.-',color=\"blue\")\n",
    "ax2.set_xlim(measure_dates_test_14d[1],measure_dates_test_14d[end])\n",
    "ax2.set_xlabel('time (s)')\n",
    "ax2.set_ylabel('Distance Metric')\n",
    "ax2.tick_params(axis='x', labelrotation=45)\n",
    "ax2.pcolorfast(ax2.get_xlim(), ax2.get_ylim(),results['detection'].values[np.newaxis], cmap = cmap, alpha = 0.4)\n",
    "for index, label in enumerate(ax2.xaxis.get_ticklabels()):\n",
    "    if index % 28 != 0:\n",
    "        label.set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4a5731-46e6-483d-9b8c-bf8ac376d3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_window=14\n",
    "lookup_window=60\n",
    "dist_vals_test, p_vals_test = dynamic_rolling_window(stat_window, lookup_window, stride, num_timesteps, x_test_stream, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e97954-ee6f-4a57-a5f0-7c0d165cadd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_dates_test_60d = [(datetime.datetime.strptime(date,\"%Y-%m-%d\")+datetime.timedelta(days=stat_window*2+lookup_window)).strftime(\"%Y-%m-%d\") for date in measure_dates_test]\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20,8))\n",
    "fig.suptitle('Rolling Windowing')\n",
    "\n",
    "end = len(p_vals_test)\n",
    "results = percentile_list = pd.DataFrame(\n",
    "    {'dates': measure_dates_test_60d[1:end],\n",
    "     'p_val_val': p_vals_test[1:end],\n",
    "     'dist metric_val': dist_vals_test[1:end],\n",
    "     'detection': np.where(p_vals_test[1:end]<threshold,1,0)\n",
    "    })\n",
    "\n",
    "\n",
    "cmap = ListedColormap(['lightgrey','red'])\n",
    "ax1.plot(measure_dates_test_60d[1:end], p_vals_test[1:end], '.-', color=\"red\")\n",
    "ax1.set_xlim(measure_dates_test_60d[1],measure_dates_test_60d[end])\n",
    "ax1.axhline(y=0.05, color='black', linestyle='--')\n",
    "ax1.set_ylabel('P-Values')\n",
    "ax1.set_xticklabels([])\n",
    "ax1.pcolorfast(ax1.get_xlim(), ax1.get_ylim(),results['detection'].values[np.newaxis], cmap = cmap, alpha = 0.4)\n",
    "        \n",
    "ax2.plot(measure_dates_test_60d[1:end], dist_vals_test[1:end], '.-',color=\"blue\")\n",
    "ax2.set_xlim(measure_dates_test_60d[1],measure_dates_test_60d[end])\n",
    "ax2.set_xlabel('time (s)')\n",
    "ax2.set_ylabel('Distance Metric')\n",
    "ax2.tick_params(axis='x', labelrotation=45)\n",
    "ax2.pcolorfast(ax2.get_xlim(), ax2.get_ylim(),results['detection'].values[np.newaxis], cmap = cmap, alpha = 0.4)\n",
    "for index, label in enumerate(ax2.xaxis.get_ticklabels()):\n",
    "    if index % 28 != 0:\n",
    "        label.set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf129ed1-6421-4970-8b9f-497e3bf51c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_window=30\n",
    "lookup_window=120\n",
    "dist_vals_test, p_vals_test = dynamic_rolling_window(stat_window, lookup_window, stride, num_timesteps, x_test_stream, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f82228-014d-4e5e-96f2-7363d89f2711",
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_dates_test_120d = [(datetime.datetime.strptime(date,\"%Y-%m-%d\")+datetime.timedelta(days=stat_window*2+lookup_window)).strftime(\"%Y-%m-%d\") for date in measure_dates_test]\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20,8))\n",
    "fig.suptitle('Rolling Windowing')\n",
    "\n",
    "end = len(p_vals_test)\n",
    "results = percentile_list = pd.DataFrame(\n",
    "    {'dates': measure_dates_test_120d[1:end],\n",
    "     'p_val_val': p_vals_test[1:end],\n",
    "     'dist metric_val': dist_vals_test[1:end],\n",
    "     'detection': np.where(p_vals_test[1:end]<threshold,1,0)\n",
    "    })\n",
    "\n",
    "\n",
    "cmap = ListedColormap(['lightgrey','red'])\n",
    "ax1.plot(measure_dates_test_120d[1:end], p_vals_test[1:end], '.-', color=\"red\")\n",
    "ax1.set_xlim(measure_dates_test_120d[1],measure_dates_test_120d[end])\n",
    "ax1.axhline(y=0.05, color='black', linestyle='--')\n",
    "ax1.set_ylabel('P-Values')\n",
    "ax1.set_xticklabels([])\n",
    "ax1.pcolorfast(ax1.get_xlim(), ax1.get_ylim(),results['detection'].values[np.newaxis], cmap = cmap, alpha = 0.4)\n",
    "        \n",
    "ax2.plot(measure_dates_test_120d[1:end], dist_vals_test[1:end], '.-',color=\"blue\")\n",
    "ax2.set_xlim(measure_dates_test_120d[1],measure_dates_test_120d[end])\n",
    "ax2.set_xlabel('time (s)')\n",
    "ax2.set_ylabel('Distance Metric')\n",
    "ax2.tick_params(axis='x', labelrotation=45)\n",
    "ax2.pcolorfast(ax2.get_xlim(), ax2.get_ylim(),results['detection'].values[np.newaxis], cmap = cmap, alpha = 0.4)\n",
    "for index, label in enumerate(ax2.xaxis.get_ticklabels()):\n",
    "    if index % 28 != 0:\n",
    "        label.set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d977b6a3-6471-4992-9ca9-4c48bf8dfbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.05\n",
    "num_timesteps = 6\n",
    "stat_window=14\n",
    "lookup_window=14\n",
    "stride=1\n",
    "random.seed(1)\n",
    "#####################################################\n",
    "## dynamically adjusting drift detector - if drift is significant, reference dataset is reset to current time \n",
    "#####################################################\n",
    "def adaptive_rolling_window(stat_window, lookup_window, stride, num_timesteps, series, threshold,custom_ref=None):\n",
    "\n",
    "    p_vals = np.asarray([])\n",
    "    dist_vals = np.asarray([])\n",
    "    retrain_stream = []\n",
    "    run_length = stat_window\n",
    "    \n",
    "    i = last = stat_window\n",
    "    \n",
    "    if custom_ref is not None:\n",
    "        prev = reshape_inputs(custom_ref, num_timesteps)\n",
    "    \n",
    "    while i+stat_window+lookup_window <= len(series):\n",
    "        feat_index = 0\n",
    "        retrain_stream.append(max(int(i)-run_length,0))\n",
    "        \n",
    "        if custom_ref is None:\n",
    "            prev = pd.concat(series[max(int(i)-run_length,0):int(i)+stat_window])\n",
    "            prev = prev[~prev.index.duplicated(keep='first')]\n",
    "            prev = reshape_inputs(prev, num_timesteps)\n",
    "            #prev = prev.reshape(prev.shape[0]*prev.shape[1],prev.shape[2])\n",
    "            \n",
    "        next = pd.concat(series[max(int(i)+lookup_window,0):int(i)+stat_window+lookup_window])\n",
    "        next = next[~next.index.duplicated(keep='first')]\n",
    "        next = reshape_inputs(next, num_timesteps)\n",
    "        #next = next.reshape(next.shape[0]*next.shape[1],next.shape[2])\n",
    "        if next.shape[0]<=2 or prev.shape[0]<=2:\n",
    "            break\n",
    "            \n",
    "        ## run distribution shift check here\n",
    "        cd = MMDDrift(prev, backend='pytorch', p_val=.05)\n",
    "        preds = cd.predict(next, return_p_val=True, return_distance=True)\n",
    "        p_val = preds['data']['p_val']\n",
    "        dist_val = preds['data']['distance']\n",
    "\n",
    "        print(max(int(i)-run_length,0),\"-\", int(i),\"-->\",max(int(i)+lookup_window,0),\"-\",int(i)+stat_window+lookup_window,\"\\tP-Value: \",p_val)\n",
    "\n",
    "        if p_val >= threshold:\n",
    "            i += stride\n",
    "            run_length += stride\n",
    "            dist_vals = np.concatenate((dist_vals, np.repeat(dist_val, 1)))\n",
    "            p_vals = np.concatenate((p_vals, np.repeat(p_val, 1)))\n",
    "        else:\n",
    "            print(\"P-value below threshold, reset.\")\n",
    "            del retrain_stream[-1]\n",
    "            run_length-=stat_window\n",
    "    \n",
    "    return dist_vals, p_vals, retrain_stream\n",
    "\n",
    "dist_vals_test, p_vals_test, retrain_stream = adaptive_rolling_window(stat_window, lookup_window, stride, num_timesteps, x_test_stream, threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyclops",
   "language": "python",
   "name": "cyclops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

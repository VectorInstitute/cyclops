{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5117a0d-9d1f-495e-93d5-edb057cf4c0a",
   "metadata": {},
   "source": [
    "## Data pipeline for predicting length of stay in ER."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bb2625-e38f-428a-bcfd-6299b405d0f4",
   "metadata": {},
   "source": [
    "## Imports and Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "international-relief",
   "metadata": {},
<<<<<<< Updated upstream
   "outputs": [],
=======
<<<<<<< HEAD
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 17:45:11,990 \u001b[1;37mINFO\u001b[0m cyclops.orm     - Database setup, ready to run queries!\n"
     ]
    }
   ],
=======
   "outputs": [],
>>>>>>> a2a74ebb2f19e4b2f89c58830922144dc06b8bfa
>>>>>>> Stashed changes
   "source": [
    "import os\n",
    "import random\n",
    "from typing import List, Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from cyclops.feature_handler import FeatureHandler\n",
    "from cyclops.plotter import plot_timeline, set_bars_color, setup_plot\n",
    "from cyclops.processor import run_data_pipeline\n",
    "from cyclops.processors.aggregate import Aggregator\n",
    "from cyclops.processors.column_names import (\n",
    "    ADMIT_TIMESTAMP,\n",
    "    AGE,\n",
    "    DIAGNOSIS_CODE,\n",
    "    DISCHARGE_DISPOSITION,\n",
    "    DISCHARGE_TIMESTAMP,\n",
    "    ENCOUNTER_ID,\n",
    "    EVENT_CATEGORY,\n",
    "    EVENT_NAME,\n",
    "    EVENT_TIMESTAMP,\n",
    "    EVENT_VALUE,\n",
    "    HOSPITAL_ID,\n",
    "    LENGTH_OF_STAY_IN_ER,\n",
    "    RESTRICT_TIMESTAMP,\n",
    "    SEX,\n",
    "    TIMESTEP,\n",
    "    TRIAGE_LEVEL,\n",
    "    WINDOW_START_TIMESTAMP,\n",
    ")\n",
    "from cyclops.processors.constants import SMH\n",
    "from cyclops.processors.events import (\n",
    "    combine_events,\n",
    "    convert_to_events,\n",
    "    normalize_events,\n",
    ")\n",
    "from cyclops.processors.impute import Imputer\n",
    "from cyclops.processors.statics import compute_statics\n",
    "from cyclops.processors.string_ops import replace_if_string_match, to_lower\n",
    "from cyclops.processors.util import (\n",
    "    create_indicator_variables,\n",
    "    fill_missing_timesteps,\n",
    "    gather_columns,\n",
    "    pivot_aggregated_events_to_features,\n",
    ")\n",
    "from cyclops.query import gemini\n",
    "from cyclops.utils.file import load_dataframe, save_dataframe\n",
    "\n",
    "LOS = \"los\"\n",
    "BASE_DATA_PATH = \"/mnt/nfs/project/delirium/drift_exp/los_er\"\n",
    "AGGREGATION_WINDOW = 24\n",
    "AGGREGATION_BUCKET_SIZE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8091448-5301-4631-a7d4-150667441e77",
   "metadata": {},
   "source": [
    "## Run query, save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "964a868e-11ab-432e-9d45-006f57d5a356",
<<<<<<< Updated upstream
=======
<<<<<<< HEAD
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(BASE_DATA_PATH, \"admin_er.parquet\")):\n",
    "    encounters_data = pd.read_parquet(os.path.join(BASE_DATA_PATH, \"admin_er.parquet\"))\n",
    "    labs_data = pd.read_parquet(os.path.join(BASE_DATA_PATH, \"labs.parquet\"))\n",
    "    imaging_data = pd.read_parquet(os.path.join(BASE_DATA_PATH, \"imaging.parquet\"))\n",
    "    transfusions_data = pd.read_parquet(\n",
    "        os.path.join(BASE_DATA_PATH, \"transfusions.parquet\")\n",
    "    )\n",
    "    interventions_data = pd.read_parquet(\n",
    "        os.path.join(BASE_DATA_PATH, \"interventions.parquet\")\n",
    "    )\n",
    "    labs_data[EVENT_CATEGORY] = \"labs\"\n",
    "else:\n",
    "    os.makedirs(BASE_DATA_PATH, exist_ok=True)\n",
    "    er_admin_table = gemini.get_table(gemini.ER_ADMIN)\n",
    "\n",
    "    years = [2015, 2016, 2018, 2019, 2020]\n",
    "    encounters = gemini.patient_encounters(\n",
    "        er_admin_table=er_admin_table,\n",
    "        years=years,\n",
    "    )\n",
    "    encounters_labs = gemini.events(\n",
    "        patient_encounters_table=encounters.query, event_category=\"lab\"\n",
    "    )\n",
    "    imaging = gemini.imaging(years=years)\n",
    "    transfusions = gemini.blood_transfusions(years=years)\n",
    "    interventions = gemini.interventions(years=years)\n",
    "\n",
    "    encounters.run()\n",
    "    print(f\"{len(encounters.data)} rows extracted!\")\n",
    "\n",
    "    encounters_labs.run()\n",
    "    print(f\"{len(encounters_labs.data)} rows extracted!\")\n",
    "    encounters_labs.save(os.path.join(BASE_DATA_PATH, \"labs\"))\n",
    "    encounters_labs.clear_data()\n",
    "\n",
    "    imaging.run()\n",
    "    print(f\"{len(imaging.data)} rows extracted!\")\n",
    "    transfusions.run()\n",
    "    print(f\"{len(transfusions.data)} rows extracted!\")\n",
    "    interventions.run()\n",
    "    print(f\"{len(interventions.data)} rows extracted!\")\n",
    "\n",
    "    encounters_imaging = pd.merge(\n",
    "        encounters.data, imaging.data, on=ENCOUNTER_ID, how=\"inner\"\n",
    "    )\n",
    "    encounters_transfusions = pd.merge(\n",
    "        encounters.data, transfusions.data, on=ENCOUNTER_ID, how=\"inner\"\n",
    "    )\n",
    "    encounters_interventions = pd.merge(\n",
    "        encounters.data, interventions.data, on=ENCOUNTER_ID, how=\"inner\"\n",
    "    )\n",
    "\n",
    "    encounters.save(os.path.join(BASE_DATA_PATH, \"admin_er\"))\n",
    "    encounters_imaging.to_parquet(os.path.join(BASE_DATA_PATH, \"imaging.parquet\"))\n",
    "    encounters_transfusions.to_parquet(os.path.join(BASE_DATA_PATH, \"transfusions.parquet\"))\n",
    "    encounters_interventions.to_parquet(\n",
    "        os.path.join(BASE_DATA_PATH, \"interventions.parquet\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc53fe9c-341f-4e62-9a47-d9e98da22e91",
   "metadata": {},
   "outputs": [],
   "source": []
=======
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(BASE_DATA_PATH, \"admin_er.parquet\")):\n",
    "    encounters_data = pd.read_parquet(os.path.join(BASE_DATA_PATH, \"admin_er.parquet\"))\n",
    "    labs_data = pd.read_parquet(os.path.join(BASE_DATA_PATH, \"labs.parquet\"))\n",
    "    imaging_data = pd.read_parquet(os.path.join(BASE_DATA_PATH, \"imaging.parquet\"))\n",
    "    transfusions_data = pd.read_parquet(\n",
    "        os.path.join(BASE_DATA_PATH, \"transfusions.parquet\")\n",
    "    )\n",
    "    interventions_data = pd.read_parquet(\n",
    "        os.path.join(BASE_DATA_PATH, \"interventions.parquet\")\n",
    "    )\n",
    "    labs_data[EVENT_CATEGORY] = \"labs\"\n",
    "else:\n",
    "    os.makedirs(BASE_DATA_PATH, exist_ok=True)\n",
    "    er_admin_table = gemini.get_table(gemini.ER_ADMIN)\n",
    "\n",
    "    years = [2015, 2016, 2018, 2019, 2020]\n",
    "    encounters = gemini.patient_encounters(\n",
    "        er_admin_table=er_admin_table,\n",
    "        years=years,\n",
    "    )\n",
    "    encounters_labs = gemini.events(\n",
    "        patient_encounters_table=encounters.query, event_category=\"lab\"\n",
    "    )\n",
    "    imaging = gemini.imaging(years=years)\n",
    "    transfusions = gemini.blood_transfusions(years=years)\n",
    "    interventions = gemini.interventions(years=years)\n",
    "\n",
    "    encounters.run()\n",
    "    print(f\"{len(encounters.data)} rows extracted!\")\n",
    "\n",
    "    encounters_labs.run()\n",
    "    print(f\"{len(encounters_labs.data)} rows extracted!\")\n",
    "    encounters_labs.save(os.path.join(BASE_DATA_PATH, \"labs\"))\n",
    "    encounters_labs.clear_data()\n",
    "\n",
    "    imaging.run()\n",
    "    print(f\"{len(imaging.data)} rows extracted!\")\n",
    "    transfusions.run()\n",
    "    print(f\"{len(transfusions.data)} rows extracted!\")\n",
    "    interventions.run()\n",
    "    print(f\"{len(interventions.data)} rows extracted!\")\n",
    "\n",
    "    encounters_imaging = pd.merge(\n",
    "        encounters.data, imaging.data, on=ENCOUNTER_ID, how=\"inner\"\n",
    "    )\n",
    "    encounters_transfusions = pd.merge(\n",
    "        encounters.data, transfusions.data, on=ENCOUNTER_ID, how=\"inner\"\n",
    "    )\n",
    "    encounters_interventions = pd.merge(\n",
    "        encounters.data, interventions.data, on=ENCOUNTER_ID, how=\"inner\"\n",
    "    )\n",
    "\n",
    "    encounters.save(os.path.join(BASE_DATA_PATH, \"admin_er\"))\n",
    "    encounters_imaging.to_parquet(os.path.join(BASE_DATA_PATH, \"imaging.parquet\"))\n",
    "    encounters_transfusions.to_parquet(os.path.join(BASE_DATA_PATH, \"transfusions.parquet\"))\n",
    "    encounters_interventions.to_parquet(\n",
    "        os.path.join(BASE_DATA_PATH, \"interventions.parquet\")\n",
    "    )"
   ]
>>>>>>> a2a74ebb2f19e4b2f89c58830922144dc06b8bfa
  },
  {
   "cell_type": "markdown",
   "id": "4b91df5c-c266-45af-8541-3d1f291a93e2",
   "metadata": {},
   "source": [
    "## Map triage level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d81be7a6-9a4c-4bd0-8f8a-406c2fcbba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap(triage_level):\n",
    "    map_ = {\n",
    "        \"1\": \"RESUSCITATION\",\n",
    "        \"2\": \"EMERGENCY\",\n",
    "        \"3\": \"URGENT\",\n",
    "        \"4\": \"SEMI-URGENT\",\n",
    "        \"5\": \"NON-URGENT\",\n",
    "    }\n",
    "    return map_.get(triage_level, \"UNKNOWN\")\n",
    "\n",
    "\n",
    "encounters_data[TRIAGE_LEVEL] = encounters_data[TRIAGE_LEVEL].apply(remap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0af1b6-1e8b-4554-944f-f13209d282cc",
   "metadata": {},
   "source": [
    "## Map imaging and transfusions such that they can be treated as events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3131da1-d7e8-4564-b1ff-d6e9e2251d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "imaging_data = imaging_data.rename(\n",
    "    columns={\n",
    "        \"imaging_test_description\": EVENT_NAME,\n",
    "        \"performed_date_time\": EVENT_TIMESTAMP,\n",
    "    }\n",
    ")\n",
    "imaging_data[EVENT_CATEGORY] = \"imaging\"\n",
    "imaging_data[EVENT_VALUE] = 1\n",
    "\n",
    "transfusions_data = transfusions_data.rename(\n",
    "    columns={\"issue_date_time\": EVENT_TIMESTAMP}\n",
    ")\n",
    "transfusions_data[EVENT_NAME] = transfusions_data[\"rbc_mapped\"]\n",
    "transfusions_data[EVENT_NAME] = transfusions_data[EVENT_NAME].apply(\n",
    "    lambda x: \"rbc\" if x else \"non-rbc\"\n",
    ")\n",
    "transfusions_data[EVENT_VALUE] = 1\n",
    "transfusions_data[EVENT_CATEGORY] = \"transfusions\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564db1ba-9f9d-4b39-a57a-90a357afab8f",
   "metadata": {},
   "source": [
    "##  Process interventions such that they can be treated as events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f34a21c-49ec-48a9-bfac-0cae8dce5f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_789825/3783487325.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  interventions_data[\"intervention_episode_start_time\"].loc[\n"
     ]
    }
   ],
   "source": [
    "interventions_data[EVENT_VALUE] = 1\n",
    "interventions_data[EVENT_CATEGORY] = \"interventions\"\n",
    "\n",
    "binary_mapped_cols = [\n",
    "    \"endoscopy_mapped\",\n",
    "    \"gi_endoscopy_mapped\",\n",
    "    \"bronch_endoscopy_mapped\",\n",
    "    \"dialysis_mapped\",\n",
    "    \"inv_mech_vent_mapped\",\n",
    "    \"surgery_mapped\",\n",
    "]\n",
    "interventions_data[\"intervention_episode_start_time\"].loc[\n",
    "    interventions_data[\"intervention_episode_start_time\"].isna()\n",
    "] = \"12:00:00\"\n",
    "interventions_data[EVENT_TIMESTAMP] = pd.to_datetime(\n",
    "    interventions_data[\"intervention_episode_start_date\"].astype(str)\n",
    "    + \" \"\n",
    "    + interventions_data[\"intervention_episode_start_time\"].astype(str)\n",
    ")\n",
    "interventions_data[EVENT_TIMESTAMP] = interventions_data[EVENT_TIMESTAMP].astype(\n",
    "    \"datetime64[ns]\"\n",
    ")\n",
    "interventions_data[\"unmapped_intervention\"] = ~(\n",
    "    interventions_data[\"endoscopy_mapped\"]\n",
    "    | interventions_data[\"gi_endoscopy_mapped\"]\n",
    "    | interventions_data[\"bronch_endoscopy_mapped\"]\n",
    "    | interventions_data[\"dialysis_mapped\"]\n",
    "    | interventions_data[\"inv_mech_vent_mapped\"]\n",
    "    | interventions_data[\"surgery_mapped\"]\n",
    ")\n",
    "interventions_data[EVENT_NAME] = interventions_data[\n",
    "    binary_mapped_cols + [\"unmapped_intervention\"]\n",
    "].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7303e205-6491-442d-92a2-abc9a5c2a15d",
   "metadata": {},
   "source": [
    "## Filter out encounters that had less than 1 hour LOS in ER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63fc8075-57e8-49ac-b6f8-124d5b3591e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encounters_data_atleast_los_1_hrs = encounters_data.loc[\n",
    "    ~encounters_data[LENGTH_OF_STAY_IN_ER].isna()\n",
    "]\n",
    "encounters_data_atleast_los_1_hrs = encounters_data_atleast_los_1_hrs.loc[\n",
    "    encounters_data_atleast_los_1_hrs[LENGTH_OF_STAY_IN_ER] >= 1\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3144bf82-0621-4a1b-a5f1-a95f55f07505",
   "metadata": {},
   "source": [
    "## Filter out encounters that greater than 50 hours LOS in ER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae6c28e9-f034-489d-a54a-38c16704f962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147708 154450\n"
     ]
    }
   ],
   "source": [
    "encounters_data_atleast_los_1_hrs_within_timeframe = (\n",
    "    encounters_data_atleast_los_1_hrs.loc[\n",
    "        encounters_data_atleast_los_1_hrs[LENGTH_OF_STAY_IN_ER] <= 50\n",
    "    ]\n",
    ")\n",
    "print(\n",
    "    len(encounters_data_atleast_los_1_hrs_within_timeframe),\n",
    "    len(encounters_data_atleast_los_1_hrs),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc52ac37-812b-47d1-886c-56c0c0ff707f",
   "metadata": {},
   "source": [
    "## Create smaller subset for train/val/test, plot LOS distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "363cdf2d-b276-4fe6-9f52-df67a9749255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "encounters_data_train_val_test = (\n",
    "    encounters_data_atleast_los_1_hrs_within_timeframe.sample(20000)\n",
    ")\n",
    "\n",
    "data = np.array(list(encounters_data_train_val_test[LENGTH_OF_STAY_IN_ER]))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "n, bins, patches = plt.hist(data, 50, facecolor=\"blue\", alpha=0.5, density=True)\n",
    "plt.xlabel(\"No. of hours in the ER\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c6498e-f2a6-4383-89bd-6c9b5b4ee144",
   "metadata": {},
   "source": [
    "## Create ER discharge events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90081c16-ac41-4b60-ab48-7ff747630e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "er_disch_events = convert_to_events(\n",
    "    encounters_data_atleast_los_1_hrs,\n",
    "    event_name=\"er_discharge\",\n",
    "    event_category=\"general\",\n",
    "    timestamp_col=\"er_discharge_timestamp\",\n",
    ")\n",
    "er_disch_events[EVENT_VALUE] = 1\n",
    "# er_disch_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e2653f-b1de-4e63-8531-b92677534041",
   "metadata": {},
   "source": [
    "## Get admission/discharge events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5de93b44-b260-44d5-869f-80752cc913c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "admit_events = convert_to_events(\n",
    "    encounters_data_atleast_los_1_hrs,\n",
    "    event_name=\"admission\",\n",
    "    event_category=\"general\",\n",
    "    timestamp_col=ADMIT_TIMESTAMP,\n",
    ")\n",
    "disch_events = convert_to_events(\n",
    "    encounters_data_atleast_los_1_hrs,\n",
    "    event_name=\"discharge\",\n",
    "    event_category=\"general\",\n",
    "    timestamp_col=DISCHARGE_TIMESTAMP,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238709bd-47f6-4cf6-8562-09717824d57f",
   "metadata": {},
   "source": [
    "## Filter events to be in train_val_test subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "773d7deb-f5bf-4a7a-a773-5768a68f7e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_train_val_test = labs_data.loc[\n",
    "    labs_data[ENCOUNTER_ID].isin(encounters_data_train_val_test[ENCOUNTER_ID])\n",
    "]\n",
    "imaging_train_val_test = imaging_data.loc[\n",
    "    imaging_data[ENCOUNTER_ID].isin(encounters_data_train_val_test[ENCOUNTER_ID])\n",
    "]\n",
    "transfusions_train_val_test = transfusions_data.loc[\n",
    "    transfusions_data[ENCOUNTER_ID].isin(encounters_data_train_val_test[ENCOUNTER_ID])\n",
    "]\n",
    "interventions_train_val_test = interventions_data.loc[\n",
    "    interventions_data[ENCOUNTER_ID].isin(encounters_data_train_val_test[ENCOUNTER_ID])\n",
    "]\n",
    "admit_events = admit_events.loc[\n",
    "    admit_events[ENCOUNTER_ID].isin(encounters_data_train_val_test[ENCOUNTER_ID])\n",
    "]\n",
    "disch_events = disch_events.loc[\n",
    "    disch_events[ENCOUNTER_ID].isin(encounters_data_train_val_test[ENCOUNTER_ID])\n",
    "]\n",
    "er_disch_events = er_disch_events.loc[\n",
    "    er_disch_events[ENCOUNTER_ID].isin(encounters_data_train_val_test[ENCOUNTER_ID])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527e4baa-d706-4b72-88e4-7416db744d7e",
   "metadata": {},
   "source": [
    "## Normalize all event data (names, string operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e249a41-d012-4f25-9241-66c15fad7d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 09:52:22,424 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Cleaning raw event data...\n",
      "2022-07-14 09:52:22,427 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 79611, # encounters: 18677\n",
      "2022-07-14 09:52:22,428 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 60, # encounters: 18677\n",
      "2022-07-14 09:52:22,692 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Remove text in parentheses and normalize event names...\n",
      "2022-07-14 09:52:22,695 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 79611, # encounters: 18677\n",
      "2022-07-14 09:52:22,696 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 60, # encounters: 18677\n",
      "2022-07-14 09:52:22,877 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Drop unsupported events...\n",
      "2022-07-14 09:52:22,880 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 79611, # encounters: 18677\n",
      "2022-07-14 09:52:22,881 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 60, # encounters: 18677\n",
      "2022-07-14 09:52:22,949 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Normalize event categories...\n",
      "2022-07-14 09:52:22,952 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 79611, # encounters: 18677\n",
      "2022-07-14 09:52:22,954 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 60, # encounters: 18677\n",
      "2022-07-14 09:52:22,954 \u001b[1;37mINFO\u001b[0m cyclops.utils.profile - Finished executing function normalize_events in 0.572298 s\n",
      "2022-07-14 09:52:22,957 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Cleaning raw event data...\n",
      "2022-07-14 09:52:22,959 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 6738, # encounters: 1715\n",
      "2022-07-14 09:52:22,960 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 60, # encounters: 1715\n",
      "2022-07-14 09:52:22,986 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Remove text in parentheses and normalize event names...\n",
      "2022-07-14 09:52:22,987 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 6738, # encounters: 1715\n",
      "2022-07-14 09:52:22,988 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 60, # encounters: 1715\n",
      "2022-07-14 09:52:23,001 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Drop unsupported events...\n",
      "2022-07-14 09:52:23,003 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 6738, # encounters: 1715\n",
      "2022-07-14 09:52:23,004 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 60, # encounters: 1715\n",
      "2022-07-14 09:52:23,011 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Normalize event categories...\n",
      "2022-07-14 09:52:23,012 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 6738, # encounters: 1715\n",
      "2022-07-14 09:52:23,013 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 60, # encounters: 1715\n",
      "2022-07-14 09:52:23,014 \u001b[1;37mINFO\u001b[0m cyclops.utils.profile - Finished executing function normalize_events in 0.058506 s\n",
      "2022-07-14 09:52:24,422 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Cleaning raw event data...\n",
      "2022-07-14 09:52:24,441 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 2348538, # encounters: 19955\n",
      "2022-07-14 09:52:24,442 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 60, # encounters: 19955\n",
      "2022-07-14 09:52:33,390 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Remove text in parentheses and normalize event names...\n",
      "2022-07-14 09:52:33,410 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 2348538, # encounters: 19955\n",
      "2022-07-14 09:52:33,411 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 60, # encounters: 19955\n",
      "2022-07-14 09:52:38,977 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Drop unsupported events...\n",
      "2022-07-14 09:52:38,994 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 2134522, # encounters: 19955\n",
      "2022-07-14 09:52:38,995 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 60, # encounters: 19955\n",
      "2022-07-14 09:52:56,818 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Convert Positive/Negative to 1/0...\n",
      "2022-07-14 09:52:56,836 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 2134522, # encounters: 19955\n",
      "2022-07-14 09:52:56,837 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 60, # encounters: 19955\n",
      "2022-07-14 09:53:02,940 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Remove any text in paranthesis\n",
      "2022-07-14 09:53:02,967 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 2134522, # encounters: 19955\n",
      "2022-07-14 09:53:02,968 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 60, # encounters: 19955\n",
      "2022-07-14 09:53:13,066 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Fixing inequalities and removing outlier values...\n",
      "2022-07-14 09:53:13,087 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 2134522, # encounters: 19955\n",
      "2022-07-14 09:53:13,088 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 60, # encounters: 19955\n",
      "2022-07-14 09:53:14,068 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Fill empty result string values with NaN...\n",
      "2022-07-14 09:53:14,096 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 2134522, # encounters: 19955\n",
      "2022-07-14 09:53:14,098 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 60, # encounters: 19955\n",
      "2022-07-14 09:53:14,784 \u001b[1;37mINFO\u001b[0m cyclops.processors.events - Converting string result values to numeric...\n",
      "2022-07-14 09:53:14,786 \u001b[1;37mINFO\u001b[0m cyclops.processors.events - Normalizing units...\n",
      "2022-07-14 09:53:34,134 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Normalize event categories...\n",
      "2022-07-14 09:53:34,161 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 2134522, # encounters: 19955\n",
      "2022-07-14 09:53:34,163 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 60, # encounters: 19955\n",
      "2022-07-14 09:53:34,164 \u001b[1;37mINFO\u001b[0m cyclops.utils.profile - Finished executing function normalize_events in 71.148193 s\n",
      "2022-07-14 09:53:34,166 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Cleaning raw event data...\n",
      "2022-07-14 09:53:34,168 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 20000, # encounters: 20000\n",
      "2022-07-14 09:53:34,169 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 5, # encounters: 20000\n",
      "2022-07-14 09:53:34,240 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Remove text in parentheses and normalize event names...\n",
      "2022-07-14 09:53:34,242 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 20000, # encounters: 20000\n",
      "2022-07-14 09:53:34,243 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 5, # encounters: 20000\n",
      "2022-07-14 09:53:34,264 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Drop unsupported events...\n",
      "2022-07-14 09:53:34,266 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 20000, # encounters: 20000\n",
      "2022-07-14 09:53:34,267 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 5, # encounters: 20000\n",
      "2022-07-14 09:53:34,280 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Normalize event categories...\n",
      "2022-07-14 09:53:34,282 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 20000, # encounters: 20000\n",
      "2022-07-14 09:53:34,282 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 5, # encounters: 20000\n",
      "2022-07-14 09:53:34,283 \u001b[1;37mINFO\u001b[0m cyclops.utils.profile - Finished executing function normalize_events in 0.118686 s\n",
      "2022-07-14 09:53:34,291 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Cleaning raw event data...\n",
      "2022-07-14 09:53:34,292 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 17802, # encounters: 7558\n",
      "2022-07-14 09:53:34,293 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 72, # encounters: 7558\n",
      "2022-07-14 09:53:34,357 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Remove text in parentheses and normalize event names...\n",
      "2022-07-14 09:53:34,359 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 17802, # encounters: 7558\n",
      "2022-07-14 09:53:34,359 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 72, # encounters: 7558\n",
      "2022-07-14 09:53:34,393 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Drop unsupported events...\n",
      "2022-07-14 09:53:34,395 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 17802, # encounters: 7558\n",
      "2022-07-14 09:53:34,396 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 72, # encounters: 7558\n",
      "2022-07-14 09:53:34,413 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Normalize event categories...\n",
      "2022-07-14 09:53:34,415 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 17802, # encounters: 7558\n",
      "2022-07-14 09:53:34,416 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 72, # encounters: 7558\n",
      "2022-07-14 09:53:34,417 \u001b[1;37mINFO\u001b[0m cyclops.utils.profile - Finished executing function normalize_events in 0.132475 s\n",
      "2022-07-14 09:53:34,419 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Cleaning raw event data...\n",
      "2022-07-14 09:53:34,421 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 20000, # encounters: 20000\n",
      "2022-07-14 09:53:34,422 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 5, # encounters: 20000\n",
      "2022-07-14 09:53:34,486 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Remove text in parentheses and normalize event names...\n",
      "2022-07-14 09:53:34,488 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 20000, # encounters: 20000\n",
      "2022-07-14 09:53:34,489 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 5, # encounters: 20000\n",
      "2022-07-14 09:53:34,510 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Drop unsupported events...\n",
      "2022-07-14 09:53:34,512 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 20000, # encounters: 20000\n",
      "2022-07-14 09:53:34,513 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 5, # encounters: 20000\n",
      "2022-07-14 09:53:34,648 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Convert Positive/Negative to 1/0...\n",
      "2022-07-14 09:53:34,650 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 20000, # encounters: 20000\n",
      "2022-07-14 09:53:34,651 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 5, # encounters: 20000\n",
      "2022-07-14 09:53:34,708 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Remove any text in paranthesis\n",
      "2022-07-14 09:53:34,710 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 20000, # encounters: 20000\n",
      "2022-07-14 09:53:34,711 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 5, # encounters: 20000\n",
      "2022-07-14 09:53:34,763 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Fixing inequalities and removing outlier values...\n",
      "2022-07-14 09:53:34,765 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 20000, # encounters: 20000\n",
      "2022-07-14 09:53:34,765 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 5, # encounters: 20000\n",
      "2022-07-14 09:53:34,784 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Fill empty result string values with NaN...\n",
      "2022-07-14 09:53:34,786 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 20000, # encounters: 20000\n",
      "2022-07-14 09:53:34,786 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 5, # encounters: 20000\n",
      "2022-07-14 09:53:34,788 \u001b[1;37mINFO\u001b[0m cyclops.processors.events - Converting string result values to numeric...\n",
      "2022-07-14 09:53:34,800 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Normalize event categories...\n",
      "2022-07-14 09:53:34,802 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 20000, # encounters: 20000\n",
      "2022-07-14 09:53:34,803 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 5, # encounters: 20000\n",
      "2022-07-14 09:53:34,804 \u001b[1;37mINFO\u001b[0m cyclops.utils.profile - Finished executing function normalize_events in 0.386498 s\n",
      "2022-07-14 09:53:34,806 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Cleaning raw event data...\n",
      "2022-07-14 09:53:34,808 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 20000, # encounters: 20000\n",
      "2022-07-14 09:53:34,809 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 5, # encounters: 20000\n",
      "2022-07-14 09:53:34,872 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Remove text in parentheses and normalize event names...\n",
      "2022-07-14 09:53:34,874 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 20000, # encounters: 20000\n",
      "2022-07-14 09:53:34,875 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 5, # encounters: 20000\n",
      "2022-07-14 09:53:34,896 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Drop unsupported events...\n",
      "2022-07-14 09:53:34,898 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 20000, # encounters: 20000\n",
      "2022-07-14 09:53:34,899 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 5, # encounters: 20000\n",
      "2022-07-14 09:53:35,029 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Convert Positive/Negative to 1/0...\n",
      "2022-07-14 09:53:35,032 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 20000, # encounters: 20000\n",
      "2022-07-14 09:53:35,033 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 5, # encounters: 20000\n",
      "2022-07-14 09:53:35,089 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Remove any text in paranthesis\n",
      "2022-07-14 09:53:35,091 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 20000, # encounters: 20000\n",
      "2022-07-14 09:53:35,092 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 5, # encounters: 20000\n",
      "2022-07-14 09:53:35,145 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Fixing inequalities and removing outlier values...\n",
      "2022-07-14 09:53:35,147 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 20000, # encounters: 20000\n",
      "2022-07-14 09:53:35,148 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 5, # encounters: 20000\n",
      "2022-07-14 09:53:35,166 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Fill empty result string values with NaN...\n",
      "2022-07-14 09:53:35,168 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 20000, # encounters: 20000\n",
      "2022-07-14 09:53:35,169 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 5, # encounters: 20000\n",
      "2022-07-14 09:53:35,171 \u001b[1;37mINFO\u001b[0m cyclops.processors.events - Converting string result values to numeric...\n",
      "2022-07-14 09:53:35,183 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - Normalize event categories...\n",
      "2022-07-14 09:53:35,185 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # samples: 20000, # encounters: 20000\n",
      "2022-07-14 09:53:35,186 \u001b[1;37mINFO\u001b[0m cyclops.processors.util - # columns: 5, # encounters: 20000\n",
      "2022-07-14 09:53:35,187 \u001b[1;37mINFO\u001b[0m cyclops.utils.profile - Finished executing function normalize_events in 0.381552 s\n"
     ]
    }
   ],
   "source": [
    "imaging_events = normalize_events(imaging_train_val_test)\n",
    "transfusion_events = normalize_events(transfusions_train_val_test)\n",
    "lab_events = normalize_events(labs_train_val_test)\n",
    "er_disch_events = normalize_events(er_disch_events)\n",
    "intervention_events = normalize_events(interventions_train_val_test)\n",
    "admit_events = normalize_events(admit_events)\n",
    "disch_events = normalize_events(disch_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5950cea0-8178-4303-865d-ceb47ac2b30d",
   "metadata": {},
   "source": [
    "## Combine different event data, save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d9306e6-90a0-4adb-8691-972424912f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 09:54:30,155 \u001b[1;37mINFO\u001b[0m cyclops.utils.file - Loading dataframe to /mnt/nfs/project/delirium/drift_exp/los_er/combined_events.parquet\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(os.path.join(BASE_DATA_PATH, \"combined_events.parquet\")):\n",
    "    combined_events = load_dataframe(os.path.join(BASE_DATA_PATH, \"combined_events\"))\n",
    "else:\n",
    "    combined_events = combine_events(\n",
    "        [\n",
    "            intervention_events,\n",
    "            imaging_events,\n",
    "            transfusion_events,\n",
    "            lab_events,\n",
    "            er_disch_events,\n",
    "            admit_events,\n",
    "            disch_events,\n",
    "        ]\n",
    "    )\n",
    "    save_dataframe(combined_events, os.path.join(BASE_DATA_PATH, \"combined_events\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bbc55f-d3f2-41c6-a367-c8a817b424d8",
   "metadata": {},
   "source": [
    "## Load aggregated events, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab947b7d-b489-4ce6-be32-546a8d0ae6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 09:54:44,190 \u001b[1;37mINFO\u001b[0m cyclops.utils.file - Loading dataframe to /mnt/nfs/project/delirium/drift_exp/los_er/aggregated_events.parquet\n",
      "2022-07-14 09:54:44,363 \u001b[1;37mINFO\u001b[0m cyclops.utils.file - Loading dataframe to /mnt/nfs/project/delirium/drift_exp/los_er/aggmeta_start_ts.parquet\n",
      "2022-07-14 09:54:44,446 \u001b[1;37mINFO\u001b[0m cyclops.utils.file - Loading dataframe to /mnt/nfs/project/delirium/drift_exp/los_er/aggmeta_end_ts.parquet\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(os.path.join(BASE_DATA_PATH, \"aggregated_events.parquet\")):\n",
    "    aggregated_events = load_dataframe(os.path.join(BASE_DATA_PATH, \"aggregated_events\"))\n",
    "    timestep_start_timestamps = load_dataframe(\n",
    "        os.path.join(BASE_DATA_PATH, \"aggmeta_start_ts\")\n",
    "    )\n",
    "    timestep_end_timestamps = load_dataframe(os.path.join(BASE_DATA_PATH, \"aggmeta_end_ts\"))\n",
    "else:\n",
    "    aggregator = Aggregator(bucket_size=AGGREGATION_BUCKET_SIZE, window=AGGREGATION_WINDOW)\n",
    "    aggregated_events = aggregator(combined_events)\n",
    "    save_dataframe(aggregated_events, os.path.join(BASE_DATA_PATH, \"aggregated_events\"))\n",
    "    save_dataframe(\n",
    "        aggregator.meta[\"timestep_start_timestamp\"],\n",
    "        os.path.join(BASE_DATA_PATH, \"aggmeta_start_ts\"),\n",
    "    )\n",
    "    save_dataframe(\n",
    "        aggregator.meta[\"timestep_end_timestamp\"],\n",
    "        os.path.join(BASE_DATA_PATH, \"aggmeta_end_ts\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13a0ea6-713e-4c0f-ab5a-a31fe81c9071",
   "metadata": {},
   "source": [
    "## Some small number of events are getting aggregated to a 7th timestep!! (Debug later, remove for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "281af9c0-d425-497f-ae8e-185537ce8bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sodium                       865\n",
       "potassium                    841\n",
       "bicarbonate                  768\n",
       "hemoglobin                   703\n",
       "x-ray                        698\n",
       "ct                           690\n",
       "creatinine                   688\n",
       "er_discharge                 656\n",
       "lymphocyte                   646\n",
       "white blood cell count       643\n",
       "hematocrit                   643\n",
       "platelet count               642\n",
       "neutrophils                  637\n",
       "glucose random               626\n",
       "mean cell volume             623\n",
       "lactate venous               617\n",
       "calcium                      453\n",
       "high sensitivity troponin    437\n",
       "troponin                     434\n",
       "bilirubin                    430\n",
       "venous pco2                  410\n",
       "ketone                       398\n",
       "albumin                      380\n",
       "venous ph                    332\n",
       "blood urea nitrogen          281\n",
       "glucose point of care        247\n",
       "urine specific gravity       240\n",
       "inr                          214\n",
       "aptt                         195\n",
       "pt                           189\n",
       "urine sodium                 112\n",
       "ultrasound                   108\n",
       "vitamin b12                   96\n",
       "lactate arterial              86\n",
       "arterial paco2                81\n",
       "arterial pao2                 81\n",
       "rbc                           77\n",
       "ferritin                      73\n",
       "crp                           69\n",
       "unmapped_intervention         66\n",
       "arterial ph                   60\n",
       "other                         60\n",
       "serum alcohol                 60\n",
       "hba1c                         44\n",
       "esr                           39\n",
       "influenza                     29\n",
       "calcium, ionized              26\n",
       "fibrinogen                    23\n",
       "mri                           23\n",
       "er_admit                      22\n",
       "endoscopy_mapped              11\n",
       "non-rbc                       11\n",
       "echo                          10\n",
       "lipase                         9\n",
       "inv_mech_vent_mapped           8\n",
       "interventional                 6\n",
       "glucose fasting                5\n",
       "dialysis_mapped                2\n",
       "vitamin d                      2\n",
       "Name: event_name, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_events.loc[aggregated_events[\"timestep\"] == 6][\"event_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "315f2641-2b82-41fd-ad24-2fdde0cc64cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_events = aggregated_events.loc[aggregated_events[\"timestep\"] != 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cc4793-a22b-4611-96b3-65e2bd0d3d3c",
   "metadata": {},
   "source": [
    "## Pivot aggregated events to get column-wise temporal features and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56a50a78-9e33-4f71-b45c-a2ca21ad31c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_features = pivot_aggregated_events_to_features(aggregated_events, np.mean)\n",
    "#save_dataframe(temporal_features, os.path.join(BASE_DATA_PATH, \"temporal_features\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0277e20e-c9c7-427c-b3a4-e6120b342581",
   "metadata": {},
   "source": [
    "## Add to feature handler, with indicator variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7cf2259-d1e8-4d72-acb5-d4c1ebd4cfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 09:57:35,372 \u001b[1;37mINFO\u001b[0m cyclops.utils.file - Loading dataframe to /mnt/nfs/project/delirium/drift_exp/los_er/temporal_features.parquet\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot drop non-existent features: {'mortality'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m temporal_features \u001b[38;5;241m=\u001b[39m load_dataframe(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(BASE_DATA_PATH, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemporal_features\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      4\u001b[0m feature_handler\u001b[38;5;241m.\u001b[39madd_features(temporal_features)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mfeature_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmortality\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m already_indicators \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mct\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdialysis_mapped\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx-ray\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     22\u001b[0m ]\n\u001b[1;32m     24\u001b[0m temporal_features \u001b[38;5;241m=\u001b[39m feature_handler\u001b[38;5;241m.\u001b[39mfeatures[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemporal\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/cyclops/cyclops/feature_handler.py:807\u001b[0m, in \u001b[0;36mFeatureHandler.drop_features\u001b[0;34m(self, names)\u001b[0m\n\u001b[1;32m    805\u001b[0m remaining \u001b[38;5;241m=\u001b[39m remaining\u001b[38;5;241m.\u001b[39mdifference(drop_groups)\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(remaining) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 807\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot drop non-existent features: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mremaining\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    809\u001b[0m \u001b[38;5;66;03m# Drop columns.\u001b[39;00m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drop_cols(\u001b[38;5;28mlist\u001b[39m(drop_cols))\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot drop non-existent features: {'mortality'}"
     ]
    }
   ],
   "source": [
    "feature_handler = FeatureHandler()\n",
    "\n",
    "temporal_features = load_dataframe(os.path.join(BASE_DATA_PATH, \"temporal_features\"))\n",
    "feature_handler.add_features(temporal_features)\n",
    "feature_handler.drop_features([\"death\"])\n",
    "\n",
    "already_indicators = [\n",
    "    \"ct\",\n",
    "    \"dialysis_mapped\",\n",
    "    \"echo\",\n",
    "    \"endoscopy_mapped\",\n",
    "    \"interventional\",\n",
    "    \"inv_mech_vent_mapped\",\n",
    "    \"mri\",\n",
    "    \"non-rbc\",\n",
    "    \"other\",\n",
    "    \"rbc\",\n",
    "    \"surgery_mapped\",\n",
    "    \"ultrasound\",\n",
    "    \"unmapped_intervention\",\n",
    "    \"x-ray\",\n",
    "]\n",
    "\n",
    "temporal_features = feature_handler.features[\"temporal\"]\n",
    "indicators = create_indicator_variables(\n",
    "    temporal_features[\n",
    "        [col for col in temporal_features if col not in already_indicators]\n",
    "    ]\n",
    ")\n",
    "feature_handler.add_features(indicators)\n",
    "feature_handler.features[\"temporal\"].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025e89d8-a325-45f5-a38e-0f0ef6abe443",
   "metadata": {},
   "source": [
    "## Compute static features, save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87c4497-03d3-4304-86d1-54b4eb5b5f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "encounters_train_val_test_static_cols = gather_columns(\n",
    "    encounters_train_val_test,\n",
    "    [\n",
    "        ENCOUNTER_ID,\n",
    "        AGE,\n",
    "        SEX,\n",
    "        HOSPITAL_ID,\n",
    "        ADMIT_TIMESTAMP,\n",
    "        DISCHARGE_TIMESTAMP,\n",
    "        TRIAGE_LEVEL,\n",
    "    ],\n",
    ")\n",
    "static_features = compute_statics(encounters_train_val_test_static_cols)\n",
    "#save_dataframe(static_features, os.path.join(BASE_DATA_PATH, \"static_features\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61b6950-850c-4a83-a568-45088411911a",
   "metadata": {},
   "source": [
    "##  Load static features, add to feature handler, save all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c4759c9-bfd8-42ec-adeb-c518489caae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 09:57:52,628 \u001b[1;37mINFO\u001b[0m cyclops.utils.file - Loading dataframe to /mnt/nfs/project/delirium/drift_exp/los_er/static_features.parquet\n"
     ]
    }
   ],
   "source": [
    "static_features = load_dataframe(os.path.join(BASE_DATA_PATH, \"static_features\"))\n",
    "feature_handler.add_features(\n",
    "    static_features, reference_cols=[HOSPITAL_ID, ADMIT_TIMESTAMP, DISCHARGE_TIMESTAMP]\n",
    ")\n",
    "#feature_handler.save(BASE_DATA_PATH, \"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb028c06-7771-46db-a291-f7621471ef5e",
   "metadata": {},
   "source": [
    "## Create new feature handler, load saved features from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0836f236-1f0b-46e8-90b8-8e811adcbe2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 09:57:53,884 \u001b[1;37mINFO\u001b[0m cyclops.feature_handler - Loading features from file...\n",
      "2022-07-14 09:57:53,886 \u001b[1;37mINFO\u001b[0m cyclops.feature_handler - Found file to load for static features...\n",
      "2022-07-14 09:57:53,887 \u001b[1;37mINFO\u001b[0m cyclops.feature_handler - Successfully loaded static features from file...\n",
      "2022-07-14 09:57:53,969 \u001b[1;37mINFO\u001b[0m cyclops.feature_handler - Found file to load for temporal features...\n",
      "2022-07-14 09:58:16,586 \u001b[1;37mINFO\u001b[0m cyclops.feature_handler - Successfully loaded temporal features from file...\n"
     ]
    }
   ],
   "source": [
    "feature_handler1 = FeatureHandler()\n",
    "feature_handler1.load(BASE_DATA_PATH, \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "443ad860-99aa-4423-b660-946d91891302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106, 8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_handler1.features[\"temporal\"].columns), len(\n",
    "    feature_handler1.features[\"static\"].columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49719bee-1c6e-4f23-9dd9-a49f687f5370",
   "metadata": {},
   "source": [
    "## Impute temporal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5eddb97e-e050-43fb-9b60-26f204260706",
   "metadata": {},
   "outputs": [],
   "source": [
    "static = feature_handler1.features[\"static\"]\n",
    "temporal = feature_handler1.features[\"temporal\"]\n",
    "\n",
    "numerical_cols = feature_handler1.get_numerical_feature_names()[\"temporal\"]\n",
    "cat_cols = feature_handler1.get_categorical_feature_names()[\"temporal\"]\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "#     print(temporal.isna().sum(axis=0))\n",
    "# numerical_cols, cat_cols\n",
    "\n",
    "\n",
    "# Remove encounters based on missingness.\n",
    "# print(temporal.shape)\n",
    "# encounter_ids = set(temporal.index.get_level_values(0))\n",
    "# for encounter_id in encounter_ids:\n",
    "#     features_encounter = temporal.loc[encounter_id]\n",
    "#     not_indicators = [col_name for col_name in temporal.columns if 'indicator' not in col_name]\n",
    "#     num_na_features = features_encounter[not_indicators].isna().sum().sum()\n",
    "#     fraction_missing = num_na_features / (\n",
    "#         len(features_encounter) * len(temporal.columns)\n",
    "#     )\n",
    "#     if fraction_missing > 0.4:\n",
    "#         temporal = temporal.drop(encounter_id, level=ENCOUNTER_ID)\n",
    "# num_encounters_dropped = len(encounter_ids) - len(\n",
    "#     set(temporal.index.get_level_values(0))\n",
    "# )\n",
    "# print(num_encounters_dropped)\n",
    "\n",
    "# mean over features (incomplete)\n",
    "# imputer(temporal[numerical_cols]).fillna(temporal[numerical_cols].mean(level=0, numeric_only=True, skipna=True))\n",
    "\n",
    "# Forward-fill, then backward\n",
    "temporal[numerical_cols] = temporal[numerical_cols].ffill().bfill()\n",
    "\n",
    "# Check no more missingness!\n",
    "assert not temporal.isna().sum().sum() and not static.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b4b887-e9da-4d69-b13e-7649ca3a6659",
   "metadata": {},
   "source": [
    "## Add static features to temporal, (duplicate for each timestep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ce62b29-67dd-4624-b973-071464e18fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with both static and temporal features.\n",
    "merged_static_temporal = temporal.combine_first(static)\n",
    "numerical_cols += [\"age\"]\n",
    "\n",
    "# Train model with just temporal features\n",
    "# merged_static_temporal = temporal\n",
    "# static"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431b63a8-58d1-41b7-9793-a8406514b6c1",
   "metadata": {},
   "source": [
    "## Create labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "155c4ae8-5ed3-4ab4-8d0b-c2d5d97d7181",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encounters_mortality_within_risk_timeframe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((num_encounters, num_timesteps))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Set mortality within timeframe encounters to all 1s.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m labels[\n\u001b[1;32m     10\u001b[0m     [\n\u001b[1;32m     11\u001b[0m         encounter_ids\u001b[38;5;241m.\u001b[39mindex(enc_id)\n\u001b[0;32m---> 12\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m enc_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[43mencounters_mortality_within_risk_timeframe\u001b[49m[ENCOUNTER_ID])\n\u001b[1;32m     13\u001b[0m     ]\n\u001b[1;32m     14\u001b[0m ] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Get which timestep discharge occurs and set those and following timesteps label values to be -1.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m aggregated_discharge_events \u001b[38;5;241m=\u001b[39m aggregated_events\u001b[38;5;241m.\u001b[39mloc[\n\u001b[1;32m     18\u001b[0m     aggregated_events[EVENT_NAME] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdischarge\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     19\u001b[0m ]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'encounters_mortality_within_risk_timeframe' is not defined"
     ]
    }
   ],
   "source": [
    "num_timesteps = int(AGGREGATION_WINDOW / AGGREGATION_BUCKET_SIZE)\n",
    "encounter_ids = list(merged_static_temporal.index.get_level_values(0).unique())\n",
    "num_encounters = len(encounter_ids)\n",
    "\n",
    "# All zeroes.\n",
    "labels = np.zeros((num_encounters, num_timesteps))\n",
    "\n",
    "# Set mortality within timeframe encounters to all 1s.\n",
    "labels[\n",
    "    [\n",
    "        encounter_ids.index(enc_id)\n",
    "        for enc_id in list(encounters_mortality_within_risk_timeframe[ENCOUNTER_ID])\n",
    "    ]\n",
    "] = 1\n",
    "\n",
    "# Get which timestep discharge occurs and set those and following timesteps label values to be -1.\n",
    "aggregated_discharge_events = aggregated_events.loc[\n",
    "    aggregated_events[EVENT_NAME] == \"discharge\"\n",
    "]\n",
    "aggregated_mortality_events = aggregated_events.loc[\n",
    "    aggregated_events[EVENT_NAME] == \"death\"\n",
    "]\n",
    "for enc_id in list(aggregated_discharge_events[ENCOUNTER_ID]):\n",
    "    timestep_discharge = aggregated_discharge_events.loc[\n",
    "        aggregated_discharge_events[ENCOUNTER_ID] == enc_id\n",
    "    ][\"timestep\"]\n",
    "    labels[encounter_ids.index(enc_id)][int(timestep_discharge) + 1 :] = -1\n",
    "\n",
    "# Lookahead for each timestep, and see if death occurs in risk timeframe.\n",
    "for enc_id in list(encounters_mortality_within_risk_timeframe[ENCOUNTER_ID]):\n",
    "    mortality_encounter = mortality_events.loc[mortality_events[ENCOUNTER_ID] == enc_id]\n",
    "    ts_ends = timestep_end_timestamps.loc[enc_id][\"timestep_end_timestamp\"]\n",
    "    mortality_ts = mortality_encounter[\"event_timestamp\"]\n",
    "    for ts_idx, ts_end in enumerate(ts_ends):\n",
    "        if not (\n",
    "            mortality_ts <= ts_end + pd.to_timedelta(timeframe * 24, unit=\"h\")\n",
    "        ).all():\n",
    "            labels[encounter_ids.index(enc_id)][ts_idx] = 0\n",
    "\n",
    "\n",
    "mortality_risk_targets = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da874af-fc43-4373-86b5-e3296893c27b",
   "metadata": {},
   "source": [
    "## Create train/val/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67a57ca-2e72-4f17-8452-3c3e5f4d6906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_split(\n",
    "    encounters: pd.DataFrame,\n",
    "    fractions: Optional[List] = [0.8, 0.2],\n",
    "    split_column: Optional[str] = None,\n",
    "    split_values: List = None,\n",
    "    seed: int = 3,\n",
    ") -> tuple:\n",
    "    \"\"\"Split encounters into train/test.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    encounters: pandas.DataFrame\n",
    "        Dataframe with encounter IDs.\n",
    "    fractions: list, optional\n",
    "        Fraction of samples to use for train, test sets.\n",
    "    split_column: str, optional\n",
    "        If 'split_column' is specified, then that column is used to split.\n",
    "    split_values: list, optional\n",
    "        Along with 'split_column', a list of lists can be specified for filtering.\n",
    "        e.g. [[2008], [2009, 2010]] for train/test split based on year.\n",
    "    seed: int, optional\n",
    "        Seed for random number generator.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (train IDs, test IDs)\n",
    "\n",
    "    \"\"\"\n",
    "    if split_column:\n",
    "        if split_column not in encounters.columns:\n",
    "            raise ValueError(\"Specified 'split column' not found in input dataframe\")\n",
    "        if not split_values:\n",
    "            raise ValueError(\"Specify train/test split values for the 'split column'.!\")\n",
    "        train_encounters = encounters[ENCOUNTER_ID].loc[\n",
    "            encounters[split_column].isin(split_values[0])\n",
    "        ]\n",
    "        test_encounters = encounters[ENCOUNTER_ID].loc[\n",
    "            encounters[split_column].isin(split_values[1])\n",
    "        ]\n",
    "        return train_encounters, test_encounters\n",
    "\n",
    "    encounter_ids = list(encounters[ENCOUNTER_ID].unique())\n",
    "    random.seed(seed)\n",
    "    random.shuffle(encounter_ids)\n",
    "    num_train = int(fractions[0] * len(encounter_ids))\n",
    "\n",
    "    return encounter_ids[0:num_train], encounter_ids[num_train:]\n",
    "\n",
    "\n",
    "split_type = \"hospital_id\"\n",
    "\n",
    "if split_type == \"year\":\n",
    "    encounters_train_val_test[\"year\"] = encounters_train_val_test[\n",
    "        \"admit_timestamp\"\n",
    "    ].dt.year\n",
    "    train_ids, val_test_ids = create_train_test_split(\n",
    "        encounters_train_val_test,\n",
    "        split_column=\"year\",\n",
    "        split_values=[[2015, 2016, 2017, 2018, 2019], [2020]],\n",
    "    )\n",
    "    encounters_train_val_test[HOSPITAL_ID].value_counts(), encounters_train_val_test[\n",
    "        \"year\"\n",
    "    ].value_counts()\n",
    "elif split_type == \"hospital_id\":\n",
    "    train_ids, val_test_ids = create_train_test_split(\n",
    "        encounters_train_val_test,\n",
    "        split_column=HOSPITAL_ID,\n",
    "        split_values=[[\"SBK\", \"UHNTG\", \"THPC\", \"THPM\", \"UHNTW\", \"SMH\"], [\"MSH\"]],\n",
    "    )\n",
    "elif split_type == \"random\":\n",
    "    train_ids, val_test_ids = create_train_test_split(encounters_train_val_test)\n",
    "\n",
    "\n",
    "val_ids, test_ids = create_train_test_split(\n",
    "    encounters_train_val_test.loc[\n",
    "        encounters_train_val_test[ENCOUNTER_ID].isin(val_test_ids)\n",
    "    ],\n",
    "    [0.5, 0.5],\n",
    ")\n",
    "print(\n",
    "    f\"Train set: {len(train_ids)}, Val set: {len(val_ids)}, Test set: {len(test_ids)}\"\n",
    ")\n",
    "\n",
    "X = merged_static_temporal[\n",
    "    np.in1d(temporal.index.get_level_values(0), static.index.get_level_values(0))\n",
    "]\n",
    "\n",
    "y_train, y_val, y_test = [\n",
    "    mortality_risk_targets[np.in1d(encounter_ids, ids)]\n",
    "    for ids in [train_ids, val_ids, test_ids]\n",
    "]\n",
    "X_train, X_val, X_test = [\n",
    "    X[np.in1d(X.index.get_level_values(0), ids)]\n",
    "    for ids in [train_ids, val_ids, test_ids]\n",
    "]\n",
    "\n",
    "len(X), len(X_train), len(X_val), len(X_test), len(mortality_risk_targets), len(\n",
    "    y_train\n",
    "), len(y_val), len(y_test)\n",
    "assert len(X.index.get_level_values(0).unique()) == len(mortality_risk_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f36dce7-2857-45bd-91af-69a7f4485597",
   "metadata": {},
   "source": [
    "## Save train/val/test ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a95142-e91f-43a9-a7b2-0e8a3c8b185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids_df = pd.DataFrame({\"train\": train_ids})\n",
    "val_ids_df = pd.DataFrame({\"val\": val_ids})\n",
    "test_ids_df = pd.DataFrame({\"test\": test_ids})\n",
    "train_val_test_ids = pd.concat([train_ids_df, val_ids_df, test_ids_df], axis=1)\n",
    "save_dataframe(\n",
    "    train_val_test_ids, os.path.join(BASE_DATA_PATH, split_type, \"train_val_test_ids\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bccd89-2893-45ea-b2b9-07629f4693c6",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cfd46a-5ec5-4cc0-8291-fd2261abbbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train_normalized = X_train.copy()\n",
    "X_val_normalized = X_val.copy()\n",
    "X_test_normalized = X_test.copy()\n",
    "\n",
    "for col in numerical_cols:\n",
    "    scaler = StandardScaler().fit(X_train[col].values.reshape(-1, 1))\n",
    "    X_train_normalized[col] = pd.Series(\n",
    "        np.squeeze(scaler.transform(X_train[col].values.reshape(-1, 1))),\n",
    "        index=X_train[col].index,\n",
    "    )\n",
    "    X_val_normalized[col] = pd.Series(\n",
    "        np.squeeze(scaler.transform(X_val[col].values.reshape(-1, 1))),\n",
    "        index=X_val[col].index,\n",
    "    )\n",
    "    X_test_normalized[col] = pd.Series(\n",
    "        np.squeeze(scaler.transform(X_test[col].values.reshape(-1, 1))),\n",
    "        index=X_test[col].index,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a072b711-31cc-4693-8b41-100f4dd39265",
   "metadata": {},
   "source": [
    "## Save inputs and labels as numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a168e69-a265-426f-9ab2-2a0cba495691",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(BASE_DATA_PATH, split_type), exist_ok=True)\n",
    "\n",
    "X_train_normalized.to_parquet(\n",
    "    os.path.join(BASE_DATA_PATH, split_type, \"X_train.parquet\")\n",
    ")\n",
    "X_val_normalized.to_parquet(os.path.join(BASE_DATA_PATH, split_type, \"X_val.parquet\"))\n",
    "X_test_normalized.to_parquet(os.path.join(BASE_DATA_PATH, split_type, \"X_test.parquet\"))\n",
    "\n",
    "np.save(os.path.join(BASE_DATA_PATH, split_type, \"y_train.npy\"), y_train)\n",
    "np.save(os.path.join(BASE_DATA_PATH, split_type, \"y_val.npy\"), y_val)\n",
    "np.save(os.path.join(BASE_DATA_PATH, split_type, \"y_test.npy\"), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70504f5c-eeed-43c7-aa08-e63e81cb5b85",
   "metadata": {},
   "source": [
    "## Load train/val/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d301151-c865-4525-bf86-1e0f5bdde1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized = pd.read_parquet(\n",
    "    os.path.join(BASE_DATA_PATH, split_type, \"X_train.parquet\")\n",
    ")\n",
    "X_val_normalized = pd.read_parquet(\n",
    "    os.path.join(BASE_DATA_PATH, split_type, \"X_val.parquet\")\n",
    ")\n",
    "X_test_normalized = pd.read_parquet(\n",
    "    os.path.join(BASE_DATA_PATH, split_type, \"X_test.parquet\")\n",
    ")\n",
    "\n",
    "y_train = np.load(os.path.join(BASE_DATA_PATH, split_type, \"y_train.npy\"))\n",
    "y_val = np.load(os.path.join(BASE_DATA_PATH, split_type, \"y_val.npy\"))\n",
    "y_test = np.load(os.path.join(BASE_DATA_PATH, split_type, \"y_test.npy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3219bbb-2ebb-42fb-879b-8e8f06d69861",
   "metadata": {},
   "source": [
    "## Reshape inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10d73ba-d526-45b6-97e5-8d56f3442b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_inputs(inputs, num_timesteps):\n",
    "    inputs = inputs.unstack()\n",
    "    num_encounters = inputs.shape[0]\n",
    "    inputs = inputs.values.reshape((num_encounters, num_timesteps, -1))\n",
    "\n",
    "    return inputs\n",
    "\n",
    "\n",
    "X_train_normalized_npy = reshape_inputs(X_train_normalized, num_timesteps)\n",
    "X_val_normalized_npy = reshape_inputs(X_val_normalized, num_timesteps)\n",
    "X_test_normalized_npy = reshape_inputs(X_test_normalized, num_timesteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a264bcee-1271-464a-a392-d8e369ec77e7",
   "metadata": {},
   "source": [
    "## Save inputs as npy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8df48d-7ecc-46c9-904e-82a9637368da",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(BASE_DATA_PATH, split_type, \"X_train.npy\"), X_train_normalized_npy)\n",
    "np.save(os.path.join(BASE_DATA_PATH, split_type, \"X_val.npy\"), X_val_normalized_npy)\n",
    "np.save(os.path.join(BASE_DATA_PATH, split_type, \"X_test.npy\"), X_test_normalized_npy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6812a9a8-1966-48a1-9094-66db6b4bde31",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25f4a47-a2f2-4071-8ae4-0b13957105a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encounter_id = random.choice(encounter_ids)\n",
    "encounter_id = random.choice(list(encounters_data_train_val_test[ENCOUNTER_ID]))\n",
    "# encounter_id = 13772609\n",
    "\n",
    "# Show examples:\n",
    "# 12779290, 13772609 - lookahead\n",
    "# 11454928, 15795997 - no mortality\n",
    "# 15253874 - all 1s\n",
    "\n",
    "print(encounter_id)\n",
    "combined_events_encounter = combined_events.loc[\n",
    "    combined_events[\"encounter_id\"] == encounter_id\n",
    "]\n",
    "fig = plot_timeline(combined_events_encounter, return_fig=True)\n",
    "\n",
    "fig = fig.update_layout(width=2000, height=800)\n",
    "\n",
    "# ts_starts = timestep_start_timestamps.loc[encounter_id][\"timestep_start_timestamp\"]\n",
    "# ts_ends = timestep_end_timestamps.loc[encounter_id][\"timestep_end_timestamp\"]\n",
    "# for ts_end in ts_ends:\n",
    "#     fig.add_vline(ts_end)\n",
    "\n",
    "# label_encounter = labels[encounter_ids.index(encounter_id)]\n",
    "\n",
    "# for i in range(num_timesteps):\n",
    "#     label_ts = label_encounter[i]\n",
    "#     color_map = {-1: \"grey\", 0: \"green\", 1: \"red\"}\n",
    "#     fig.add_vrect(\n",
    "#         x0=ts_starts[i],\n",
    "#         x1=ts_ends[i],\n",
    "#         fillcolor=color_map[label_ts],\n",
    "#         opacity=0.25,\n",
    "#         line_width=0,\n",
    "#     )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee092262-8a77-4ccc-933f-a4d316e28643",
   "metadata": {},
   "source": [
    "## TODO: Test out these imputation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1010c8-3c13-4dcd-803d-f5fe094749a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_simple_v1(\n",
    "    dataframe: pd.DataFrame, time_index: str = TIMESTEP\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Impute features using 'Simple' method.\n",
    "\n",
    "    Concatenate the forward filled value, the mask of the measurement,\n",
    "    and the time of the last measurement.\n",
    "\n",
    "    Z. Che, S. Purushotham, K. Cho, D. Sontag, and Y. Liu,\n",
    "    \"Recurrent Neural Networks for Multivariate Time Series with Missing Values,\"\n",
    "    Scientific Reports, vol. 8, no. 1, p. 6085, Apr 2018.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe: pandas.DataFrame\n",
    "        Temporal features dataframe.\n",
    "    time_index: str, optional\n",
    "        The name of the time-series index.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "     Dataframe after applying imputation.\n",
    "\n",
    "    \"\"\"\n",
    "    # Mask missingness.\n",
    "    masked_df = pd.isna(dataframe)\n",
    "    masked_df = masked_df.apply(pd.to_numeric)\n",
    "\n",
    "    # Compute time since last measurement.\n",
    "    index_of_time = list(dataframe.index.names).index(time_index)\n",
    "    time_in = [item[index_of_time] for item in dataframe.index.tolist()]\n",
    "    time_df = dataframe.copy()\n",
    "    for col in time_df.columns.tolist():\n",
    "        time_df[col] = time_in\n",
    "    time_df[masked_df] = np.nan\n",
    "\n",
    "    # Concatenate the dataframes.\n",
    "    df_prime = pd.concat(\n",
    "        [dataframe, masked_df, time_df], axis=1, keys=[\"measurement\", \"mask\", \"time\"]\n",
    "    )\n",
    "    df_prime.columns = df_prime.columns.rename(\"impute_simple\", level=0)\n",
    "\n",
    "    # Fill each dataframe using either ffill or mean.\n",
    "    df_prime = df_prime.fillna(method=\"ffill\").unstack().fillna(0)\n",
    "\n",
    "    # Swap the levels so that the simple imputation feature is the lowest value.\n",
    "    col_level_names = list(df_prime.columns.names)\n",
    "    col_level_names.append(col_level_names.pop(0))\n",
    "\n",
    "    df_prime = df_prime.reorder_levels(col_level_names, axis=1)\n",
    "    df_prime.sort_index(axis=1, inplace=True)\n",
    "\n",
    "    return df_prime\n",
    "\n",
    "\n",
    "def impute_simple_v2(mean_vals):\n",
    "    \"\"\"Another version of 'simple' imputation.\"\"\"\n",
    "    idx = pd.IndexSlice\n",
    "\n",
    "    mask = 1 - mean_vals.isna()\n",
    "    measurement = mean_vals.copy()\n",
    "\n",
    "    subset_data = measurement.loc[idx[:, :, 0], :]\n",
    "    data_means = measurement.mean()\n",
    "    subset_data = subset_data.fillna(data_means)\n",
    "    measurement.loc[idx[:, :, 0], :] = subset_data.values\n",
    "    measurement = measurement.ffill()\n",
    "\n",
    "    is_absent = 1 - mask\n",
    "    hours_of_absence = is_absent.groupby([\"patient_id\", \"genc_id\"]).cumsum()\n",
    "    time_df = hours_of_absence - hours_of_absence[is_absent == 0].fillna(method=\"ffill\")\n",
    "    time_df = time_df.fillna(0)\n",
    "\n",
    "    final_data = pd.concat(\n",
    "        [measurement, mask, time_df], keys=[\"measurement\", \"mask\", \"time\"], axis=1\n",
    "    )\n",
    "    final_data.columns = final_data.columns.swaplevel(0, 1)\n",
    "    final_data.sort_index(axis=\"columns\", inplace=True)\n",
    "\n",
    "    nancols = 0\n",
    "    try:\n",
    "        nancols = np.sum(\n",
    "            [a == 0 for a in final_data.loc[:, idx[:, \"mask\"]].sum().values]\n",
    "        )\n",
    "        print(nancols)\n",
    "    except:\n",
    "        print(\"could not get nancols\")\n",
    "        pass\n",
    "\n",
    "    print(nancols, \"/\", len(sorted(set(final_data.columns.get_level_values(0)))))\n",
    "    return final_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyclops-KKtuQLwg-py3.9",
   "language": "python",
   "name": "cyclops-kktuqlwg-py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

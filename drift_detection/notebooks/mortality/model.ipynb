{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd4e001b-4921-4a4f-8c2c-0c364d082a3f",
   "metadata": {},
   "source": [
    "## Train temporal models for mortality risk prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4681dab-9200-4063-9544-f2013bdcd2ba",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cce5e9ec-e3d0-4719-a7ee-43e88dcde8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn import metrics\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../..\")\n",
    "from cyclops.utils.file import load_dataframe, save_dataframe\n",
    "from drift_detection.baseline_models.temporal.pytorch.optimizer import Optimizer\n",
    "from drift_detection.baseline_models.temporal.pytorch.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e583ae-7a70-49d1-9e93-26b692c85d89",
   "metadata": {},
   "source": [
    "## Load train/val/test inputs and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12066550-01d2-4869-a96b-2ab9c37171ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 12779\n",
      "Val set size: 3195\n",
      "Test set size: 1082\n",
      "Num features: 108\n"
     ]
    }
   ],
   "source": [
    "DIR = \"/mnt/nfs/project/delirium/drift_exp/JULY-04-2022\"\n",
    "split_type = \"covid\"\n",
    "\n",
    "X_train = np.load(os.path.join(DIR, split_type, \"X_train.npy\"))\n",
    "X_val = np.load(os.path.join(DIR, split_type, \"X_val.npy\"))\n",
    "X_test = np.load(os.path.join(DIR, split_type, \"X_test.npy\"))\n",
    "\n",
    "y_train = np.load(os.path.join(DIR, split_type, \"y_train.npy\"))\n",
    "y_val = np.load(os.path.join(DIR, split_type, \"y_val.npy\"))\n",
    "y_test = np.load(os.path.join(DIR, split_type, \"y_test.npy\"))\n",
    "\n",
    "print(\"Train set size:\", X_train.shape[0])\n",
    "print(\"Val set size:\", X_val.shape[0])\n",
    "print(\"Test set size:\", X_test.shape[0])\n",
    "\n",
    "print(\"Num features:\", X_train.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcb16cf4-7838-4757-850e-913093c42181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Train    Val  Test\n",
      "-1.0  11550   2800  1083\n",
      " 0.0  43734  10702  3121\n",
      " 1.0  21390   5668  2288\n"
     ]
    }
   ],
   "source": [
    "unique, train_counts = np.unique(y_train, return_counts=True)\n",
    "unique, val_counts = np.unique(y_val, return_counts=True)\n",
    "unique, test_counts = np.unique(y_test, return_counts=True)\n",
    "print(pd.DataFrame({'Train':train_counts,'Val': val_counts, 'Test':test_counts}, index=unique))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde55789-cb88-49db-9121-27cbdbddc46b",
   "metadata": {},
   "source": [
    "## Model and training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "810aab27-5fc4-4271-98eb-16f0917eb520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (lstm): LSTM(108, 64, num_layers=2, batch_first=True, dropout=0.2)\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dim = 1\n",
    "batch_size = 64\n",
    "input_dim = X_train.shape[2]\n",
    "timesteps = X_train.shape[1]\n",
    "hidden_dim = 64\n",
    "layer_dim = 2\n",
    "dropout = 0.2\n",
    "n_epochs = 256\n",
    "learning_rate = 2e-3\n",
    "weight_decay = 1e-6\n",
    "last_timestep_only = False\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "X_train_inputs = X_train\n",
    "X_val_inputs = X_val\n",
    "X_test_inputs = X_test\n",
    "\n",
    "train_dataset = get_data(X_train_inputs, y_train)\n",
    "train_loader = train_dataset.to_loader(batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = get_data(X_val_inputs, y_val)\n",
    "val_loader = val_dataset.to_loader(batch_size)\n",
    "\n",
    "model_params = {\n",
    "    \"device\": device,\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"layer_dim\": layer_dim,\n",
    "    \"output_dim\": output_dim,\n",
    "    \"dropout_prob\": dropout,\n",
    "    \"last_timestep_only\": last_timestep_only,\n",
    "}\n",
    "\n",
    "model = get_temporal_model(\"lstm\", model_params).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388af42e-49ac-48c5-a285-8ce66a714518",
   "metadata": {},
   "source": [
    "## Training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89bdb2aa-8cb2-4632-b6bd-753033903716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/256] Training loss: 0.5061\t Validation loss: 0.5383\n",
      "[2/256] Training loss: 0.4997\t Validation loss: 0.5349\n",
      "[3/256] Training loss: 0.4960\t Validation loss: 0.5344\n",
      "[4/256] Training loss: 0.4931\t Validation loss: 0.5315\n",
      "[5/256] Training loss: 0.4921\t Validation loss: 0.5318\n",
      "[6/256] Training loss: 0.4889\t Validation loss: 0.5300\n",
      "[7/256] Training loss: 0.4887\t Validation loss: 0.5318\n",
      "[8/256] Training loss: 0.4861\t Validation loss: 0.5303\n",
      "[9/256] Training loss: 0.4860\t Validation loss: 0.5294\n",
      "[10/256] Training loss: 0.4848\t Validation loss: 0.5293\n",
      "[11/256] Training loss: 0.4835\t Validation loss: 0.5289\n",
      "[12/256] Training loss: 0.4826\t Validation loss: 0.5284\n",
      "[13/256] Training loss: 0.4830\t Validation loss: 0.5287\n",
      "[14/256] Training loss: 0.4822\t Validation loss: 0.5272\n",
      "[15/256] Training loss: 0.4809\t Validation loss: 0.5285\n",
      "[16/256] Training loss: 0.4802\t Validation loss: 0.5271\n",
      "[17/256] Training loss: 0.4797\t Validation loss: 0.5267\n",
      "[18/256] Training loss: 0.4788\t Validation loss: 0.5271\n",
      "[19/256] Training loss: 0.4778\t Validation loss: 0.5268\n",
      "[20/256] Training loss: 0.4769\t Validation loss: 0.5279\n",
      "[21/256] Training loss: 0.4768\t Validation loss: 0.5264\n",
      "[22/256] Training loss: 0.4758\t Validation loss: 0.5263\n",
      "[23/256] Training loss: 0.4750\t Validation loss: 0.5257\n",
      "[24/256] Training loss: 0.4747\t Validation loss: 0.5256\n",
      "[25/256] Training loss: 0.4743\t Validation loss: 0.5260\n",
      "[26/256] Training loss: 0.4740\t Validation loss: 0.5255\n",
      "[27/256] Training loss: 0.4736\t Validation loss: 0.5273\n",
      "[28/256] Training loss: 0.4727\t Validation loss: 0.5250\n",
      "[29/256] Training loss: 0.4718\t Validation loss: 0.5250\n",
      "[30/256] Training loss: 0.4725\t Validation loss: 0.5249\n",
      "[31/256] Training loss: 0.4707\t Validation loss: 0.5249\n",
      "[32/256] Training loss: 0.4693\t Validation loss: 0.5245\n",
      "[33/256] Training loss: 0.4694\t Validation loss: 0.5241\n",
      "[34/256] Training loss: 0.4701\t Validation loss: 0.5244\n",
      "[35/256] Training loss: 0.4706\t Validation loss: 0.5240\n",
      "[36/256] Training loss: 0.4677\t Validation loss: 0.5243\n",
      "[37/256] Training loss: 0.4679\t Validation loss: 0.5253\n",
      "[38/256] Training loss: 0.4686\t Validation loss: 0.5236\n",
      "[39/256] Training loss: 0.4685\t Validation loss: 0.5237\n",
      "[40/256] Training loss: 0.4677\t Validation loss: 0.5235\n",
      "[41/256] Training loss: 0.4673\t Validation loss: 0.5241\n",
      "[42/256] Training loss: 0.4669\t Validation loss: 0.5235\n",
      "[43/256] Training loss: 0.4666\t Validation loss: 0.5227\n",
      "[44/256] Training loss: 0.4661\t Validation loss: 0.5239\n",
      "[45/256] Training loss: 0.4647\t Validation loss: 0.5237\n",
      "[46/256] Training loss: 0.4653\t Validation loss: 0.5242\n",
      "[47/256] Training loss: 0.4647\t Validation loss: 0.5243\n",
      "[48/256] Training loss: 0.4646\t Validation loss: 0.5235\n",
      "[49/256] Training loss: 0.4643\t Validation loss: 0.5235\n",
      "[50/256] Training loss: 0.4639\t Validation loss: 0.5237\n",
      "[51/256] Training loss: 0.4644\t Validation loss: 0.5238\n",
      "[52/256] Training loss: 0.4632\t Validation loss: 0.5237\n",
      "[53/256] Training loss: 0.4629\t Validation loss: 0.5232\n",
      "[54/256] Training loss: 0.4618\t Validation loss: 0.5242\n",
      "[55/256] Training loss: 0.4616\t Validation loss: 0.5237\n",
      "[56/256] Training loss: 0.4618\t Validation loss: 0.5240\n",
      "[57/256] Training loss: 0.4606\t Validation loss: 0.5238\n",
      "[58/256] Training loss: 0.4599\t Validation loss: 0.5239\n",
      "[59/256] Training loss: 0.4608\t Validation loss: 0.5234\n",
      "[60/256] Training loss: 0.4599\t Validation loss: 0.5231\n",
      "[61/256] Training loss: 0.4589\t Validation loss: 0.5230\n",
      "[62/256] Training loss: 0.4596\t Validation loss: 0.5237\n",
      "[63/256] Training loss: 0.4585\t Validation loss: 0.5240\n",
      "[64/256] Training loss: 0.4580\t Validation loss: 0.5235\n",
      "[65/256] Training loss: 0.4578\t Validation loss: 0.5235\n",
      "[66/256] Training loss: 0.4574\t Validation loss: 0.5238\n",
      "[67/256] Training loss: 0.4575\t Validation loss: 0.5236\n",
      "[68/256] Training loss: 0.4565\t Validation loss: 0.5234\n",
      "[69/256] Training loss: 0.4573\t Validation loss: 0.5231\n",
      "[70/256] Training loss: 0.4558\t Validation loss: 0.5239\n",
      "[71/256] Training loss: 0.4568\t Validation loss: 0.5237\n",
      "[72/256] Training loss: 0.4544\t Validation loss: 0.5239\n",
      "[73/256] Training loss: 0.4551\t Validation loss: 0.5244\n",
      "[74/256] Training loss: 0.4553\t Validation loss: 0.5245\n",
      "[75/256] Training loss: 0.4558\t Validation loss: 0.5245\n",
      "[76/256] Training loss: 0.4539\t Validation loss: 0.5241\n",
      "[77/256] Training loss: 0.4537\t Validation loss: 0.5242\n",
      "[78/256] Training loss: 0.4540\t Validation loss: 0.5243\n",
      "[79/256] Training loss: 0.4525\t Validation loss: 0.5250\n",
      "[80/256] Training loss: 0.4525\t Validation loss: 0.5242\n",
      "[81/256] Training loss: 0.4523\t Validation loss: 0.5247\n",
      "[82/256] Training loss: 0.4522\t Validation loss: 0.5243\n",
      "[83/256] Training loss: 0.4522\t Validation loss: 0.5242\n",
      "[84/256] Training loss: 0.4508\t Validation loss: 0.5248\n",
      "[85/256] Training loss: 0.4514\t Validation loss: 0.5248\n",
      "[86/256] Training loss: 0.4514\t Validation loss: 0.5244\n",
      "[87/256] Training loss: 0.4514\t Validation loss: 0.5249\n",
      "[88/256] Training loss: 0.4508\t Validation loss: 0.5244\n",
      "[89/256] Training loss: 0.4499\t Validation loss: 0.5249\n",
      "[90/256] Training loss: 0.4502\t Validation loss: 0.5246\n",
      "[91/256] Training loss: 0.4509\t Validation loss: 0.5253\n",
      "[92/256] Training loss: 0.4484\t Validation loss: 0.5248\n",
      "[93/256] Training loss: 0.4499\t Validation loss: 0.5248\n",
      "[94/256] Training loss: 0.4501\t Validation loss: 0.5249\n",
      "[95/256] Training loss: 0.4489\t Validation loss: 0.5248\n",
      "[96/256] Training loss: 0.4476\t Validation loss: 0.5253\n",
      "[97/256] Training loss: 0.4486\t Validation loss: 0.5253\n",
      "[98/256] Training loss: 0.4480\t Validation loss: 0.5261\n",
      "[99/256] Training loss: 0.4468\t Validation loss: 0.5253\n",
      "[100/256] Training loss: 0.4479\t Validation loss: 0.5253\n",
      "[101/256] Training loss: 0.4490\t Validation loss: 0.5255\n",
      "[102/256] Training loss: 0.4470\t Validation loss: 0.5253\n",
      "[103/256] Training loss: 0.4455\t Validation loss: 0.5266\n",
      "[104/256] Training loss: 0.4453\t Validation loss: 0.5256\n",
      "[105/256] Training loss: 0.4446\t Validation loss: 0.5264\n",
      "[106/256] Training loss: 0.4454\t Validation loss: 0.5263\n",
      "[107/256] Training loss: 0.4441\t Validation loss: 0.5266\n",
      "[108/256] Training loss: 0.4445\t Validation loss: 0.5266\n",
      "[109/256] Training loss: 0.4435\t Validation loss: 0.5276\n",
      "[110/256] Training loss: 0.4436\t Validation loss: 0.5269\n",
      "[111/256] Training loss: 0.4444\t Validation loss: 0.5267\n",
      "[112/256] Training loss: 0.4445\t Validation loss: 0.5269\n",
      "[113/256] Training loss: 0.4450\t Validation loss: 0.5268\n",
      "[114/256] Training loss: 0.4438\t Validation loss: 0.5270\n",
      "[115/256] Training loss: 0.4433\t Validation loss: 0.5272\n",
      "[116/256] Training loss: 0.4429\t Validation loss: 0.5276\n",
      "[117/256] Training loss: 0.4438\t Validation loss: 0.5271\n",
      "[118/256] Training loss: 0.4427\t Validation loss: 0.5267\n",
      "[119/256] Training loss: 0.4419\t Validation loss: 0.5276\n",
      "[120/256] Training loss: 0.4423\t Validation loss: 0.5278\n",
      "[121/256] Training loss: 0.4426\t Validation loss: 0.5278\n",
      "[122/256] Training loss: 0.4409\t Validation loss: 0.5277\n",
      "[123/256] Training loss: 0.4409\t Validation loss: 0.5279\n",
      "[124/256] Training loss: 0.4408\t Validation loss: 0.5280\n",
      "[125/256] Training loss: 0.4413\t Validation loss: 0.5284\n",
      "[126/256] Training loss: 0.4385\t Validation loss: 0.5280\n",
      "[127/256] Training loss: 0.4403\t Validation loss: 0.5279\n",
      "[128/256] Training loss: 0.4393\t Validation loss: 0.5286\n",
      "[129/256] Training loss: 0.4383\t Validation loss: 0.5287\n",
      "[130/256] Training loss: 0.4383\t Validation loss: 0.5290\n",
      "[131/256] Training loss: 0.4380\t Validation loss: 0.5291\n",
      "[132/256] Training loss: 0.4399\t Validation loss: 0.5291\n",
      "[133/256] Training loss: 0.4394\t Validation loss: 0.5290\n",
      "[134/256] Training loss: 0.4399\t Validation loss: 0.5288\n",
      "[135/256] Training loss: 0.4391\t Validation loss: 0.5291\n",
      "[136/256] Training loss: 0.4381\t Validation loss: 0.5292\n",
      "[137/256] Training loss: 0.4381\t Validation loss: 0.5291\n",
      "[138/256] Training loss: 0.4371\t Validation loss: 0.5293\n",
      "[139/256] Training loss: 0.4383\t Validation loss: 0.5292\n",
      "[140/256] Training loss: 0.4373\t Validation loss: 0.5292\n",
      "[141/256] Training loss: 0.4379\t Validation loss: 0.5294\n",
      "[142/256] Training loss: 0.4373\t Validation loss: 0.5295\n",
      "[143/256] Training loss: 0.4381\t Validation loss: 0.5294\n",
      "[144/256] Training loss: 0.4364\t Validation loss: 0.5299\n",
      "[145/256] Training loss: 0.4365\t Validation loss: 0.5298\n",
      "[146/256] Training loss: 0.4374\t Validation loss: 0.5298\n",
      "[147/256] Training loss: 0.4368\t Validation loss: 0.5298\n",
      "[148/256] Training loss: 0.4362\t Validation loss: 0.5302\n",
      "[149/256] Training loss: 0.4382\t Validation loss: 0.5301\n",
      "[150/256] Training loss: 0.4372\t Validation loss: 0.5302\n",
      "[151/256] Training loss: 0.4370\t Validation loss: 0.5302\n",
      "[152/256] Training loss: 0.4347\t Validation loss: 0.5303\n",
      "[153/256] Training loss: 0.4354\t Validation loss: 0.5305\n",
      "[154/256] Training loss: 0.4348\t Validation loss: 0.5308\n",
      "[155/256] Training loss: 0.4362\t Validation loss: 0.5307\n",
      "[156/256] Training loss: 0.4363\t Validation loss: 0.5305\n",
      "[157/256] Training loss: 0.4351\t Validation loss: 0.5306\n",
      "[158/256] Training loss: 0.4363\t Validation loss: 0.5306\n",
      "[159/256] Training loss: 0.4350\t Validation loss: 0.5309\n",
      "[160/256] Training loss: 0.4356\t Validation loss: 0.5310\n",
      "[161/256] Training loss: 0.4355\t Validation loss: 0.5310\n",
      "[162/256] Training loss: 0.4351\t Validation loss: 0.5309\n",
      "[163/256] Training loss: 0.4351\t Validation loss: 0.5309\n",
      "[164/256] Training loss: 0.4353\t Validation loss: 0.5309\n",
      "[165/256] Training loss: 0.4347\t Validation loss: 0.5310\n",
      "[166/256] Training loss: 0.4338\t Validation loss: 0.5312\n",
      "[167/256] Training loss: 0.4357\t Validation loss: 0.5311\n",
      "[168/256] Training loss: 0.4347\t Validation loss: 0.5314\n",
      "[169/256] Training loss: 0.4351\t Validation loss: 0.5311\n",
      "[170/256] Training loss: 0.4344\t Validation loss: 0.5311\n",
      "[171/256] Training loss: 0.4345\t Validation loss: 0.5312\n",
      "[172/256] Training loss: 0.4338\t Validation loss: 0.5313\n",
      "[173/256] Training loss: 0.4344\t Validation loss: 0.5316\n",
      "[174/256] Training loss: 0.4336\t Validation loss: 0.5314\n",
      "[175/256] Training loss: 0.4342\t Validation loss: 0.5313\n",
      "[176/256] Training loss: 0.4338\t Validation loss: 0.5316\n",
      "[177/256] Training loss: 0.4329\t Validation loss: 0.5317\n",
      "[178/256] Training loss: 0.4338\t Validation loss: 0.5317\n",
      "[179/256] Training loss: 0.4342\t Validation loss: 0.5316\n",
      "[180/256] Training loss: 0.4344\t Validation loss: 0.5320\n",
      "[181/256] Training loss: 0.4342\t Validation loss: 0.5322\n",
      "[182/256] Training loss: 0.4334\t Validation loss: 0.5318\n",
      "[183/256] Training loss: 0.4335\t Validation loss: 0.5320\n",
      "[184/256] Training loss: 0.4330\t Validation loss: 0.5321\n",
      "[185/256] Training loss: 0.4324\t Validation loss: 0.5321\n",
      "[186/256] Training loss: 0.4342\t Validation loss: 0.5321\n",
      "[187/256] Training loss: 0.4335\t Validation loss: 0.5321\n",
      "[188/256] Training loss: 0.4316\t Validation loss: 0.5320\n",
      "[189/256] Training loss: 0.4324\t Validation loss: 0.5323\n",
      "[190/256] Training loss: 0.4316\t Validation loss: 0.5325\n",
      "[191/256] Training loss: 0.4312\t Validation loss: 0.5326\n",
      "[192/256] Training loss: 0.4326\t Validation loss: 0.5327\n",
      "[193/256] Training loss: 0.4315\t Validation loss: 0.5328\n",
      "[194/256] Training loss: 0.4306\t Validation loss: 0.5331\n",
      "[195/256] Training loss: 0.4325\t Validation loss: 0.5330\n",
      "[196/256] Training loss: 0.4316\t Validation loss: 0.5329\n",
      "[197/256] Training loss: 0.4308\t Validation loss: 0.5328\n",
      "[198/256] Training loss: 0.4319\t Validation loss: 0.5329\n",
      "[199/256] Training loss: 0.4318\t Validation loss: 0.5330\n",
      "[200/256] Training loss: 0.4306\t Validation loss: 0.5331\n",
      "[201/256] Training loss: 0.4321\t Validation loss: 0.5330\n",
      "[202/256] Training loss: 0.4308\t Validation loss: 0.5331\n",
      "[203/256] Training loss: 0.4314\t Validation loss: 0.5333\n",
      "[204/256] Training loss: 0.4299\t Validation loss: 0.5335\n",
      "[205/256] Training loss: 0.4297\t Validation loss: 0.5335\n",
      "[206/256] Training loss: 0.4298\t Validation loss: 0.5337\n",
      "[207/256] Training loss: 0.4311\t Validation loss: 0.5337\n",
      "[208/256] Training loss: 0.4300\t Validation loss: 0.5339\n",
      "[209/256] Training loss: 0.4318\t Validation loss: 0.5337\n",
      "[210/256] Training loss: 0.4298\t Validation loss: 0.5339\n",
      "[211/256] Training loss: 0.4301\t Validation loss: 0.5341\n",
      "[212/256] Training loss: 0.4309\t Validation loss: 0.5339\n",
      "[213/256] Training loss: 0.4303\t Validation loss: 0.5340\n",
      "[214/256] Training loss: 0.4306\t Validation loss: 0.5340\n",
      "[215/256] Training loss: 0.4295\t Validation loss: 0.5340\n",
      "[216/256] Training loss: 0.4292\t Validation loss: 0.5344\n",
      "[217/256] Training loss: 0.4301\t Validation loss: 0.5343\n",
      "[218/256] Training loss: 0.4294\t Validation loss: 0.5341\n",
      "[219/256] Training loss: 0.4288\t Validation loss: 0.5343\n",
      "[220/256] Training loss: 0.4303\t Validation loss: 0.5343\n",
      "[221/256] Training loss: 0.4293\t Validation loss: 0.5344\n",
      "[222/256] Training loss: 0.4283\t Validation loss: 0.5343\n",
      "[223/256] Training loss: 0.4305\t Validation loss: 0.5342\n",
      "[224/256] Training loss: 0.4300\t Validation loss: 0.5342\n",
      "[225/256] Training loss: 0.4297\t Validation loss: 0.5346\n",
      "[226/256] Training loss: 0.4297\t Validation loss: 0.5344\n",
      "[227/256] Training loss: 0.4307\t Validation loss: 0.5344\n",
      "[228/256] Training loss: 0.4301\t Validation loss: 0.5344\n",
      "[229/256] Training loss: 0.4293\t Validation loss: 0.5345\n",
      "[230/256] Training loss: 0.4290\t Validation loss: 0.5346\n",
      "[231/256] Training loss: 0.4295\t Validation loss: 0.5346\n",
      "[232/256] Training loss: 0.4281\t Validation loss: 0.5346\n",
      "[233/256] Training loss: 0.4294\t Validation loss: 0.5345\n",
      "[234/256] Training loss: 0.4286\t Validation loss: 0.5346\n",
      "[235/256] Training loss: 0.4277\t Validation loss: 0.5351\n",
      "[236/256] Training loss: 0.4278\t Validation loss: 0.5350\n",
      "[237/256] Training loss: 0.4280\t Validation loss: 0.5349\n",
      "[238/256] Training loss: 0.4283\t Validation loss: 0.5350\n",
      "[239/256] Training loss: 0.4293\t Validation loss: 0.5351\n",
      "[240/256] Training loss: 0.4281\t Validation loss: 0.5355\n",
      "[241/256] Training loss: 0.4285\t Validation loss: 0.5355\n",
      "[242/256] Training loss: 0.4279\t Validation loss: 0.5354\n",
      "[243/256] Training loss: 0.4278\t Validation loss: 0.5351\n",
      "[244/256] Training loss: 0.4272\t Validation loss: 0.5352\n",
      "[245/256] Training loss: 0.4271\t Validation loss: 0.5351\n",
      "[246/256] Training loss: 0.4270\t Validation loss: 0.5354\n",
      "[247/256] Training loss: 0.4273\t Validation loss: 0.5355\n",
      "[248/256] Training loss: 0.4278\t Validation loss: 0.5355\n",
      "[249/256] Training loss: 0.4263\t Validation loss: 0.5356\n",
      "[250/256] Training loss: 0.4267\t Validation loss: 0.5356\n",
      "[251/256] Training loss: 0.4268\t Validation loss: 0.5360\n",
      "[252/256] Training loss: 0.4275\t Validation loss: 0.5359\n",
      "[253/256] Training loss: 0.4279\t Validation loss: 0.5358\n",
      "[254/256] Training loss: 0.4282\t Validation loss: 0.5358\n",
      "[255/256] Training loss: 0.4268\t Validation loss: 0.5359\n",
      "[256/256] Training loss: 0.4259\t Validation loss: 0.5360\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.chdir(os.path.join(os.getcwd(),\"../../saved_models\"))\n",
    "loss_fn = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "optimizer = optim.Adagrad(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=weight_decay\n",
    ")\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=128, gamma=0.5)\n",
    "activation = nn.Sigmoid()\n",
    "opt = Optimizer(\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    activation=activation,\n",
    "    lr_scheduler=lr_scheduler,\n",
    ")\n",
    "opt.train(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    batch_size=batch_size,\n",
    "    n_epochs=n_epochs,\n",
    "    n_features=input_dim,\n",
    "    timesteps=timesteps,\n",
    ")\n",
    "opt.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c88675-3fb8-4bd8-9022-fc16a250192a",
   "metadata": {},
   "source": [
    "## Validation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a631838-e434-4005-8879-8d60b062ac1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9249 1453]\n",
      " [2829 2839]]\n",
      "confusion matrix:\n",
      "[[9249 1453]\n",
      " [2829 2839]]\n",
      "accuracy = 0.7384239435195923\n",
      "precision class 0 = 0.7657724618911743\n",
      "precision class 1 = 0.66146320104599\n",
      "recall class 0 = 0.8642309904098511\n",
      "recall class 1 = 0.5008821487426758\n",
      "AUC of ROC = 0.7841584708970168\n",
      "AUC of PRC = 0.6727877459018292\n",
      "min(+P, Se) = 0.6108270146358666\n",
      "Precision: 0.7136178016662598\n",
      "Recall: 0.6825565695762634\n"
     ]
    }
   ],
   "source": [
    "val_evaluate_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "y_val_labels, y_val_pred_values, y_val_pred_labels = opt.evaluate(\n",
    "    val_evaluate_loader, batch_size=1, n_features=input_dim, timesteps=timesteps\n",
    ")\n",
    "\n",
    "y_val_pred_values = y_val_pred_values[y_val_labels != -1]\n",
    "y_val_pred_labels = y_val_pred_labels[y_val_labels != -1]\n",
    "y_val_labels = y_val_labels[y_val_labels != -1]\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_val_labels, y_val_pred_labels)\n",
    "print(confusion_matrix)\n",
    "\n",
    "pred_metrics = print_metrics_binary(y_val_labels, y_val_pred_values, y_val_pred_labels)\n",
    "prec = (pred_metrics[\"prec0\"] + pred_metrics[\"prec1\"]) / 2\n",
    "rec = (pred_metrics[\"rec0\"] + pred_metrics[\"rec1\"]) / 2\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a11dbaa-02e3-4415-84ee-abc159a5337a",
   "metadata": {},
   "source": [
    "## Testing metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14f74137-9a38-40c6-92ee-1e6f4e02290c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2800  321]\n",
      " [1200 1088]]\n",
      "confusion matrix:\n",
      "[[2800  321]\n",
      " [1200 1088]]\n",
      "accuracy = 0.7188019752502441\n",
      "precision class 0 = 0.699999988079071\n",
      "precision class 1 = 0.7721788287162781\n",
      "recall class 0 = 0.8971483707427979\n",
      "recall class 1 = 0.4755244851112366\n",
      "AUC of ROC = 0.7956256035697721\n",
      "AUC of PRC = 0.7447077834359142\n",
      "min(+P, Se) = 0.673513986013986\n",
      "Precision: 0.7360894083976746\n",
      "Recall: 0.6863363981246948\n"
     ]
    }
   ],
   "source": [
    "test_dataset = get_data(X_test_inputs, y_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "y_test_labels, y_pred_values, y_pred_labels = opt.evaluate(\n",
    "    test_loader, batch_size=1, n_features=input_dim, timesteps=timesteps\n",
    ")\n",
    "\n",
    "y_pred_values = y_pred_values[y_test_labels != -1]\n",
    "y_pred_labels = y_pred_labels[y_test_labels != -1]\n",
    "y_test_labels = y_test_labels[y_test_labels != -1]\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_test_labels, y_pred_labels)\n",
    "print(confusion_matrix)\n",
    "\n",
    "pred_metrics = print_metrics_binary(y_test_labels, y_pred_values, y_pred_labels)\n",
    "prec = (pred_metrics[\"prec0\"] + pred_metrics[\"prec1\"]) / 2\n",
    "rec = (pred_metrics[\"rec0\"] + pred_metrics[\"rec1\"]) / 2\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612d8bf4-79c5-449f-ad60-f20217377827",
   "metadata": {},
   "source": [
    "## Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449a9b82-1081-4140-814f-a5ce083662ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(confusion_matrix, class_names):\n",
    "    confusion_matrix = (\n",
    "        confusion_matrix.astype(\"float\") / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
    "    )\n",
    "\n",
    "    layout = {\n",
    "        \"title\": \"Confusion Matrix\",\n",
    "        \"xaxis\": {\"title\": \"Predicted value\"},\n",
    "        \"yaxis\": {\"title\": \"Real value\"},\n",
    "    }\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=go.Heatmap(\n",
    "            z=confusion_matrix,\n",
    "            x=class_names,\n",
    "            y=class_names,\n",
    "            hoverongaps=False,\n",
    "            colorscale=\"Greens\",\n",
    "        ),\n",
    "        layout=layout,\n",
    "    )\n",
    "    fig.update_layout(height=512, width=1024)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "plot_confusion_matrix(\n",
    "    confusion_matrix, [\"low risk of mortality\", \"high risk of mortality\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43cfde9-3c6d-4de9-817e-811376f5cb3f",
   "metadata": {},
   "source": [
    "## Compute AUROC across timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679e86a5-8db4-4e44-bf50-babfb186427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_labels, y_pred_values, y_pred_labels = opt.evaluate(\n",
    "    test_loader, batch_size=1, n_features=input_dim, timesteps=timesteps, flatten=False\n",
    ")\n",
    "\n",
    "num_timesteps = y_pred_labels.shape[1]\n",
    "auroc_timesteps = []\n",
    "for i in range(num_timesteps):\n",
    "    labels = y_test_labels[:, i]\n",
    "    pred_vals = y_pred_values[:, i]\n",
    "    preds = y_pred_labels[:, i]\n",
    "    pred_vals = pred_vals[labels != -1]\n",
    "    preds = preds[labels != -1]\n",
    "    labels = labels[labels != -1]\n",
    "    pred_metrics = print_metrics_binary(labels, pred_vals, preds, verbose=False)\n",
    "    auroc_timesteps.append(pred_metrics[\"auroc\"])\n",
    "\n",
    "\n",
    "prediction_hours = list(range(24, 168, 24))\n",
    "fig = go.Figure(\n",
    "    data=[go.Bar(x=prediction_hours, y=auroc_timesteps, name=\"model confidence\")]\n",
    ")\n",
    "\n",
    "fig.update_xaxes(tickvals=prediction_hours)\n",
    "fig.update_yaxes(range=[min(auroc_timesteps) - 0.05, max(auroc_timesteps) + 0.05])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"AUROC split by no. of hours after admission\",\n",
    "    autosize=False,\n",
    "    xaxis_title=\"No. of hours after admission\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aea19ab-7dc3-4f9e-b073-17f788537b81",
   "metadata": {},
   "source": [
    "## WIP: Compute accuracy across lead times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed54c9c-4e81-4bce-9fe7-09a18296c3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE_DATA_PATH = \"/mnt/nfs/project/delirium/drift_exp/risk_of_mortality\"\n",
    "\n",
    "# combined_events = load_dataframe(os.path.join(BASE_DATA_PATH, \"combined_events\"))\n",
    "# timestep_end_timestamps = load_dataframe(os.path.join(BASE_DATA_PATH, \"aggmeta_end_ts\"))\n",
    "\n",
    "# mortality_events = combined_events.loc[combined_events[\"event_name\"] == \"death\"]\n",
    "\n",
    "# y_test_labels, y_pred_values, y_pred_labels = opt.evaluate(\n",
    "#     test_loader, batch_size=1, n_features=input_dim, timesteps=timesteps, flatten=False\n",
    "# )\n",
    "# train_val_test_ids = load_dataframe(os.path.join(BASE_DATA_PATH, \"train_val_test_ids\"))\n",
    "# test_ids = train_val_test_ids[\"test\"].dropna()\n",
    "\n",
    "# num_timesteps = y_pred_labels.shape[1]\n",
    "# acc_timesteps = []\n",
    "# for timestep in range(num_timesteps):\n",
    "#     labels = y_test_labels[:, timestep]\n",
    "#     pred_vals = y_pred_values[:, timestep]\n",
    "#     preds = y_pred_labels[:, timestep]\n",
    "\n",
    "#     is_correct_timestep = []\n",
    "#     for enc_id in test_ids:\n",
    "#         timestep_end_timestamp = timestep_end_timestamps.loc[enc_id, timestep]\n",
    "#         mortality_timestamp = mortality_events.loc[mortality_events[\"encounter_id\"] == enc_id][\"discharge_timestamp\"]\n",
    "#         lead_time = mortality_timestamp - timestep_end_timestamp\n",
    "#         print(timestep_end_timestamp, mortality_timestamp)\n",
    "#         if (lead_time > pd.to_timedelta(0, unit=\"h\")).all():\n",
    "#             label_ = labels[test_ids.index(enc_id)]\n",
    "#             pred_ = preds[test_ids.index(enc_id)]\n",
    "\n",
    "#             if label_ == 1:\n",
    "#                 if label_ == pred_:\n",
    "#                     is_correct_timestep.append(1)\n",
    "#                 else:\n",
    "#                     is_correct_timestep.append(0)\n",
    "\n",
    "#     acc_timesteps.append(sum(is_correct_timestep) / len(is_correct_timestep))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8825f3a-a941-456b-b418-db620c224eb0",
   "metadata": {},
   "source": [
    "## Visualize model outputs and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6fbfab-57bc-4f07-9645-740b588d2ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_risk_mortality(predictions, labels=None):\n",
    "    prediction_hours = list(range(24, 168, 24))\n",
    "    is_mortality = labels == 1\n",
    "    after_discharge = labels == -1\n",
    "    label_h = -0.2\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Scatter(\n",
    "                mode=\"markers\",\n",
    "                x=prediction_hours,\n",
    "                y=[label_h for x in prediction_hours],\n",
    "                line=dict(color=\"Black\"),\n",
    "                name=\"low risk of mortality label\",\n",
    "                marker=dict(color=\"Green\", size=20, line=dict(color=\"Black\", width=2)),\n",
    "            ),\n",
    "            go.Scatter(\n",
    "                mode=\"markers\",\n",
    "                x=[prediction_hours[i] for i, v in enumerate(is_mortality) if v],\n",
    "                y=[label_h for _, v in enumerate(is_mortality) if v],\n",
    "                line=dict(color=\"Red\"),\n",
    "                name=\"high risk of mortality label\",\n",
    "                marker=dict(color=\"Red\", size=20, line=dict(color=\"Black\", width=2)),\n",
    "            ),\n",
    "            go.Scatter(\n",
    "                mode=\"markers\",\n",
    "                x=[prediction_hours[i] for i, v in enumerate(after_discharge) if v],\n",
    "                y=[label_h for _, v in enumerate(after_discharge) if v],\n",
    "                line=dict(color=\"Grey\"),\n",
    "                name=\"post discharge label\",\n",
    "                marker=dict(color=\"Grey\", size=20, line=dict(color=\"Black\", width=2)),\n",
    "            ),\n",
    "            go.Bar(\n",
    "                x=prediction_hours,\n",
    "                y=predictions,\n",
    "                marker_color=\"Red\",\n",
    "                name=\"model confidence\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    fig.update_yaxes(range=[label_h, 1])\n",
    "    fig.update_xaxes(tickvals=prediction_hours)\n",
    "    fig.update_xaxes(showline=True, linewidth=2, linecolor=\"black\")\n",
    "\n",
    "    fig.add_hline(y=0.5)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Model output visualization\",\n",
    "        autosize=False,\n",
    "        xaxis_title=\"No. of hours after admission\",\n",
    "        yaxis_title=\"Model confidence\",\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "mortality_cases = [idx for idx, v in enumerate(y_test_labels)]\n",
    "sample_idx = random.choice(mortality_cases)\n",
    "fig = plot_risk_mortality(\n",
    "    y_pred_values[sample_idx].squeeze(), y_test_labels[sample_idx]\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e182f4-e943-4e8f-ac45-8c445ed064c5",
   "metadata": {},
   "source": [
    "## Journal of some experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb21dd9-83a7-4b49-b328-655bf02a3c8b",
   "metadata": {},
   "source": [
    "\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Split</th>\n",
    "            <th>Model</th>\n",
    "            <th>AUROC</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td rowspan=4>Random</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>LSTM</td>\n",
    "            <td><b>0.8005</b></td>\n",
    "        </tr>\n",
    "          <tr style=\"border-bottom:1px solid black\">\n",
    "            <td colspan=\"100%\"></td>\n",
    "          </tr>\n",
    "          <tr> ... </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyclops-KKtuQLwg-py3.9",
   "language": "python",
   "name": "cyclops-kktuqlwg-py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd4e001b-4921-4a4f-8c2c-0c364d082a3f",
   "metadata": {},
   "source": [
    "## Train temporal models for mortality risk prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4681dab-9200-4063-9544-f2013bdcd2ba",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce5e9ec-e3d0-4719-a7ee-43e88dcde8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn import metrics\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "from baseline_models.temporal.pytorch.optimizer import Optimizer\n",
    "from baseline_models.temporal.pytorch.utils import *\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from cyclops.utils.file import load_dataframe, save_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e583ae-7a70-49d1-9e93-26b692c85d89",
   "metadata": {},
   "source": [
    "## Load train/val/test inputs and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12066550-01d2-4869-a96b-2ab9c37171ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = \"/mnt/nfs/project/delirium/drift_exp/JULY-04-2022\"\n",
    "split_type = \"simulated_deployment\"\n",
    "\n",
    "X_train = np.load(os.path.join(DIR, split_type, \"X_train.npy\"))\n",
    "X_val = np.load(os.path.join(DIR, split_type, \"X_val.npy\"))\n",
    "X_test = np.load(os.path.join(DIR, split_type, \"X_test.npy\"))\n",
    "\n",
    "y_train = np.load(os.path.join(DIR, split_type, \"y_train.npy\"))\n",
    "y_val = np.load(os.path.join(DIR, split_type, \"y_val.npy\"))\n",
    "y_test = np.load(os.path.join(DIR, split_type, \"y_test.npy\"))\n",
    "\n",
    "print(\"Train set size:\", X_train.shape[0])\n",
    "print(\"Val set size:\", X_val.shape[0])\n",
    "print(\"Test set size:\", X_test.shape[0])\n",
    "\n",
    "print(\"Num features:\", X_train.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb16cf4-7838-4757-850e-913093c42181",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, train_counts = np.unique(y_train, return_counts=True)\n",
    "unique, val_counts = np.unique(y_val, return_counts=True)\n",
    "unique, test_counts = np.unique(y_test, return_counts=True)\n",
    "print(\n",
    "    pd.DataFrame(\n",
    "        {\"Train\": train_counts, \"Val\": val_counts, \"Test\": test_counts}, index=unique\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde55789-cb88-49db-9121-27cbdbddc46b",
   "metadata": {},
   "source": [
    "## Model and training configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810aab27-5fc4-4271-98eb-16f0917eb520",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = 1\n",
    "batch_size = 64\n",
    "input_dim = X_train.shape[2]\n",
    "timesteps = X_train.shape[1]\n",
    "hidden_dim = 64\n",
    "layer_dim = 2\n",
    "dropout = 0.2\n",
    "n_epochs = 256\n",
    "learning_rate = 2e-3\n",
    "weight_decay = 1e-6\n",
    "last_timestep_only = False\n",
    "\n",
    "device = get_device()\n",
    "\n",
    "X_train_inputs = X_train\n",
    "X_val_inputs = X_val\n",
    "X_test_inputs = X_test\n",
    "\n",
    "train_dataset = get_data(X_train_inputs, y_train)\n",
    "train_loader = train_dataset.to_loader(batch_size, shuffle=True)\n",
    "\n",
    "val_dataset = get_data(X_val_inputs, y_val)\n",
    "val_loader = val_dataset.to_loader(batch_size)\n",
    "\n",
    "model_params = {\n",
    "    \"device\": device,\n",
    "    \"input_dim\": input_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"layer_dim\": layer_dim,\n",
    "    \"output_dim\": output_dim,\n",
    "    \"dropout_prob\": dropout,\n",
    "    \"last_timestep_only\": last_timestep_only,\n",
    "}\n",
    "model_name = \"lstm\"\n",
    "model = get_temporal_model(model_name, model_params).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388af42e-49ac-48c5-a285-8ce66a714518",
   "metadata": {},
   "source": [
    "## Training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba84339-f87b-4262-abf1-49200468eaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_fpath = os.path.join(os.getcwd(),'../../saved_models/',split_type+\"_lstm.pt\")\n",
    "# model, opt, n_epochs = load_ckp(checkpoint_fpath, model)\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "optimizer = optim.Adagrad(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=weight_decay\n",
    ")\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=128, gamma=0.5)\n",
    "activation = nn.Sigmoid()\n",
    "opt = Optimizer(\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    activation=activation,\n",
    "    lr_scheduler=lr_scheduler,\n",
    ")\n",
    "opt.train(\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    batch_size=batch_size,\n",
    "    n_epochs=n_epochs,\n",
    "    n_features=input_dim,\n",
    "    timesteps=timesteps,\n",
    ")\n",
    "opt.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cb13ae-590a-43ea-8eaf-cb8cfa7a6a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../../saved_models/\" + split_type + \"_\" + model_name + \".pt\"\n",
    "state = {\"n_epochs\": n_epochs, \"model\": model.state_dict(), \"optimizer\": opt}\n",
    "torch.save(state, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c88675-3fb8-4bd8-9022-fc16a250192a",
   "metadata": {},
   "source": [
    "## Validation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a631838-e434-4005-8879-8d60b062ac1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_evaluate_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=1, shuffle=False\n",
    ")\n",
    "y_val_labels, y_val_pred_values, y_val_pred_labels = opt.evaluate(\n",
    "    val_evaluate_loader, batch_size=1, n_features=input_dim, timesteps=timesteps\n",
    ")\n",
    "\n",
    "y_val_pred_values = y_val_pred_values[y_val_labels != -1]\n",
    "y_val_pred_labels = y_val_pred_labels[y_val_labels != -1]\n",
    "y_val_labels = y_val_labels[y_val_labels != -1]\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_val_labels, y_val_pred_labels)\n",
    "print(confusion_matrix)\n",
    "\n",
    "pred_metrics = print_metrics_binary(y_val_labels, y_val_pred_values, y_val_pred_labels)\n",
    "prec = (pred_metrics[\"prec0\"] + pred_metrics[\"prec1\"]) / 2\n",
    "rec = (pred_metrics[\"rec0\"] + pred_metrics[\"rec1\"]) / 2\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {rec}\")\n",
    "\n",
    "\n",
    "def plot_pretty_confusion_matrix(confusion_matrix):\n",
    "    sns.set(style=\"white\")\n",
    "    fig, ax = plt.subplots(figsize=(9, 6))\n",
    "    sns.heatmap(\n",
    "        np.eye(2),\n",
    "        annot=confusion_matrix,\n",
    "        fmt=\"g\",\n",
    "        annot_kws={\"size\": 50},\n",
    "        cmap=sns.color_palette([\"tomato\", \"palegreen\"], as_cmap=True),\n",
    "        cbar=False,\n",
    "        yticklabels=[\"False\", \"True\"],\n",
    "        xticklabels=[\"False\", \"True\"],\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.xaxis.set_label_position(\"top\")\n",
    "    ax.tick_params(labelsize=20, length=0)\n",
    "\n",
    "    ax.set_title(\"Confusion Matrix for Test Set\", size=24, pad=20)\n",
    "    ax.set_xlabel(\"Predicted Values\", size=20)\n",
    "    ax.set_ylabel(\"Actual Values\", size=20)\n",
    "\n",
    "    additional_texts = [\n",
    "        \"(True Negative)\",\n",
    "        \"(False Negative)\",\n",
    "        \"(False Positive)\",\n",
    "        \"(True Positive)\",\n",
    "    ]\n",
    "    for text_elt, additional_text in zip(ax.texts, additional_texts):\n",
    "        ax.text(\n",
    "            *text_elt.get_position(),\n",
    "            \"\\n\" + additional_text,\n",
    "            color=text_elt.get_color(),\n",
    "            ha=\"center\",\n",
    "            va=\"top\",\n",
    "            size=24,\n",
    "        )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_pretty_confusion_matrix(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a11dbaa-02e3-4415-84ee-abc159a5337a",
   "metadata": {},
   "source": [
    "## Testing metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f74137-9a38-40c6-92ee-1e6f4e02290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = get_data(X_test_inputs, y_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "y_test_labels, y_pred_values, y_pred_labels = opt.evaluate(\n",
    "    test_loader, batch_size=1, n_features=input_dim, timesteps=timesteps\n",
    ")\n",
    "\n",
    "y_pred_values = y_pred_values[y_test_labels != -1]\n",
    "y_pred_labels = y_pred_labels[y_test_labels != -1]\n",
    "y_test_labels = y_test_labels[y_test_labels != -1]\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_test_labels, y_pred_labels)\n",
    "print(confusion_matrix)\n",
    "\n",
    "pred_metrics = print_metrics_binary(y_test_labels, y_pred_values, y_pred_labels)\n",
    "prec = (pred_metrics[\"prec0\"] + pred_metrics[\"prec1\"]) / 2\n",
    "rec = (pred_metrics[\"rec0\"] + pred_metrics[\"rec1\"]) / 2\n",
    "print(f\"Precision: {prec}\")\n",
    "print(f\"Recall: {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612d8bf4-79c5-449f-ad60-f20217377827",
   "metadata": {},
   "source": [
    "## Plot confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449a9b82-1081-4140-814f-a5ce083662ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(confusion_matrix, class_names):\n",
    "    confusion_matrix = (\n",
    "        confusion_matrix.astype(\"float\") / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
    "    )\n",
    "\n",
    "    layout = {\n",
    "        \"title\": \"Confusion Matrix\",\n",
    "        \"xaxis\": {\"title\": \"Predicted value\"},\n",
    "        \"yaxis\": {\"title\": \"Real value\"},\n",
    "    }\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=go.Heatmap(\n",
    "            z=confusion_matrix,\n",
    "            x=class_names,\n",
    "            y=class_names,\n",
    "            hoverongaps=False,\n",
    "            colorscale=\"Greens\",\n",
    "        ),\n",
    "        layout=layout,\n",
    "    )\n",
    "    fig.update_layout(height=512, width=1024)\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "plot_confusion_matrix(\n",
    "    confusion_matrix, [\"low risk of mortality\", \"high risk of mortality\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43cfde9-3c6d-4de9-817e-811376f5cb3f",
   "metadata": {},
   "source": [
    "## Compute AUROC across timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679e86a5-8db4-4e44-bf50-babfb186427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_labels, y_pred_values, y_pred_labels = opt.evaluate(\n",
    "    test_loader, batch_size=1, n_features=input_dim, timesteps=timesteps, flatten=False\n",
    ")\n",
    "\n",
    "num_timesteps = y_pred_labels.shape[1]\n",
    "auroc_timesteps = []\n",
    "for i in range(num_timesteps):\n",
    "    labels = y_test_labels[:, i]\n",
    "    pred_vals = y_pred_values[:, i]\n",
    "    preds = y_pred_labels[:, i]\n",
    "    pred_vals = pred_vals[labels != -1]\n",
    "    preds = preds[labels != -1]\n",
    "    labels = labels[labels != -1]\n",
    "    pred_metrics = print_metrics_binary(labels, pred_vals, preds, verbose=False)\n",
    "    auroc_timesteps.append(pred_metrics[\"auroc\"])\n",
    "\n",
    "\n",
    "prediction_hours = list(range(24, 168, 24))\n",
    "fig = go.Figure(\n",
    "    data=[go.Bar(x=prediction_hours, y=auroc_timesteps, name=\"model confidence\")]\n",
    ")\n",
    "\n",
    "fig.update_xaxes(tickvals=prediction_hours)\n",
    "fig.update_yaxes(range=[min(auroc_timesteps) - 0.05, max(auroc_timesteps) + 0.05])\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"AUROC split by no. of hours after admission\",\n",
    "    autosize=False,\n",
    "    xaxis_title=\"No. of hours after admission\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aea19ab-7dc3-4f9e-b073-17f788537b81",
   "metadata": {},
   "source": [
    "## WIP: Compute accuracy across lead times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed54c9c-4e81-4bce-9fe7-09a18296c3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE_DATA_PATH = \"/mnt/nfs/project/delirium/drift_exp/risk_of_mortality\"\n",
    "\n",
    "# combined_events = load_dataframe(os.path.join(BASE_DATA_PATH, \"combined_events\"))\n",
    "# timestep_end_timestamps = load_dataframe(os.path.join(BASE_DATA_PATH, \"aggmeta_end_ts\"))\n",
    "\n",
    "# mortality_events = combined_events.loc[combined_events[\"event_name\"] == \"death\"]\n",
    "\n",
    "# y_test_labels, y_pred_values, y_pred_labels = opt.evaluate(\n",
    "#     test_loader, batch_size=1, n_features=input_dim, timesteps=timesteps, flatten=False\n",
    "# )\n",
    "# train_val_test_ids = load_dataframe(os.path.join(BASE_DATA_PATH, \"train_val_test_ids\"))\n",
    "# test_ids = train_val_test_ids[\"test\"].dropna()\n",
    "\n",
    "# num_timesteps = y_pred_labels.shape[1]\n",
    "# acc_timesteps = []\n",
    "# for timestep in range(num_timesteps):\n",
    "#     labels = y_test_labels[:, timestep]\n",
    "#     pred_vals = y_pred_values[:, timestep]\n",
    "#     preds = y_pred_labels[:, timestep]\n",
    "\n",
    "#     is_correct_timestep = []\n",
    "#     for enc_id in test_ids:\n",
    "#         timestep_end_timestamp = timestep_end_timestamps.loc[enc_id, timestep]\n",
    "#         mortality_timestamp = mortality_events.loc[mortality_events[\"encounter_id\"] == enc_id][\"discharge_timestamp\"]\n",
    "#         lead_time = mortality_timestamp - timestep_end_timestamp\n",
    "#         print(timestep_end_timestamp, mortality_timestamp)\n",
    "#         if (lead_time > pd.to_timedelta(0, unit=\"h\")).all():\n",
    "#             label_ = labels[test_ids.index(enc_id)]\n",
    "#             pred_ = preds[test_ids.index(enc_id)]\n",
    "\n",
    "#             if label_ == 1:\n",
    "#                 if label_ == pred_:\n",
    "#                     is_correct_timestep.append(1)\n",
    "#                 else:\n",
    "#                     is_correct_timestep.append(0)\n",
    "\n",
    "#     acc_timesteps.append(sum(is_correct_timestep) / len(is_correct_timestep))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8825f3a-a941-456b-b418-db620c224eb0",
   "metadata": {},
   "source": [
    "## Visualize model outputs and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6fbfab-57bc-4f07-9645-740b588d2ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_risk_mortality(predictions, labels=None):\n",
    "    prediction_hours = list(range(24, 168, 24))\n",
    "    is_mortality = labels == 1\n",
    "    after_discharge = labels == -1\n",
    "    label_h = -0.2\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Scatter(\n",
    "                mode=\"markers\",\n",
    "                x=prediction_hours,\n",
    "                y=[label_h for x in prediction_hours],\n",
    "                line=dict(color=\"Black\"),\n",
    "                name=\"low risk of mortality label\",\n",
    "                marker=dict(color=\"Green\", size=20, line=dict(color=\"Black\", width=2)),\n",
    "            ),\n",
    "            go.Scatter(\n",
    "                mode=\"markers\",\n",
    "                x=[prediction_hours[i] for i, v in enumerate(is_mortality) if v],\n",
    "                y=[label_h for _, v in enumerate(is_mortality) if v],\n",
    "                line=dict(color=\"Red\"),\n",
    "                name=\"high risk of mortality label\",\n",
    "                marker=dict(color=\"Red\", size=20, line=dict(color=\"Black\", width=2)),\n",
    "            ),\n",
    "            go.Scatter(\n",
    "                mode=\"markers\",\n",
    "                x=[prediction_hours[i] for i, v in enumerate(after_discharge) if v],\n",
    "                y=[label_h for _, v in enumerate(after_discharge) if v],\n",
    "                line=dict(color=\"Grey\"),\n",
    "                name=\"post discharge label\",\n",
    "                marker=dict(color=\"Grey\", size=20, line=dict(color=\"Black\", width=2)),\n",
    "            ),\n",
    "            go.Bar(\n",
    "                x=prediction_hours,\n",
    "                y=predictions,\n",
    "                marker_color=\"Red\",\n",
    "                name=\"model confidence\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    fig.update_yaxes(range=[label_h, 1])\n",
    "    fig.update_xaxes(tickvals=prediction_hours)\n",
    "    fig.update_xaxes(showline=True, linewidth=2, linecolor=\"black\")\n",
    "\n",
    "    fig.add_hline(y=0.5)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Model output visualization\",\n",
    "        autosize=False,\n",
    "        xaxis_title=\"No. of hours after admission\",\n",
    "        yaxis_title=\"Model confidence\",\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "mortality_cases = [idx for idx, v in enumerate(y_test_labels)]\n",
    "sample_idx = random.choice(mortality_cases)\n",
    "fig = plot_risk_mortality(\n",
    "    y_pred_values[sample_idx].squeeze(), y_test_labels[sample_idx]\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e182f4-e943-4e8f-ac45-8c445ed064c5",
   "metadata": {},
   "source": [
    "## Journal of some experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb21dd9-83a7-4b49-b328-655bf02a3c8b",
   "metadata": {},
   "source": [
    "\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Split</th>\n",
    "            <th>Model</th>\n",
    "            <th>AUROC</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td rowspan=4>Random</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>LSTM</td>\n",
    "            <td><b>0.8005</b></td>\n",
    "        </tr>\n",
    "          <tr style=\"border-bottom:1px solid black\">\n",
    "            <td colspan=\"100%\"></td>\n",
    "          </tr>\n",
    "          <tr> ... </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyclops-KKtuQLwg-py3.9",
   "language": "python",
   "name": "cyclops-kktuqlwg-py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

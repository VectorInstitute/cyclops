{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d995dcd3-fb7a-4398-b8b8-984c2ddc78be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from baseline_models.temporal.pytorch.optimizer import Optimizer\n",
    "from baseline_models.temporal.pytorch.utils import *\n",
    "from alibi_detect.cd import MMDDrift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19e5e72f-2501-4d32-a5d9-1f53051c1d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-24 21:32:50,724 \u001b[1;37mINFO\u001b[0m cyclops.feature_handler - Loading features from file...\n",
      "2022-06-24 21:32:50,730 \u001b[1;37mINFO\u001b[0m cyclops.feature_handler - Found file to load for static features...\n",
      "2022-06-24 21:32:50,731 \u001b[1;37mINFO\u001b[0m cyclops.feature_handler - Successfully loaded static features from file...\n",
      "2022-06-24 21:32:52,288 \u001b[1;37mINFO\u001b[0m cyclops.feature_handler - Found file to load for temporal features...\n",
      "2022-06-24 21:32:55,057 \u001b[1;37mINFO\u001b[0m cyclops.feature_handler - Successfully loaded temporal features from file...\n"
     ]
    }
   ],
   "source": [
    "from cyclops.feature_handler import FeatureHandler\n",
    "from cyclops.plotter import plot_timeline, set_bars_color, setup_plot\n",
    "from cyclops.processor import run_data_pipeline\n",
    "from cyclops.processors.aggregate import Aggregator\n",
    "from cyclops.processors.column_names import (\n",
    "    ADMIT_TIMESTAMP,\n",
    "    AGE,\n",
    "    DIAGNOSIS_CODE,\n",
    "    DISCHARGE_DISPOSITION,\n",
    "    DISCHARGE_TIMESTAMP,\n",
    "    ENCOUNTER_ID,\n",
    "    EVENT_CATEGORY,\n",
    "    EVENT_NAME,\n",
    "    EVENT_TIMESTAMP,\n",
    "    EVENT_VALUE,\n",
    "    HOSPITAL_ID,\n",
    "    LENGTH_OF_STAY_IN_ER,\n",
    "    RESTRICT_TIMESTAMP,\n",
    "    SEX,\n",
    "    TIMESTEP,\n",
    "    TRIAGE_LEVEL,\n",
    "    WINDOW_START_TIMESTAMP,\n",
    ")\n",
    "from cyclops.processors.constants import SMH\n",
    "from cyclops.processors.events import (\n",
    "    combine_events,\n",
    "    convert_to_events,\n",
    "    normalize_events,\n",
    ")\n",
    "from cyclops.processors.impute import Imputer\n",
    "from cyclops.processors.statics import compute_statics\n",
    "from cyclops.processors.string_ops import replace_if_string_match, to_lower\n",
    "from cyclops.processors.util import (\n",
    "    create_indicator_variables,\n",
    "    fill_missing_timesteps,\n",
    "    gather_columns,\n",
    "    pivot_aggregated_events_to_features,\n",
    ")\n",
    "from cyclops.query import gemini\n",
    "from cyclops.utils.file import load_dataframe, save_dataframe\n",
    "\n",
    "BASE_DATA_PATH = \"/mnt/nfs/project/delirium/drift_exp/risk_of_mortality\"\n",
    "feature_handler = FeatureHandler()\n",
    "feature_handler.load(BASE_DATA_PATH, \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cab5bf4-7a31-426a-bc7b-4bba9856cf52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-24 23:06:34,753 \u001b[1;37mINFO\u001b[0m cyclops.feature_handler - Loading features from file...\n",
      "2022-06-24 23:06:34,757 \u001b[1;37mINFO\u001b[0m cyclops.feature_handler - Found file to load for static features...\n",
      "2022-06-24 23:06:34,759 \u001b[1;37mINFO\u001b[0m cyclops.feature_handler - Successfully loaded static features from file...\n",
      "2022-06-24 23:06:34,810 \u001b[1;37mINFO\u001b[0m cyclops.feature_handler - Found file to load for temporal features...\n",
      "2022-06-24 23:06:37,381 \u001b[1;37mINFO\u001b[0m cyclops.feature_handler - Successfully loaded temporal features from file...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fractions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m encounter_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(merged_static_temporal\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_level_values(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m     30\u001b[0m random\u001b[38;5;241m.\u001b[39mshuffle(encounter_ids)\n\u001b[0;32m---> 31\u001b[0m num_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43mfractions\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(encounter_ids))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fractions' is not defined"
     ]
    }
   ],
   "source": [
    "hospital = [\"SMH\",\"MSH\",\"PMH\"]\n",
    "import os\n",
    "import random\n",
    "BASE_DATA_PATH = \"/mnt/nfs/project/delirium/drift_exp/risk_of_mortality\"\n",
    "hosp_label = \"_\".join(sorted(hospital, key=str.lower))\n",
    "if True:\n",
    "        # Declare feature handler\n",
    "        feature_handler = FeatureHandler()\n",
    "        feature_handler.load(BASE_DATA_PATH, \"features\")\n",
    "        \n",
    "        # Get static and temporal data\n",
    "        static = feature_handler.features[\"static\"]\n",
    "        temporal = feature_handler.features[\"temporal\"]\n",
    "\n",
    "         # Get types of columns\n",
    "        numerical_cols = feature_handler.get_numerical_feature_names()[\"temporal\"]\n",
    "        cat_cols = feature_handler.get_categorical_feature_names()[\"temporal\"]\n",
    "        \n",
    "        ## Impute numerical columns\n",
    "        temporal[numerical_cols] = temporal[numerical_cols].ffill().bfill()\n",
    "\n",
    "        # Check no more missingness!\n",
    "        assert not temporal.isna().sum().sum() and not static.isna().sum().sum()\n",
    "        \n",
    "        # Combine static and temporal\n",
    "        merged_static_temporal = temporal.combine_first(static)\n",
    "        numerical_cols += [\"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92190c8d-c335-4f66-87f3-48831361f565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - 1 --> 2 - 3\n",
      "No GPU detected, fall back on CPU.\n",
      "[]\n",
      "1 - 2 --> 3 - 4\n",
      "No GPU detected, fall back on CPU.\n",
      "[0.05022074]\n",
      "2 - 3 --> 4 - 5\n",
      "No GPU detected, fall back on CPU.\n",
      "[0.05022074 0.46022977]\n",
      "3 - 4 --> 5 - 6\n",
      "No GPU detected, fall back on CPU.\n",
      "[0.05022074 0.46022977 0.37153142]\n"
     ]
    }
   ],
   "source": [
    "n_start_window = 1\n",
    "n_end_window = 1\n",
    "n_window = 2\n",
    "\n",
    "DIR = \"/mnt/nfs/project/delirium/drift_exp/risk_of_mortality\"\n",
    "split_type = \"random\"\n",
    "series = np.load(os.path.join(DIR, split_type, \"X_test.npy\"))\n",
    "threshold = 0.05\n",
    "\n",
    "def rolling_window(n_start_window, n_end_window, n_window, series, threshold):\n",
    "\n",
    "    p_vals = np.asarray([])\n",
    "    dist_vals = np.asarray([])\n",
    "\n",
    "    run_length = int(n_start_window)\n",
    "    i = n_start_window\n",
    "\n",
    "    while i+n_end_window+n_window <= series.shape[1]:\n",
    "        feat_index = 0\n",
    "        print(max(int(i)-run_length,0),\"-\", int(i),\"-->\",max(int(i)+n_window,0),\"-\",int(i)+n_end_window+n_window)\n",
    "        prev = series[: , max(int(i)-run_length,0):int(i), :]\n",
    "        prev = prev.reshape(prev.shape[0]*prev.shape[1],prev.shape[2])\n",
    "        next = series[: , max(int(i)+n_window,0):int(i)+n_end_window+n_window, :]\n",
    "        next = next.reshape(next.shape[0]*next.shape[1],next.shape[2])\n",
    "        if next.shape[0]<=2 or prev.shape[0]<=2:\n",
    "            break\n",
    "            \n",
    "        ## run distribution shift check here\n",
    "        cd = MMDDrift(prev, backend='pytorch', p_val=.05)\n",
    "        preds = cd.predict(next, return_p_val=True, return_distance=True)\n",
    "        p_val = preds['data']['p_val']\n",
    "        dist_val = preds['data']['distance']\n",
    "        print(dist_vals)\n",
    "        if p_val >= threshold:\n",
    "            dist_vals = np.concatenate((dist_vals, np.repeat(dist_val, 1)))\n",
    "            dist_vals = np.concatenate((dist_vals, np.repeat(0, n_end_window-1)))\n",
    "            i += n_end_window\n",
    "            run_length += n_start_window\n",
    "        else:\n",
    "            dist_vals = np.concatenate((dist_vals, np.repeat(dist_val, 1)))\n",
    "            i+=1\n",
    "            run_length = n_start_window\n",
    "\n",
    "    return dist_vals, \n",
    "\n",
    "dist_vals = rolling_window(n_start_window, n_end_window, 1, series, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11f5d6ec-cb30-4c26-b848-27fd27a0fa56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1738,)\n"
     ]
    }
   ],
   "source": [
    "print(dist_vals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12dea525-0769-4f8d-abc6-96ca4cc5556e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'query_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m limit_tn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m## query data \u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m encounters_data, labs_data, imaging_data, transfusions_data, interventions_data \u001b[38;5;241m=\u001b[39m \u001b[43mquery_data\u001b[49m(BASE_DATA_PATH)\n\u001b[1;32m      8\u001b[0m encounters_mortality, encounters_not_mortality \u001b[38;5;241m=\u001b[39m split_encounters_bymortality(encounter_data)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m limit_tn:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'query_data' is not defined"
     ]
    }
   ],
   "source": [
    "DIR = \"/mnt/nfs/project/delirium/drift_exp/_extract_v2\"\n",
    "\n",
    "timeframe=14\n",
    "limit_tn=True\n",
    "\n",
    "## query data \n",
    "encounters_data, labs_data, imaging_data, transfusions_data, interventions_data = query_data(BASE_DATA_PATH)\n",
    "encounters_mortality, encounters_not_mortality = split_encounters_bymortality(encounter_data)\n",
    "\n",
    "if limit_tn:\n",
    "    num_encounters_not_mortality = len(encounters_mortality)\n",
    "    encounters_not_mortality_subset = encounters_not_mortality[\n",
    "        0:num_encounters_not_mortality\n",
    "]\n",
    "        \n",
    "encounters_train_val_test = pd.concat(\n",
    "    [encounters_mortality, encounters_not_mortality_subset], ignore_index=True\n",
    ")\n",
    "encounters_mortality_within_risk_timeframe = encounters_mortality.loc[\n",
    "    encounters_mortality[LOS] <= pd.to_timedelta(timeframe * 24, unit=\"h\")\n",
    "]\n",
    "\n",
    "mortality_events = create_mortality_events(encounters_mortality_within_risk_timeframe, encounters_mortality)\n",
    "combined_events = create_events(encounters_train_val_test, labs_data, imaging_data, transfusions_data, interventions_data, mortality_events)\n",
    "static_features = get_static_features(encounters_train_val_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7715b717-7f17-43f3-b2da-84371427fdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_p_vals, std_p_vals, mean_dist, std_dist = run_shift_experiment(\n",
    "                        outcome=OUTCOME,\n",
    "                        hospital=HOSPITAL,\n",
    "                        path=PATH,\n",
    "                        dr_technique=DR_TECHNIQUE,\n",
    "                        md_test=MD_TEST,\n",
    "                        samples=SAMPLES,\n",
    "                        dataset=DATASET,\n",
    "                        sign_level=SIGN_LEVEL,\n",
    "                        na_cutoff=NA_CUTOFF,\n",
    "                        random_runs=RANDOM_RUNS,\n",
    "                        calc_acc=CALC_ACC,\n",
    "                        bucket_size=6, \n",
    "                        window=6\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyclops-KKtuQLwg-py3.9",
   "language": "python",
   "name": "cyclops-kktuqlwg-py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
